{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27dca54c",
   "metadata": {},
   "source": [
    "# Base model for stock prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51e1b357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.log_controller import LogController\n",
    "from pathlib import Path\n",
    "\n",
    "log_controller = LogController(config_path=Path('config', 'logging_config.json'))\n",
    "log_controller.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f63950aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m 2025-09-04 23:09:39 - data_repository - INFO - Loaded: AAPL\u001b[0m\n",
      "\u001b[32m 2025-09-04 23:09:39 - data_repository - INFO - Loaded: AMZN\u001b[0m\n",
      "\u001b[32m 2025-09-04 23:09:39 - data_repository - INFO - Loaded periodic stock market data for: {'AAPL', 'AMZN'}\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-10-29</th>\n",
       "      <td>0.9285</td>\n",
       "      <td>0.9460</td>\n",
       "      <td>0.9035</td>\n",
       "      <td>0.9255</td>\n",
       "      <td>144840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-10-30</th>\n",
       "      <td>0.9540</td>\n",
       "      <td>0.9610</td>\n",
       "      <td>0.9235</td>\n",
       "      <td>0.9425</td>\n",
       "      <td>137776000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-10-31</th>\n",
       "      <td>0.9680</td>\n",
       "      <td>0.9740</td>\n",
       "      <td>0.9425</td>\n",
       "      <td>0.9515</td>\n",
       "      <td>136452000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-11-01</th>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>0.9610</td>\n",
       "      <td>110988000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-11-04</th>\n",
       "      <td>0.9390</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>0.9295</td>\n",
       "      <td>0.9695</td>\n",
       "      <td>259270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-10-22</th>\n",
       "      <td>2.7015</td>\n",
       "      <td>2.8075</td>\n",
       "      <td>2.6865</td>\n",
       "      <td>2.8025</td>\n",
       "      <td>654038000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-10-23</th>\n",
       "      <td>2.7160</td>\n",
       "      <td>2.7260</td>\n",
       "      <td>2.6455</td>\n",
       "      <td>2.6490</td>\n",
       "      <td>292234000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-10-24</th>\n",
       "      <td>2.7255</td>\n",
       "      <td>2.7470</td>\n",
       "      <td>2.6500</td>\n",
       "      <td>2.7275</td>\n",
       "      <td>208764000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-10-27</th>\n",
       "      <td>2.7410</td>\n",
       "      <td>2.7625</td>\n",
       "      <td>2.7250</td>\n",
       "      <td>2.7450</td>\n",
       "      <td>127838000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-10-28</th>\n",
       "      <td>2.8365</td>\n",
       "      <td>2.8450</td>\n",
       "      <td>2.7275</td>\n",
       "      <td>2.7595</td>\n",
       "      <td>184618000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Close    High     Low    Open     Volume\n",
       "Date                                                 \n",
       "2002-10-29  0.9285  0.9460  0.9035  0.9255  144840000\n",
       "2002-10-30  0.9540  0.9610  0.9235  0.9425  137776000\n",
       "2002-10-31  0.9680  0.9740  0.9425  0.9515  136452000\n",
       "2002-11-01  0.9900  0.9950  0.9545  0.9610  110988000\n",
       "2002-11-04  0.9390  0.9905  0.9295  0.9695  259270000\n",
       "...            ...     ...     ...     ...        ...\n",
       "2003-10-22  2.7015  2.8075  2.6865  2.8025  654038000\n",
       "2003-10-23  2.7160  2.7260  2.6455  2.6490  292234000\n",
       "2003-10-24  2.7255  2.7470  2.6500  2.7275  208764000\n",
       "2003-10-27  2.7410  2.7625  2.7250  2.7450  127838000\n",
       "2003-10-28  2.8365  2.8450  2.7275  2.7595  184618000\n",
       "\n",
       "[252 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from core.data_repository import DataRepository\n",
    "from pathlib import Path\n",
    "\n",
    "data_repository = DataRepository(repo_path=Path('repo'))\n",
    "AMZN_periodic_data = data_repository.get_dataframes()['AMZN']\n",
    "\n",
    "AMZN_periodic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89fb09ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m 2025-09-04 23:09:39 - data_preparator - INFO - Preparing data for target column: Close, with t=5\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Close_0</th>\n",
       "      <th>Close_1</th>\n",
       "      <th>Close_2</th>\n",
       "      <th>Close_3</th>\n",
       "      <th>Close_4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-11-05</th>\n",
       "      <td>0.9360</td>\n",
       "      <td>0.9390</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>0.9285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-11-06</th>\n",
       "      <td>0.9670</td>\n",
       "      <td>0.9360</td>\n",
       "      <td>0.9390</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>0.9540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-11-07</th>\n",
       "      <td>0.9560</td>\n",
       "      <td>0.9670</td>\n",
       "      <td>0.9360</td>\n",
       "      <td>0.9390</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.9680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-11-08</th>\n",
       "      <td>0.9755</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>0.9670</td>\n",
       "      <td>0.9360</td>\n",
       "      <td>0.9390</td>\n",
       "      <td>0.9900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-11-11</th>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>0.9670</td>\n",
       "      <td>0.9360</td>\n",
       "      <td>0.9390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-10-22</th>\n",
       "      <td>2.7015</td>\n",
       "      <td>2.9675</td>\n",
       "      <td>2.9795</td>\n",
       "      <td>2.9845</td>\n",
       "      <td>2.9955</td>\n",
       "      <td>2.9275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-10-23</th>\n",
       "      <td>2.7160</td>\n",
       "      <td>2.7015</td>\n",
       "      <td>2.9675</td>\n",
       "      <td>2.9795</td>\n",
       "      <td>2.9845</td>\n",
       "      <td>2.9955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-10-24</th>\n",
       "      <td>2.7255</td>\n",
       "      <td>2.7160</td>\n",
       "      <td>2.7015</td>\n",
       "      <td>2.9675</td>\n",
       "      <td>2.9795</td>\n",
       "      <td>2.9845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-10-27</th>\n",
       "      <td>2.7410</td>\n",
       "      <td>2.7255</td>\n",
       "      <td>2.7160</td>\n",
       "      <td>2.7015</td>\n",
       "      <td>2.9675</td>\n",
       "      <td>2.9795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-10-28</th>\n",
       "      <td>2.8365</td>\n",
       "      <td>2.7410</td>\n",
       "      <td>2.7255</td>\n",
       "      <td>2.7160</td>\n",
       "      <td>2.7015</td>\n",
       "      <td>2.9675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Close  Close_0  Close_1  Close_2  Close_3  Close_4\n",
       "Date                                                           \n",
       "2002-11-05  0.9360   0.9390   0.9900   0.9680   0.9540   0.9285\n",
       "2002-11-06  0.9670   0.9360   0.9390   0.9900   0.9680   0.9540\n",
       "2002-11-07  0.9560   0.9670   0.9360   0.9390   0.9900   0.9680\n",
       "2002-11-08  0.9755   0.9560   0.9670   0.9360   0.9390   0.9900\n",
       "2002-11-11  0.9500   0.9755   0.9560   0.9670   0.9360   0.9390\n",
       "...            ...      ...      ...      ...      ...      ...\n",
       "2003-10-22  2.7015   2.9675   2.9795   2.9845   2.9955   2.9275\n",
       "2003-10-23  2.7160   2.7015   2.9675   2.9795   2.9845   2.9955\n",
       "2003-10-24  2.7255   2.7160   2.7015   2.9675   2.9795   2.9845\n",
       "2003-10-27  2.7410   2.7255   2.7160   2.7015   2.9675   2.9795\n",
       "2003-10-28  2.8365   2.7410   2.7255   2.7160   2.7015   2.9675\n",
       "\n",
       "[247 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from core.data_preparator import DataPreparator\n",
    "\n",
    "AMZN_supervised_data = DataPreparator.reformat_periodic_to_supervised_data(\n",
    "    dataframe=AMZN_periodic_data,\n",
    "    target_column='Close',\n",
    "    t=5\n",
    ")\n",
    "\n",
    "AMZN_supervised_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a4435c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m 2025-09-04 23:09:41 - dataset - INFO - Created stock dataset for AMZN, focusing target: Close\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close_0</th>\n",
       "      <th>Close_1</th>\n",
       "      <th>Close_2</th>\n",
       "      <th>Close_3</th>\n",
       "      <th>Close_4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-11-05</th>\n",
       "      <td>0.9390</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>0.9285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-11-06</th>\n",
       "      <td>0.9360</td>\n",
       "      <td>0.9390</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>0.9540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-11-07</th>\n",
       "      <td>0.9670</td>\n",
       "      <td>0.9360</td>\n",
       "      <td>0.9390</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.9680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-11-08</th>\n",
       "      <td>0.9560</td>\n",
       "      <td>0.9670</td>\n",
       "      <td>0.9360</td>\n",
       "      <td>0.9390</td>\n",
       "      <td>0.9900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-11-11</th>\n",
       "      <td>0.9755</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>0.9670</td>\n",
       "      <td>0.9360</td>\n",
       "      <td>0.9390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-10-22</th>\n",
       "      <td>2.9675</td>\n",
       "      <td>2.9795</td>\n",
       "      <td>2.9845</td>\n",
       "      <td>2.9955</td>\n",
       "      <td>2.9275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-10-23</th>\n",
       "      <td>2.7015</td>\n",
       "      <td>2.9675</td>\n",
       "      <td>2.9795</td>\n",
       "      <td>2.9845</td>\n",
       "      <td>2.9955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-10-24</th>\n",
       "      <td>2.7160</td>\n",
       "      <td>2.7015</td>\n",
       "      <td>2.9675</td>\n",
       "      <td>2.9795</td>\n",
       "      <td>2.9845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-10-27</th>\n",
       "      <td>2.7255</td>\n",
       "      <td>2.7160</td>\n",
       "      <td>2.7015</td>\n",
       "      <td>2.9675</td>\n",
       "      <td>2.9795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-10-28</th>\n",
       "      <td>2.7410</td>\n",
       "      <td>2.7255</td>\n",
       "      <td>2.7160</td>\n",
       "      <td>2.7015</td>\n",
       "      <td>2.9675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Close_0  Close_1  Close_2  Close_3  Close_4\n",
       "Date                                                   \n",
       "2002-11-05   0.9390   0.9900   0.9680   0.9540   0.9285\n",
       "2002-11-06   0.9360   0.9390   0.9900   0.9680   0.9540\n",
       "2002-11-07   0.9670   0.9360   0.9390   0.9900   0.9680\n",
       "2002-11-08   0.9560   0.9670   0.9360   0.9390   0.9900\n",
       "2002-11-11   0.9755   0.9560   0.9670   0.9360   0.9390\n",
       "...             ...      ...      ...      ...      ...\n",
       "2003-10-22   2.9675   2.9795   2.9845   2.9955   2.9275\n",
       "2003-10-23   2.7015   2.9675   2.9795   2.9845   2.9955\n",
       "2003-10-24   2.7160   2.7015   2.9675   2.9795   2.9845\n",
       "2003-10-27   2.7255   2.7160   2.7015   2.9675   2.9795\n",
       "2003-10-28   2.7410   2.7255   2.7160   2.7015   2.9675\n",
       "\n",
       "[247 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2002-11-05    0.9360\n",
       "2002-11-06    0.9670\n",
       "2002-11-07    0.9560\n",
       "2002-11-08    0.9755\n",
       "2002-11-11    0.9500\n",
       "               ...  \n",
       "2003-10-22    2.7015\n",
       "2003-10-23    2.7160\n",
       "2003-10-24    2.7255\n",
       "2003-10-27    2.7410\n",
       "2003-10-28    2.8365\n",
       "Name: Close, Length: 247, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(247, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(247,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from core.dataset import StockDataset\n",
    "\n",
    "AMZN_dataset = StockDataset(\n",
    "    data=AMZN_supervised_data,\n",
    "    ticker='AMZN',\n",
    "    target_column='Close'\n",
    ")\n",
    "\n",
    "display(AMZN_dataset.X, AMZN_dataset.y, AMZN_dataset.X.shape, AMZN_dataset.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a57141c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m 2025-09-04 23:09:41 - model - INFO - Model(id=base_amzn_model, ticker=('AMZN',), input_dimension=5)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from models.base_model import BaseStockModel\n",
    "\n",
    "AMZN_base_model = BaseStockModel(\n",
    "    id='base_amzn_model',\n",
    "    ticker='AMZN',\n",
    "    input_dim=AMZN_dataset.X.shape[1],\n",
    "    hidden_dim=10,\n",
    "    layer_dim=2,\n",
    "    output_dim=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f3b3691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "optimizer = Adam(AMZN_base_model.parameters(), lr=0.001)\n",
    "loss_function = MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabe50cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 5]) torch.Size([16])\n",
      "\u001b[37m 2025-09-04 23:09:43 - model - DEBUG - Forward pass with input shape: torch.Size([16, 5]), h0 shape: torch.Size([2, 5, 10]), c0 shape: torch.Size([2, 5, 10])\u001b[0m\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "For unbatched 2-D input, hx and cx should also be 2-D but got (3-D, 3-D) tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m optimizer.zero_grad()\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(X.shape, y.shape)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m outputs = \u001b[43mAMZN_base_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m loss = loss_function(outputs, y)\n\u001b[32m     13\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/kalman_stock_prediction/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/kalman_stock_prediction/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/kalman_stock_prediction/src/app/models/base_model.py:31\u001b[39m, in \u001b[36mBaseStockModel.forward\u001b[39m\u001b[34m(self, x, h0, c0)\u001b[39m\n\u001b[32m     29\u001b[39m     c0 = torch.zeros(\u001b[38;5;28mself\u001b[39m.layer_dim, \u001b[38;5;28mself\u001b[39m.input_dim, \u001b[38;5;28mself\u001b[39m.hidden_dim)\n\u001b[32m     30\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mForward pass with input shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, h0 shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh0.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, c0 shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc0.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m out, (hn, cn) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlstm_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mLSTM output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     33\u001b[39m out = \u001b[38;5;28mself\u001b[39m.output_layer(out[:, -\u001b[32m1\u001b[39m, :])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/kalman_stock_prediction/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/kalman_stock_prediction/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/kalman_stock_prediction/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1116\u001b[39m, in \u001b[36mLSTM.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m hx[\u001b[32m0\u001b[39m].dim() != \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m hx[\u001b[32m1\u001b[39m].dim() != \u001b[32m2\u001b[39m:\n\u001b[32m   1112\u001b[39m         msg = (\n\u001b[32m   1113\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFor unbatched 2-D input, hx and cx should \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1114\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33malso be 2-D but got (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx[\u001b[32m0\u001b[39m].dim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-D, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx[\u001b[32m1\u001b[39m].dim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-D) tensors\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1115\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1116\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[32m   1117\u001b[39m     hx = (hx[\u001b[32m0\u001b[39m].unsqueeze(\u001b[32m1\u001b[39m), hx[\u001b[32m1\u001b[39m].unsqueeze(\u001b[32m1\u001b[39m))\n\u001b[32m   1118\u001b[39m \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[32m   1119\u001b[39m \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: For unbatched 2-D input, hx and cx should also be 2-D but got (3-D, 3-D) tensors"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "AMZN_dataloader = DataLoader(AMZN_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for X,y in AMZN_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        print(X.shape, y.shape)\n",
    "        outputs = AMZN_base_model(X)\n",
    "        loss = loss_function(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kalman_stock_prediction (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
