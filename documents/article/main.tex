\documentclass[12pt]{article}

%~ Packages
\usepackage{amsmath}   % For math
\usepackage{graphicx}  % For images
\usepackage{float}     % For stronger figure placement
\usepackage{hyperref}  % For links
\usepackage[T1]{fontenc}
\usepackage{geometry} % For margins
\usepackage[utf8]{inputenc} % Polish characters
\usepackage[polish]{babel} % Polish language support
\usepackage{times} % Use Times font
\usepackage{indentfirst} % Indent first paragraph after section
\usepackage{titlesec} % Customize section titles

%~ Document settings
\geometry{a4paper, margin=2.5cm}
% \renewcommand{\familydefault}{\sfdefault} % Switched to Times

% Adjust justification to prevent overfull boxes without hyphenation
\tolerance=1000
\emergencystretch=\maxdimen
\hyphenpenalty=10000
\hbadness=10000

%~ Section formatting
\titleformat{\section}{\Large\bfseries}{\thesection.}{1em}{}
\titleformat{\subsection}{\large\bfseries}{\thesubsection.}{1em}{}


%~ Document
\begin{document}

%~ Main Page
\begin{titlepage}
    \centering
    
    \includegraphics[width=0.4\textwidth]{/home/emdablju/Documents/projects/kalman_stock_prediction/documents/article/assets/PJATK_PL_sygnet.png}

    {\Large Polsko-Japońska Akademia Technik Komputerowych}
    
    \vspace{0.5cm}
    
    {\large Wydział Informatyki}
    
    \vspace{2cm}
    
    {\huge\bfseries Zastosowanie filtrów Kalmana do poprawy predykcji cen giełdowych przy użyciu sieci LSTM}
    
    \vspace{2cm}
    
    {\Large Praca Dyplomowa}
    
    \vspace{2cm}
    
    \begin{flushleft}
    \begin{tabular}{ll}
        \textbf{Autor:} & Mikołaj Warda (s28034) \\
        \textbf{Kierunek studiów:} & Informatyka \\
        \textbf{Specjalizacja:} & Data Science \\
        \textbf{Promotor:} & dr Sinh Hoa Nguyen Thi \\
    \end{tabular}
    \end{flushleft}
    
    \vfill
    
    {\large \today}
    
\end{titlepage}

%~ Table of Contents
\tableofcontents
\clearpage

%~ Abstract
\begin{abstract}
    
\end{abstract}
\clearpage

%~ Introduction
\section{Wstęp}

Prognozowanie cen akcji odgrywa kluczową rolę w finansach, wspierając inwestorów w podejmowaniu świadomych decyzji zarządzania swoim portfolio.
Chaotyczny charakter rynków sprawia jednak, że trafne przewidywanie notowań pozostaje trudnym zadaniem.
Tradycyjna analiza techniczna bywa niewystarczająca - jest wrażliwa na szum, a wnioski często zawierają element subiektywności \cite{TODO_general_finanse_predicting}.

W ostatnich latach dynamiczny rozwój uczenia maszynowego, zwłaszcza sieci neuronowych, 
znacząco zmienił podejście do modelowania danych czasowych (w tym giełdowych).
Architektury takie jak LSTM (Long Short-Term Memory) potrafią uchwycić złożone zależności i długookresowe relacje w danych, 
co czyni je obiecującymi narzędziami do prognozowania cen \cite{TODO_LSTM_paper}.
Niemniej jednak ich skuteczność nadal zależy od jakości danych wejściowych.
Głównym problemem, jest wysoka wrażliwość na losowe wahania, które są nieodłącznym elementem danych finansowych. 
Te zniekształcenia wynikają z nieprzewidywalnych zdarzeń rynkowych.
Model, zamiast uczyć się rzeczywistych trendów, modeluje wspomniane zakłócenia, 
obniżając swoją zdolność do generalizacji na nowych danych. 
W rezultacie, predykcje mogą być obarczone znacznym błędem, 
co podważa ich użyteczność w podejmowaniu decyzji inwestycyjnych \cite{TODO_LSTM_problem}.

Można temu zapobiegać stosując techniki filtracji na danych wejściowych.
Jednym z klasycznych narzędzi tego typu jest filtr Kalmana,
który może pełnić rolę modułu wygładzania i korekty obserwacji, podnosząc stabilność i dokładność predykcji.
Trenowanie sieci neuronowej na przefiltrowanych danych przy użyciu filtra Kalmana może zredukować wpływ szumu, 
pozwalając na lepsze uchwycenie istotnych wzorców i trendów w danych \cite{TODO_KalmanFilter_paper, TODO_FilteringInfluenceOnLearning}.

W ramach niniejszej pracy dyplomowej, podjęto się zbadania skuteczności zastosowania filtru Kalmana jako etapu przetwarzania danych dla modeli LSTM w kontekście prognozowania cen akcji spółki Amazon.com Inc (AMZN) .
Wybór tematu pracy wyniknął z chęci zdobycia wiedzy na temat działania architektury LSTM oraz zbadania wpływu filtracji danych na jakość prognoz.
Dodatkową motywacją była możliwość wszechstronnego rozwoju ze względu na złożony charakter problemu, łączącego zagadnienia z dziedziny uczenia maszynowego, analizy szeregów czasowych oraz teorii filtrów.

W dalszej części pracy, w sekcji \textit{"Podstawy teoretyczne"}, przedstawiono wszelkie niezbędne pojęcia związane z tematem pracy i przebiegiem badań ze szczególnym naciskiem na architekturę sieci LSTM oraz filtr Kalmana.
Następnie, w sekcji \textit{"Metodyka badań"}, opisano podejście badawcze, w tym przygotowanie danych, implementację modelu, metryki oceny oraz wykorzystane narzędzia.
Kolejna sekcja \textit{"Wyniki i dyskusja"} prezentuje uzyskane wyniki eksperymentów wraz z ich analizą i interpretacją.
Na zakończenie, w sekcji \textit{"Podsumowanie i wnioski"}, podsumowano przeprowadzone badania, przedstawiono kluczowe wnioski oraz zasugerowano kierunki dalszych badań w tym obszarze.

%~ Fundamentals
\clearpage
\section{Podstawy teoretyczne}
\subsection{Przewidywanie szeregów czasowych na rynkach finansowych}
Dane finansowe, takie jak np. ceny akcji, zawierają obserwacje tworzące szeregi czasowe.
Innymi słowy, są to dane, które reprezentują zmiany wartości w określonych odstępach czasu.
Formalnie szeregiem czasowym określa się zbiór uporządkowanych obserwacji w czasie, gdzie każda obserwacja jest powiązana z określoną chwilą czasową \cite{TODO_time_series_definition}:
\begin{equation}
    X = \{x_1, x_2, x_3, \ldots, x_n\}
\end{equation}
gdzie \( x_i \) reprezentuje wartość obserwacji w czasie \( t_i \), a \( n \) to liczba obserwacji w szeregu czasowym.

Abstrahując od rynków finansowych, przedstawiono kilka przykładów szeregów czasowych z innych dziedzin, celem lepszego zobrazowania tej koncepcji:
\begin{itemize}
    \item \textbf{Energetyka:} Godzinowe zużycie energii elektrycznej
    \item \textbf{Meteorologia:} Codzienny pomiar temperatury
    \item \textbf{Sport:} Wyniki meczów drużyny na przestrzeni sezonu
\end{itemize}

Najczęściej spotykanym formatem danych finansowych są tzw. dane OHLC.
Przedstawione w takiej postaci informacje tworzą szereg czasowy, w którym każda obserwacja składa się z czterech części \cite{TODO_OHLC_definition}:
\begin{itemize}
    \item \textbf{Open (O):} Cena otwarcia - cena, po której dany instrument finansowy rozpoczął notowania w danym okresie.
    \item \textbf{High (H):} Cena najwyższa - najwyższa cena osiągnięta przez instrument finansowy w danym okresie.
    \item \textbf{Low (L):} Cena najniższa - najniższa cena osiągnięta przez instrument finansowy w danym okresie.
    \item \textbf{Close (C):} Cena zamknięcia - cena, po której instrument finansowy zakończył notowania w danym okresie.
\end{itemize}
Na potrzeby tej pracy, wykorzystano składnik \textit{Close}, ze względu na jego powszechne wykorzystanie w analizie i prognozie cen akcji \cite{TODO_Close_price_usage}.

Rysunek \ref{fig:amzn_stock_prices} przedstawia przykładowy wykres cenowy względem składnika \textit{Close} spółki Amazon.com Inc (AMZN) na przestrzeni kilku lat w odstępach dziennych. 
Dane przedstawione na wykresie są nieregularne i zawierają liczne fluktuacje, co jest charakterystyczne dla danych finansowych.
Ta wysoka zmienność stanowi główne wyzwanie dla modeli predykcyjnych, co motywuje do poszukiwania skutecznych metod filtrujących \cite{TODO_LSTM_problem}.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{/home/emdablju/Documents/projects/kalman_stock_prediction/documents/plots/1_AMZN_stock.png}
    \caption{Wykres cenowy względem składnika \textit{Close} Amazon.com Inc (AMZN) w latach 2022-2025. Źródło danych: Yahoo Finance \cite{TODO_YahooFinance}.}
    \label{fig:amzn_stock_prices}
\end{figure}

Tradycyjnie analiza danych rynkowych opierała się o wskaźniki techniczne. 
Można je określić mianem narzędzi statystycznych reprezentujących różne aspekty zachowań cen \cite{TODO_technical_indicators_paper}.
W niniejszej pracy wykorzystano trzy wskaźniki techniczne, które opisano w następnych podsekcjach.

\subsubsection{Wskaźnik siły względnej (Relative Strength Index, RSI)}
Wskaźnik siły względnej (RSI) to popularny wskaźnik techniczny używany do oceny siły i prędkości zmian cen aktywów finansowych \cite{TODO_RSI_paper}.
Wyraża się go wzorem:
\begin{equation}
    RSI = 100 - \frac{100}{1 + RS}
\end{equation}
gdzie \( RS \) (Relative Strength) to stosunek średnich wzrostów do średnich spadków cen w określonym czasie. Według badań, optymalny okres do obliczania RSI wynosi 14 dni \cite{TODO_RSI_paper}.

Produktem końcowym RSI jest liczba z zakresu od 0 do 100, która interpretowana jest następująco:
\begin{itemize}
    \item Wartości powyżej 70 sugerują, że akcja jest wykupiona i może nastąpić spadek cen.
    \item Wartości poniżej 30 sugerują, że akcja jest wyprzedana i może nastąpić wzrost cen.
    \item Wartości pomiędzy 30 a 70 wskazują na neutralny stan rynku.
\end{itemize}

\subsubsection{Wstęgi Bollingera (Bollinger Bands)}
Wstęgi Bollingera to narzędzie analizy technicznej, dostarczające informacji o zmienności rynku \cite{TODO_bollinger_bands_paper}. 
Składaja się z trzech linii na wykresie cenowym:
\begin{itemize}
    \item \textbf{Środkowa linia:} Prosta średnia krocząca (SMA) obliczona na podstawie cen zamknięcia w określonym czasie. Najczęsciej używanym okresem jest 20 dni.
    \item \textbf{Górna wstęga:} Obliczana jako suma wartości środkowej linii i dwukrotności odchylenia standardowego cen w tym okresie.
    \item \textbf{Dolna wstęga:} Obliczana jako różnica wartości środkowej linii i dwukrotności odchylenia standardowego cen w tym okresie.
\end{itemize}
Na podstawie ww. składowych można zinterpretować dwie nowe miary, które zostały wykorzystane w niniejszej pracy:
\begin{itemize}
    \item \textbf{Bollinger Bandwidth (BBW):} Miara szerokości wstęg Bollingera, obliczana jako stosunek różnicy między górną a dolną wstęgą do środkowej linii \cite{TODO_bollinger_bands_paper}:
    \begin{equation}
        BBW = \frac{Upper Band - Lower Band}{Middle Line}
    \end{equation}
    \item \textbf{Bollinger \%B (BB\%):} Miara położenia ceny względem wstęg Bollingera, obliczana jako stosunek różnicy między ceną zamknięcia a dolną wstęgą do różnicy między górną a dolną wstęgą \cite{TODO_bollinger_bands_paper}:
    \begin{equation}
        BB\% = \frac{Close - Lower Band}{Upper Band - Lower Band}
    \end{equation}
\end{itemize}

Opisane powyżej wskaźniki techniczne - RSI, BBW oraz BB\% - dostarczają cennych informacji o dynamice rynku. 
W tradycyjnej analizie mogą posłużyć do subiektywnej interpretacji przez analityków.
W nowoczesnych podejściach, opartych na modelach uczenia maszynowego, 
można je wykorzystać do wzbogacenia danych o dodatkowe cechy, co potencjalnie może poprawić jakość prognoz \cite{TODO_dataset_enrichment_indicators}.

\subsection{Sieci neuronowe w prognozowaniu rynków finansowych}

Wraz z rozwojem mocy obliczeniowej i technik uczenia maszynowego, pojawiły się bardziej zaawansowane metody analizy i prognozowania w dziedzinie finansów \cite{TODO_better_methods_on_market_predictions}.
Do najpopularniejszych podejść należą sieci rekurencyjne (RNN), w tym ich zaawansowane warianty, takie jak \textit{LSTM} (Long Short-Term Memory).
Sieci te są zdolne do uchwycenia złożonych wzorców i zależności w szeregach czasowych \cite{TODO_RNN_paper, TODO_LSTM_paper}.

W niniejszej sekcji zostały omówione podstawy działania sieci neuronowych. 
Przedstawiona została budowa pojedynczego neuronu wchodzącego w skład sieci, kluczowe algorytmy uczenia oraz architektura LSTM.

\subsubsection{Podstawy działania sztucznego neuronu}
Ważnym kamieniem milowym w dziedzinie uczenia maszynowego było wprowadzenie matematycznego modelu neuronu przez McCullocha i Pitts'a w 1943 roku \cite{TODO_neuron_McCulloch_Pitts}.
Współcześnie można mówić o różnych architekturach takiego neuronu, jednak ich podstawowa zasada działania pozostaje podobna.

Neuron otrzymuje na wejściu sygnały \( x_1, x_2, \ldots, x_n \), które są ważone przez odpowiednie wagi \( w_1, w_2, \ldots, w_n \).
Następnie, sumuje te ważone sygnały i dodaje do nich wartość obciążenia (bias) \( b \) \cite{TODO_how_neurons_process_signals}:
\begin{equation}
    z = \sum_{i=1}^{n} w_i x_i + b
\end{equation}

Otrzymana wartość \( z \), zwana logitem (surowym wyjściem) neuronu, jest następnie przekształcana przez funkcję aktywacji \( f(z) \) \cite{TODO_how_neurons_process_signals}:
\begin{equation}
    \hat{y} = f(z) = f(\sum_{i=1}^{n} w_i x_i + b)
\end{equation}

Funkcja aktywacji modyfikuje logit \( z \), produkując finalne wyjście neuronu \( \hat{y} \) -- stopień aktywacji.
W zależności od zastosowanej funkcji aktywacji, wyjście może przyjmować różne formy \cite{TODO_activation_function_overview}.
Tą różnicę najprościej zilustrować na przykładzie dwóch popularnych funkcji aktywacji:
\begin{itemize}
    \item \textbf{Funkcja skokowa:}
    \begin{equation}
        f(z) = 
        \begin{cases}
            1 & \text{jeśli } z \geq 0 \\
            0 & \text{jeśli } z < 0
        \end{cases}
    \end{equation}
    W tym przypadku, wyjście neuronu jest binarne. 
    Innymi słowy, neuron zostanie albo aktywowany (1), albo nieaktywowany (0), w zależności od tego, czy logit \( z \) przekracza pewien próg (w tym przypadku 0) \cite{TODO_step_function_overview}.
    \item \textbf{Funkcja sigmoidalna:}
    \begin{equation}
        f(z) = \frac{1}{1 + e^{-z}}
    \end{equation}
    W tym przypadku, wyjście neuronu jest ciągłe i mieści się w zakresie od 0 do 1.
    Oznacza to, że neuron może przyjmować różne poziomy aktywacji, co pozwala na wyrażenie stopnia pewności co do wyniku \cite{TODO_sigmoid_function_overview}.
\end{itemize}
Rysunek \ref{fig:step_sigmoid_comparison} przedstawia porównanie ww. funkcji aktywacji.
Po lewej stronie znajduje się wykres funkcji skokowej, gdzie wyjście nagle zmienia się z 0 na 1 w punkcie \( z=0 \).
Po prawej stronie znajduje się wykres funkcji sigmoidalnej, gdzie wyjście zmienia się stopniowo od 0 do 1 wraz ze wzrostem wartości \( z \).
\begin{figure}[H]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{assets/step_figure.png}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{assets/sigmoid_figure.png}
    \end{minipage}
    \caption{Porównanie funkcji aktywacji: (po lewej) funkcja skokowa, (po prawej) funkcja sigmoidalna. Opracownanie własne przy użyciu Matplotlib.}
    \label{fig:step_sigmoid_comparison}
\end{figure}
Istnieje wiele innych funkcji aktywacji (np. ReLU, tanh, softmax), a każda z nich ma swoje unikalne właściwości i zastosowania \cite{TODO_activation_function_overview}.
W przypadku funkcji skokowej, neuron podejmuje twardą decyzję, aktywując się w pełni lub wcale.
Przez brak elastyczności, funkcja ta nie pozwala na wyrażenie przekonania co do wyniku \cite{TODO_step_function_overview}.
W przeciwieństwie do niej, funkcja sigmoidalna umożliwia płynną aktywację, pozwalając uwzględnić stopień pewności \cite{TODO_sigmoid_function_overview}.

Znając rolę funkcji aktywacji, można lepiej wyjaśnić działanie parametrów uczonych neuronu, czyli wag \( w_i \) oraz obciążenia \( b \).

Wagi określają, jak duży wpływ ma każdy sygnał wejściowy \( x_i \) na logit \( z \).
Poprzez modelowanie wag, w trakcie procesu uczenia, neuron może nauczyć się, które cechy wejściowe są bardziej istotne dla danego zadania \cite{TODO_weights}.

Rysunek \ref{fig:sigmoid_weights_combined} przedstawia wpływ różnych wartości wagi \( w \) na funkcję sigmoidalną w neuronie z jednym wejściem i bez obciążenia.
Po lewej stronie znajduje się wykres dla małej wagi \( w=0.1 \), gdzie funkcja zmienia się powoli i ma łagodne nachylenie.
Po prawej stronie znajduje się wykres dla dużej wagi \( w=2.0 \), gdzie funkcja zmienia się gwałtownie i ma strome nachylenie.
Można zaobserwować, że wraz ze wzrostem wartości wagi, funkcja sigmoidalna zaczyna przypominać funkcję skokową.
Oznacza to, że neuron staje się pewniejszy swoich decyzji, aktywując się niemal natychmiast po przekroczeniu progu.

\begin{figure}[H]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{assets/sigmoid_w_min_figure.png}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{assets/sigmoid_w_max_figure.png}
    \end{minipage}
    \caption{Wpływ wartości wagi (w) na kształt funkcji sigmoidalnej: (po lewej) \(w=0.1\), (po prawej) \(w=2.0\). Opracowanie własne przy użyciu Matplotlib.}
    \label{fig:sigmoid_weights_combined}
\end{figure}

Drugim kluczowym parametrem jest obciążenie, czyli bias \( b \), który przesuwa próg funkcji aktywacji wzdłuż osi poziomej.
W istocie umożliwia to opóźnienie lub przyspieszenie momentu, w którym neuron zostaje aktywowany \cite{TODO_bias}.

Rysunek \ref{fig:sigmoid_bias_combined} przedstawia wpływ różnych wartości biasu \( b \) na kształt funkcji sigmoidalnej w neuronie z jednym wejściem i wagą \( w=0.1 \).
\begin{figure}[H]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{assets/sigmoid_b_min_figure.png}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{assets/sigmoid_b_max_figure.png}
    \end{minipage}
    \caption{Wpływ wartości bias (b) na kształt funkcji sigmoidalnej: (po lewej) \(b=-2.82\), (po prawej) \(b=4.21\).}
    \label{fig:sigmoid_bias_combined}
\end{figure}

Opisane powyżej parametry -- wagi \( w_i \), obciążenie \( b \) oraz funkcja aktywacji \( f(z) \) - stanowią podstawę działania sztucznego neuronu \cite{TODO_weights_bias_importance}.

Rysunek \ref{fig:neuron_architecture} podsumowuje budowę sztucznego neuronu, ilustrując jak sygnały wejściowe są przetwarzane przez wagę, sumowane z obciążeniem i przekształcane przez funkcję aktywacji.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/neuron.png}
    % Andrut, Krzysztof Zajączkowski, \href{https://commons.wikimedia.org/wiki/File:Neuron_McCullocha-Pittsa.svg}{Wikimedia Commons}, licencja \href{https://creativecommons.org/licenses/by-sa/2.5/deed.pl}{CC BY-SA 2.5}.
    \caption[Schemat budowy sztucznego neuronu]{Schemat budowy sztucznego neuronu. Źródło: \cite{wikimedia_neuron_mcculloch_pitts}}
    \label{fig:neuron_architecture}
\end{figure}

Niestety pojedyczny neuron jest ograniczony w swoich możliwościach -- może nauczyć się jedynie prostych zależności liniowo-separowalnych.
Inaczej mówiąc, jest w stanie rozróżnić tylko te wzorce, które można oddzielić prostą linią w przestrzeni cech.
Aby radzić sobie z bardziej złożonymi problemami, konieczne jest łączenie wielu neuronów w wielowarstwowe struktury \cite{TODO_single_neuron_limitations}.

\subsubsection{Architektura sieci neuronowej}

W celu modelowania bardziej złożonych zależności, łączy się wiele neuronów w struktury zwane sieciami neuronowymi.
Składają się one z warstw, gdzie każda warstwa zawiera wiele neuronów.
Typowa sieć neuronowa składa się z trzech głównych typów warstw \cite{TODO_nn}:
\begin{enumerate}
    \item \textbf{Warstwa wejściowa:} Odpowiada za przyjmowanie danych wejściowych.
    \item \textbf{Warstwy ukryte:} Przetwarzają dane poprzez zestaw neuronów, ucząc się złożonych wzorców.
    \item \textbf{Warstwa wyjściowa:} Generuje ostateczne prognozy lub klasyfikacje na podstawie przetworzonych danych.
\end{enumerate}
Warstwy można łączyć na różne sposoby, np. poprzez pełne łączenie, konwolucje czy rekurencje \cite{TODO_alternative_ways_connecting_layers}.
W przypadku pełnego łączenia tworzy się połączenia każdego neuronu z jednej warstwy do każdego neuronu w następnej warstwie \cite{TODO_dense_layer}.
Przepływ sygnału w takiej sieci odbywa się na zasadzie propagacji w przód (ang. forward propagation) -- od warstwy wejściowej, przez warstwy ukryte, aż do warstwy wyjściowej.
\clearpage
Formalnie ten proces można opisać krokami obliczeniowymi dla każdej warstwy \cite{TODO_forward_propagation}:
\begin{enumerate}
    \item \textbf{Warstwa wejściowa:}
    \begin{equation}
        \mathbf{a}^{(0)} = \mathbf{x}
    \end{equation}
    \item \textbf{Warstwy ukryte:}
    \begin{equation}
        \mathbf{a}^{(l)} = f(\mathbf{W}^{(l)} \mathbf{a}^{(l-1)} + \mathbf{b}^{(l)}) \quad \text{dla } l = 1, 2, \ldots, L-1
    \end{equation}
    \item \textbf{Warstwa wyjściowa:}
    \begin{equation}
        \mathbf{\hat{y}} = g(\mathbf{W}^{(L)} \mathbf{a}^{(L-1)} + \mathbf{b}^{(L)})
    \end{equation}
    gdzie:
    \begin{itemize}
        \item \( \mathbf{x} \) to wektor danych wejściowych,
        \item \( \mathbf{\hat{y}} \) to wektor danych wyjściowych (prognoz),
        \item \( \mathbf{a}^{(l)} \) to aktywacje (wyjścia) warstwy \( l \),
        \item \( \mathbf{W}^{(l)} \) to macierz wag warstwy \( l \),
        \item \( \mathbf{b}^{(l)} \) to wektor obciążeń warstwy \( l \),
        \item \( f \) to funkcja aktywacji dla warstw ukrytych,
        \item \( g \) to funkcja aktywacji dla warstwy wyjściowej,
        \item \( L \) to liczba warstw w sieci.
    \end{itemize}
\end{enumerate}

Rysunek \ref{fig:nn_architecture} przedstawia schematyczną budowę prostej sieci neuronowej z jedną warstwą wejściową, dwiema warstwami ukrytymi i jedną warstwą wyjściową.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/nn.png}
    \caption{Budowa prostej sieci neuronowej z jedną warstwą wejściową, dwiema warstwami ukrytymi i jedną warstwą wyjściową. Opracowanie własne na podstawie \href{https://media.geeksforgeeks.org/wp-content/uploads/20250923121847731542/Neural-Networks-Architecture.webp}{GeeksforGeeks}.}
    \label{fig:nn_architecture}
\end{figure}

Przedstawiona architektura oraz proces propagacji w przód definiują przepływ informacji w sieci neuronowej w celu generowania prognoz \cite{TODO_nn, TODO_forward_propagation}.
Jednakże aby prognoza była trafna, parametry sieci -- wartości wag \( \mathbf{W}^{(l)} \) oraz obciążeń \( \mathbf{b}^{(l)} \) -- muszą zostać odpowiednio dobrane \cite{TODO_weights_bias_importance}.
Ten proces nazywany jest uczeniem sieci i zostanie omówiony w następnej podsekcji.

\subsubsection{Uczenie sieci neuronowej}
Uczenie sieci neuronowej polega na algorytmicznym dostosowywaniu jej parametrów (wag i obciążeń) w celu minimalizacji błędu prognoz.
Działa ono w oparciu o zestaw danych zawierających zarówno dane wejściowe \( \mathbf{x} \), jak i odpowiadające im rzeczywiste wartości wyjściowe \( \mathbf{y} \).
Innymi słowy, sieć uczy się na podstawie przykładów, aby poprawić swoje prognozy \cite{TODO_nn_modelling}.

Aby proces uczenia zwracał rzetelne wyniki, zestaw danych dzieli się na trzy niezależne podzbiory \cite{TODO_dataset_split}:
\begin{itemize}
    \item \textbf{Zbiór treningowy:} Służy do uczenia sieci poprzez dostosowywanie jej parametrów \cite{TODO_train_dataset}.
    \item \textbf{Zbiór walidacyjny:} Używany do monitorowania wydajności sieci podczas treningu i dostrajania hiperparametrów \cite{TODO_valid_dataset}.
    \item \textbf{Zbiór testowy:} Służy do oceny ostatecznej wydajności sieci na niewidzianych wcześniej danych \cite{TODO_test_dataset}.
\end{itemize}

Sam proces dostosowywania parametrów sieci przeprowadzany jest na zbiorze treningowym i można go opisać w kilku kluczowych krokach \cite{TODO_nn_modelling}:

\begin{enumerate}

    \item \textbf{Inicjalizacja:} Na początku, wagi \( \mathbf{W}^{(l)} \) oraz obciążenia \( \mathbf{b}^{(l)} \) są inicjalizowane małymi, losowymi wartościami \cite{TODO_weights_bias_init}.

    \item \textbf{Propagacja w przód:} Dane wejściowe \( \mathbf{x} \) są przekazywane przez sieć, generując prognozy \( \mathbf{\hat{y}} \) \cite{TODO_forward_propagation}.

    \item \textbf{Obliczanie błędu:} Prognoza modelu \( \mathbf{\hat{y}} \) jest porównywana z rzeczywistą wartością \( \mathbf{y} \) za pomocą funkcji kosztu (np. MSE), co pozwala na zmierzenie błędu prognozy \cite{TODO_measuring_loss}:
    \begin{equation}
        L = \frac{1}{n} \sum_{i=1}^{n} (\hat{y}_i - y_i)^2
    \end{equation}
    gdzie \( L \) to wartość funkcji kosztu MSE, a \( n \) to liczba próbek w zbiorze treningowym.

    \item \textbf{Propagacja wsteczna błędu:} Obliczony błąd jest propagowany wstecz sieci, od warstwy wyjściowej do wejściowej. 
    Celem tego kroku jest obliczenie gradientów funkcji kosztu w każdym neuronie sieci.
    Gradienty te wskazują kierunek i wielkość zmian, które należy wprowadzić w parametrach sieci, aby skutecznie minimalizować błąd prognozy.
    Formalnie gradient jest pochodną funkcji kosztu względem wag lub obciążeń \cite{TODO_backward_propagation}:
    \begin{equation}
        \frac{\partial L}{\partial \mathbf{W}^{(l)}}, \quad \frac{\partial L}{\partial \mathbf{b}^{(l)}}
    \end{equation}

    \item \textbf{Aktualizacja parametrów:} Wagi i obciążenia są aktualizowane za pomocą algorytmu optymalizacji (np. Stochastic Gradient Descent, Adam), wykorzystując obliczone gradienty \cite{TODO_weights_bias_update}:
    \begin{equation}
        \mathbf{W}^{(l)} \leftarrow \mathbf{W}^{(l)} - \eta \frac{\partial L}{\partial \mathbf{W}^{(l)}}, \quad
        \mathbf{b}^{(l)} \leftarrow \mathbf{b}^{(l)} - \eta \frac{\partial L}{\partial \mathbf{b}^{(l)}}
    \end{equation}
    gdzie \( \eta \) to współczynnik nauki (learning rate), określający wielkość kroków aktualizacji.

\end{enumerate}

Proces ten jest powtarzany przez wiele iteracji (epok) na całym zbiorze treningowym, aż do osiągnięcia zadowalającej dokładności prognoz lub spełnienia kryteriów zatrzymania (np. minimalny błąd na zbiorze walidacyjnym).
Wynikowo sieć neuronowa uczy się optymalnych wartości wag i obciążeń, co pozwala jej na generowanie trafnych prognoz na niewidzianych wcześniej danych \cite{TODO_nn_modelling}.

\subsubsection{Sieci rekurencyjne}
Tradycyjna architekura sieci neuronowej, opisana w poprzednich podsekcjach, zakłada, że dane wejściowe są niezależne od siebie \cite{TODO_nn_independent_inputs}.
W przypadku danych finansowych (szeregi czasowe) takie założenie jest błędne, ponieważ obserwacje są ze sobą powiązane w czasie.
Można sobie to wyobrazić na przykładzie cen akcji, gdzie ceny z kilku poprzednich dni wpływają na cenę w dniu dzisiejszym.
Wówczas pojawia się potrzeba "pamiętania" wcześniejszych informacji podczas przetwarzania bieżących danych.
Sieci rekurencyjne (RNN) zostały zaprojektowane właśnie w tym celu \cite{TODO_time_series_data}.

Podstawowym budulcem sieci RNN jest komórka rekurencyjna, która posiada zdolność do przechowywania stanu ukrytego \( \mathbf{h}_t \) \cite{TODO_RNN_cells}.
Stan ukryty \( \mathbf{h}_t \) jest nośnikiem informacji z poprzednich kroków czasowych \cite{TODO_hidden_state}.
Aby skutecznie taką informację utrwalić, sieci RNN wykorzystują mechanizm rekurencji, gdzie wyjście z poprzedniego kroku czasowego jest wykorzystywane jako dodatkowe wejście do bieżącego kroku \cite{TODO_RNN_recurrence}.

Formalnie, stan ukryty \( \mathbf{h}_t \) w czasie \( t \) jest wektorem obliczanym na podstawie bieżącego wejścia \( \mathbf{x}_t \) oraz poprzedniego stanu ukrytego \( \mathbf{h}_{t-1} \) \cite{TODO_RNN_cells}:
\begin{equation}
    \mathbf{h}_t = f(\mathbf{W}_h \mathbf{h}_{t-1} + \mathbf{W}_x \mathbf{x}_t + \mathbf{b})
\end{equation}
gdzie \( \mathbf{W}_h \) to macierz wag dla stanu ukrytego, \( \mathbf{W}_x \) to macierz wag dla wejścia, \( \mathbf{b} \) to wektor obciążeń, a \( f \) to funkcja aktywacji.

Gdy obliczony zostanie ostatni stan ukryty \( \mathbf{h}_t \), sieć może wygenerować prognozę \( \mathbf{\hat{y}}_t \) na podstawie tego stanu \cite{TODO_RNN_output}:
\begin{equation}
    \mathbf{\hat{y}}_t = g(\mathbf{W}_y \mathbf{h}_t + \mathbf{b}_y)
\end{equation}
gdzie \( \mathbf{W}_y \) to macierz wag dla wyjścia, \( \mathbf{b}_y \) to wektor obciążeń wyjścia, a \( g \) to funkcja aktywacji wyjścia.

Rysunek \ref{fig:rnn_cell} przedstawia schematyczną budowę komórki rekurencyjnej w sieci RNN.
Aby lepiej zobrazować działanie komórki RNN, na rysunku pokazano jej rozwinięcie w czasie.
Stan ukryty \( \mathbf{h}_t \) jest przekazywany z jednego kroku czasowego do następnego.
% Wagi \( \mathbf{W}_h \), \( \mathbf{W}_x \), \( \mathbf{W}_y \) oraz obciążenie \( \mathbf{b} \) są współdzielone przez wszystkie kroki czasowe.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{assets/rnn_cell.png}
    % \href{https://commons.wikimedia.org/wiki/File:Recurrent_neural_network_unfold.svg}{Wikimedia Commons}
    \caption{Budowa komórki rekurencyjnej w sieci RNN. Opracowanie własne na podstawie \cite{wikimedia_rnn_unfold}.}
    \label{fig:rnn_cell}
\end{figure}

Taka architektura stanowi solidny fundament do modelowania szeregów czasowych \cite{TODO_RNN_for_time_series_modelling}.
Niemniej jednak, tradycyjne sieci RNN mają pewne ograniczenia.
Są nimi m.in. problem zanikającego i eksplodującego gradientu podczas procesu uczenia, co utrudnia naukę długoterminowych zależności w danych \cite{TODO_vanishing_gradient, TODO_exploding_gradient}.
Aby wyjaśnić na czym polegają te problemy, należy wrócić do procesu opartego na wstecznej propagacji błędu.

W przypadku sieci RNN, odpowiednikiem algorytmu wstecznej propagacji jest algorytm zwany propagacją wsteczną w czasie (ang. *Backpropagation Through Time, BPTT*).
Tak jak w przypadku klasycznej propagacji wstecznej, BPTT polega na obliczaniu gradientów funkcji kosztu względem wag i obciążeń sieci.
Ze względu na współdzielenie wag w czasie, gradienty są sumowane przez wszystkie kroki czasowe, co daje ostateczny gradient dla każdej wagi \cite{TODO_BPTT}:
\begin{equation}
    \frac{\partial L}{\partial \mathbf{W}_h} = \sum_{t=1}^{T} \frac{\partial L}{\partial \mathbf{h}_t} \frac{\partial \mathbf{h}_t}{\partial \mathbf{W}_h}
\end{equation}
W praktyce, propagacja błędu w czasie wiąże się z wielokrotnym mnożeniem macierzy wag \( \mathbf{W}_h \) odpowiadających za stan ukryty \cite{TODO_repetetive_multiplication_of_weights}:
\begin{equation}
    \frac{\partial L}{\partial \mathbf{h}_t} = \frac{\partial L}{\partial \mathbf{h}_T} \prod_{k=t+1}^{T} \frac{\partial \mathbf{h}_k}{\partial \mathbf{h}_{k-1}}
\end{equation}
To właśnie ten mechanizm prowadzi do dwóch problemów:
\begin{itemize}
    \item \textbf{Problem zanikającego gradientu:} Jeśli wartości w macierzy wag \( \mathbf{W}_h \) są małe (norma macierzy mniejsza od 1), to przy wielokrotnym mnożeniu sygnał błędu (gradient) staje się wykładniczo coraz mniejszy.
    W konsekwencji sieć nie jest w stanie nauczyć się zależności między danymi, które są od siebie odległe w czasie \cite{TODO_vanishing_gradient}.

    \item \textbf{Problem eksplodującego gradientu:} Jest to sytuacja odwrotna. Jeśli wartości w macierzy wag \( \mathbf{W}_h \) są duże (norma macierzy większa od 1), sygnał błędu przy wielokrotnym mnożeniu rośnie wykładniczo, stając się ogromną liczbą.
    Na skutek tego aktualizacje wag stają się tak duże, że proces uczenia staje się niestabilny \cite{TODO_exploding_gradient}.
\end{itemize}

Aby skutecznie radzić sobie z tymi problemami, opracowano zaawansowane architektury sieci rekurencyjnych.
Jedną z najpopularniejszych jest Long Short-Term Memory (LSTM), która zostanie omówiona w następnej podsekcji \cite{TODO_LSTM}.

\subsubsection{Sieci Long Short-Term Memory}
Sieci Long Short-Term Memory (LSTM) zostały zaprojektowane, aby niwelować problemy zanikającego i eksplodującego gradientu występujące w tradycyjnych sieciach RNN \cite{TODO_LSTM}.
Cechę tę osiągnięto poprzez wprowadzenie mechanizmów zwanych bramkami (ang. *gates*) oraz dodatkowego stanu komórki \( \mathbf{C}_t \) \cite{TODO_LSTM_cells}.
Stan komórki \( \mathbf{C}_t \), w odróżnieniu od stanu ukrytego \( \mathbf{h}_t \), jest nośnikiem długoterminowych informacji.
Dzięki temu LSTM mogą efektywnie przechowywać i wykorzystywać informacje z odległych kroków czasowych \cite{TODO_LSTM_long_term_memory}.
Komórka LSTM składa sie z trzech głównych bramek \cite{TODO_LSTM_gates}:
\begin{enumerate}
    \item \textbf{Bramka zapominania (Forget Gate):} Decyduje, które informacje z poprzedniego stanu komórki \( \mathbf{C}_{t-1} \) należy zachować, a które odrzucić.
    \item \textbf{Bramka wejścia (Input Gate):} Określa, które nowe informacje z bieżącego wejścia \( \mathbf{x}_t \) powinny zostać dodane do stanu komórki \( \mathbf{C}_t \).
    \item \textbf{Bramka wyjścia (Output Gate):} Kontroluje, które informacje ze stanu komórki \( \mathbf{C}_t \) zostaną wykorzystane do wygenerowania bieżącego stanu ukrytego \( \mathbf{h}_t \).
\end{enumerate}

Rysunek \ref{fig:lstm_cell} przedstawia schematyczną budowę komórki LSTM wraz z jej trzema bramkami.
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{assets/lstm_cell.png}
    \caption{Budowa komórki LSTM z trzema bramkami: bramką zapominania, bramką wejścia i bramką wyjścia. Opracowanie własne na podstawie \cite{lstm_cell_drawing}.}
    \label{fig:lstm_cell}
\end{figure}

Każda z bramek w komórce LSTM działa na podobnej zasadzie jak tradycyjny neuron, wykorzystując funkcję aktywacji sigmoidalnej do generowania wartości między 0 a 1 \cite{TODO_LSTM_gates}.
Służy to określeniu stopnia przepuszczania informacji przez daną bramkę.
Przepływ informacji w komórce LSTM można opisać następującymi krokami \cite{TODO_LSTM_operations}:
\begin{enumerate}
    \item \textbf{Bramka zapominania:} Oblicza się wartość bramki zapominania \( \mathbf{f}_t \) na podstawie bieżącego wejścia \( \mathbf{x}_t \) oraz poprzedniego stanu ukrytego \( \mathbf{h}_{t-1} \). 
    Otrzymana wartość decyduje, które informacje z poprzedniego stanu komórki \( \mathbf{C}_{t-1} \) należy zachować \cite{TODO_LSTM_forgetting}:
    \begin{equation}
        \mathbf{f}_t = \sigma(\mathbf{W}_f [\mathbf{h}_{t-1}, \mathbf{x}_t] + \mathbf{b}_f)
    \end{equation}
    \begin{equation}
        \mathbf{C}_t = \mathbf{f}_t * \mathbf{C}_{t-1}
    \end{equation}

    \item \textbf{Bramka wejścia:} Oblicza się wartość bramki wejścia \( \mathbf{i}_t \) oraz tworzy się kandydat na nowe informacje \( \tilde{\mathbf{C}}_t \) na podstawie bieżącego wejścia \( \mathbf{x}_t \) oraz poprzedniego stanu ukrytego \( \mathbf{h}_{t-1} \).
    Następnie, przy pomocy nowych informacji aktualizuje się stan komórki \( \mathbf{C}_t \) \cite{TODO_LSTM_input}:
    \begin{equation}
        \mathbf{i}_t = \sigma(\mathbf{W}_i [\mathbf{h}_{t-1}, \mathbf{x}_t] + \mathbf{b}_i)
    \end{equation}
    \begin{equation}
        \tilde{\mathbf{C}}_t = \tanh(\mathbf{W}_C [\mathbf{h}_{t-1}, \mathbf{x}_t] + \mathbf{b}_C)
    \end{equation}
    \begin{equation}
        \mathbf{C}_t = \mathbf{C}_t + \mathbf{i}_t * \tilde{\mathbf{C}}_t
    \end{equation}

    \item \textbf{Bramka wyjścia:} Oblicza się wartość bramki wyjścia \( \mathbf{o}_t \) na podstawie bieżącego wejścia \( \mathbf{x}_t \) oraz poprzedniego stanu ukrytego \( \mathbf{h}_{t-1} \).
    Następnie, generuje się bieżący stan ukryty \( \mathbf{h}_t \) na podstawie zaktualizowanego stanu komórki \( \mathbf{C}_t \) \cite{TODO_LSTM_output}:
    \begin{equation}
        \mathbf{o}_t = \sigma(\mathbf{W}_o [\mathbf{h}_{t-1}, \mathbf{x}_t] + \mathbf{b}_o)
    \end{equation}
    \begin{equation}
        \mathbf{h}_t = \mathbf{o}_t * \tanh(\mathbf{C}_t)
    \end{equation}
    gdzie:
    \begin{itemize}
        \item \( \sigma \) to funkcja aktywacji sigmoidalnej,
        \item \( \tanh \) to funkcja aktywacji tangens hiperboliczny,
        \item \( \mathbf{W}_f, \mathbf{W}_i, \mathbf{W}_C, \mathbf{W}_o \) to macierze wag dla poszczególnych bramek,
        \item \( \mathbf{b}_f, \mathbf{b}_i, \mathbf{b}_C, \mathbf{b}_o \) to wektory obciążeń dla poszczególnych bramek.
    \end{itemize}
\end{enumerate}

Kluczem do skutecznej minimalizacji problemu zanikającego gradientu w LSTM jest mechanizm bramek, który umożliwia selektywne przepuszczanie informacji przez stan komórki \( \mathbf{C}_t \) \cite{TODO_LSTM_vanishing_gradient_solution}.
Zamiast wielokrotnego mnożenia wag, jak ma to miejsce w tradycyjnych RNN, LSTM wykorzystują operacje dodawania do aktualizacji stanu komórki oraz mnożenia do określenia stopnia zachowania informacji.
Dzięki takiej architekturze, gradienty mogą przepływać przez sieć w sposób bardziej kontrolowany, co znacząco ogranicza ryzyko ich zanikania lub eksplodowania i poprawia stabilność procesu uczenia \cite{TODO_LSTM_gradient_flow}.




%~ Research approach
% \section{Metodyka badań}

% %~ Results
% \section{Wyniki i dyskusja}

% %~ Summary
% \section{Podsumowanie i wnioski}

% %~ Bibliography
% \section{Bibliografia}

% %~ List of figures and tables
% \section{Spis rysunków i tabel}

% %~ Attachments
% \section{Załączniki}


\end{document}
