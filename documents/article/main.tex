\documentclass[12pt]{article}

%~ Packages
\usepackage{amsmath}   % For math
\usepackage{graphicx}  % For images
\usepackage{float}     % For stronger figure placement
\usepackage{hyperref}  % For links
\usepackage[T1]{fontenc}
\usepackage{geometry} % For margins
\usepackage[utf8]{inputenc} % Polish characters
\usepackage[polish]{babel} % Polish language support
\usepackage{times} % Use Times font
\usepackage{indentfirst} % Indent first paragraph after section
\usepackage{titlesec} % Customize section titles
\usepackage{float}     % For stronger figure placement
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{setspace}

%~ Document settings
\geometry{a4paper, margin=2.5cm}
\onehalfspacing

\tolerance=1000
\emergencystretch=\maxdimen
\hyphenpenalty=10000
\hbadness=10000

%~ Section formatting
\titleformat{\section}{\Large\bfseries}{\thesection.}{1em}{}
\titleformat{\subsection}{\large\bfseries}{\thesubsection.}{1em}{}


%~ Document
\begin{document}


%~ Main Page (Polish)
\begin{titlepage}
    \centering
    
    % University Logo and Name as a single image
    \includegraphics[width=1\textwidth]{assets/PJATK_PL_poziom_2.png}
    
    
    {\large\bfseries Wydział Informatyki}
    
    \vspace{0.5cm}
    
    {\large\bfseries Katedra Systemy Inteligentne i Data Science} % <--- UZUPEŁNIJ
    
    \vspace{0.2cm}

    {\large Inteligentne przetwarzanie danych}

    \vspace{0.5cm}
    
    {\large\bfseries Mikołaj Warda}

    \vspace{0.1cm}
    
    {\large Nr albumu: s28034}

    \vspace{1cm}
    
    \begin{spacing}{1.1} % Increase line spacing for the title
        {\LARGE\bfseries Zastosowanie filtrów Kalmana do poprawy predykcji cen giełdowych przy użyciu sieci LSTM\par}
    \end{spacing}

    \vfill

    \begin{flushright}
        \begin{tabular}{l}
            {\large Praca Inżynierska} \\
            \vspace{0.3cm} \\
            {\large Promotor: dr Sinh Hoa Nguyen Thi}
        \end{tabular}
    \end{flushright}
    
    \vfill
    
    {\large Warszawa, Styczeń 2026}
    
\end{titlepage}
\clearpage
%~ Main Page (English)
\begin{titlepage}
    \centering
    
    % University Logo and Name as a single image
    \includegraphics[width=1\textwidth]{assets/PJAIT_EN_poziom_2.png}
    
    
    {\large\bfseries Faculty of Computer Science}
    
    \vspace{0.5cm}
    
    {\large\bfseries Department of Intelligent Systems and Data Science}
    
    \vspace{0.2cm}

    {\large Intelligent data processing}

    \vspace{0.5cm}
    
    {\large\bfseries Mikołaj Warda}

    \vspace{0.1cm}
    
    {\large Student ID: s28034}

    \vspace{1cm}
    
    \begin{spacing}{1.1} % Increase line spacing for the title
        {\LARGE\bfseries Application of Kalman Filters to Improve Stock Price Prediction Using LSTM Networks\par}
    \end{spacing}

    \vfill

    \begin{flushright}
        \begin{tabular}{l}
            {\large Engineering Thesis} \\
            \vspace{0.3cm} \\
            {\large Supervisor: dr Sinh Hoa Nguyen Thi}
        \end{tabular}
    \end{flushright}
    
    \vfill
    
    {\large Warsaw, January 2026}
    
\end{titlepage}
\clearpage

%~ Abstract
\begin{quote}
    \noindent\textbf{Streszczenie}
    \vspace{0.2cm}

    Prognozowanie cen akcji przy użyciu sieci neuronowych, takich jak LSTM, nie jest łatwym zadaniem ze względu na wysoką niestabilność rynkową.
    Modele te często uczą się losowych fluktuacji zamiast bazowych trendów, co wpływa negatywnie na ich zdolność do precyzyjnych prognoz.

    W pracy zbadano skuteczność filtru Kalmana jako techniki wstępnego przetwarzania danych celem poprawy jakości predykcji sieci LSTM.
    Przeprowadzono eksperyment na danych historycznych cen akcji Amazon.com Inc (AMZN), porównując trzy modele: bazowy LSTM, model z dodatkowymi wskaźnikami analizy technicznej oraz model uczony na danych przefiltrowanych.

    Wyniki pokazały, że w realistycznym scenariuszu testowym (predykcja na oryginalnych danych, nie poddanych filtracji) żaden z bardziej złożonych modeli nie uzyskał przewagi nad najprostszym modelem bazowym. 
    Jednocześnie model uczony na danych po filtracji Kalmana, testowany w warunkach laboratoryjnych (predykcja na danych również poddanych filtracji), osiągnął niemal perfekcyjną skuteczność (\(R^2=0.9543\)), co dowodzi jego zdolności do ekstrakcji bazowego trendu.

    Główny wniosek płynący z pracy jest taki, że zastosowanie filtracji Kalmana, choć nie gwarantuje lepszych prognoz konkretnych wartości cen akcji, to znacznie poprawia zdolność modelu do nauki trendu, co mogłoby się znacznie lepiej sprawdzić w zadaniach natury klasyfikacyjnej, np. prognozowania kierunku zmian cen.

    \vspace{1cm}
    \noindent \textbf{Słowa kluczowe:} \it{prognozowanie cen akcji}, \it{sieci LSTM, filtr Kalmana}, \it{szeregi czasowe}, \it{uczenie maszynowe}, \it{analiza finansowa}
\end{quote}
\clearpage

\begin{quote}
    \noindent\textbf{Abstract}
    \vspace{0.2cm}

    Forecasting stock prices using neural networks, such as LSTM, is a challenging task due to high market volatility. These models often learn random fluctuations instead of underlying trends, which negatively affects their ability to make precise predictions.

    This thesis investigates the effectiveness of the Kalman filter as a data pre-processing technique for filtering input data to improve the prediction quality of an LSTM network. An experiment was conducted on historical stock price data for Amazon.com Inc. (AMZN), comparing three models: a baseline LSTM, a model enriched with additional technical analysis indicators, and a model trained on filtered data.

    The results showed that in a realistic test scenario (prediction on original, unfiltered data), neither of the more complex models achieved a clear advantage over the simplest baseline model. The model trained on filtered data, despite showing no advantage in the realistic test, achieved high performance (\(R^2=0.9543\)) when tested on data that was also filtered, demonstrating its ability to almost perfectly extract the underlying trend.

    The main conclusion of this work is that while Kalman filtering does not guarantee better predictions of specific stock price values, it significantly enhances the model's ability to learn the trend. This could prove much more effective in classification tasks, such as forecasting the direction of price changes.
    
    \vspace{1cm}
    \noindent \textbf{Keywords:} \it{stock price prediction}, \it{LSTM networks}, \it{Kalman filter}, \it{time series}, \it{machine learning}, \it{financial analysis}.
\end{quote}
\clearpage

%~ Table of Contents
\begin{spacing}{1.0}
    \tableofcontents
\end{spacing}
\clearpage

%~ Introduction
\section{Wstęp}

Prognozowanie cen akcji odgrywa kluczową rolę w finansach, wspierając inwestorów w podejmowaniu świadomych decyzji zarządzania swoim portfolio.
Chaotyczny charakter rynków sprawia jednak, że trafne przewidywanie notowań pozostaje trudnym zadaniem.
Tradycyjna analiza techniczna bywa niewystarczająca - jest wrażliwa na szum, a wnioski często zawierają element subiektywności \cite{xie2023stock}.

W ostatnich latach dynamiczny rozwój uczenia maszynowego, zwłaszcza sieci neuronowych, 
znacząco zmienił podejście do modelowania danych czasowych (w tym giełdowych).
Architektury takie jak LSTM (Long Short-Term Memory) potrafią uchwycić złożone zależności i długookresowe relacje w danych, 
co czyni je obiecującymi narzędziami do prognozowania cen \cite{sen2021stock}.
Niemniej jednak ich skuteczność nadal zależy od jakości danych wejściowych.
Głównym problemem, jest wysoka wrażliwość na losowe wahania, które są nieodłącznym elementem danych finansowych. 
Te zniekształcenia wynikają z nieprzewidywalnych zdarzeń rynkowych.
Model, zamiast uczyć się rzeczywistych trendów, modeluje wspomniane zakłócenia, 
obniżając swoją zdolność do generalizacji na nowych danych. 
W rezultacie, predykcje mogą być obarczone znacznym błędem, 
co podważa ich użyteczność w podejmowaniu decyzji inwestycyjnych \cite{brogaard2022what}.

Można temu zapobiegać stosując techniki filtracji na danych wejściowych.
Jednym z klasycznych narzędzi tego typu jest filtr Kalmana,
który może pełnić rolę modułu wygładzania i korekty obserwacji, podnosząc stabilność i dokładność predykcji.
Trenowanie sieci neuronowej na przefiltrowanych danych przy użyciu filtra Kalmana może zredukować wpływ szumu, 
pozwalając na lepsze uchwycenie istotnych wzorców i trendów w danych \cite{cheeneebash2007improving}.

W ramach niniejszej pracy dyplomowej, podjęto się zbadania skuteczności zastosowania filtru Kalmana jako etapu przetwarzania danych dla modeli LSTM w kontekście prognozowania cen akcji spółki Amazon.com Inc (AMZN) \cite{yfinance_data}.
Wybór tematu pracy wyniknął z chęci zdobycia wiedzy na temat działania architektury LSTM oraz zbadania wpływu filtracji danych na jakość prognoz.
Dodatkową motywacją była możliwość wszechstronnego rozwoju ze względu na złożony charakter problemu, łączącego zagadnienia z dziedziny uczenia maszynowego, analizy szeregów czasowych oraz teorii filtrów.

W dalszej części pracy, w rozdziale drugim i trzecim, przedstawiono podstawy teoretyczne niezbędne do zrozumienia przeprowadzonych badań, ze szczególnym naciskiem na architekturę sieci LSTM oraz matematyczne podstawy działania filtru Kalmana.
Następnie, w rozdziale czwartym, opisano podejście badawcze, w tym przygotowanie danych, implementację modelu, metryki oceny oraz wykorzystane narzędzia.
Rozdział piąty prezentuje uzyskane wyniki eksperymentów wraz z ich analizą i interpretacją.
Na zakończenie, w rozdziale szóstym, podsumowano przeprowadzone badania, przedstawiono kluczowe wnioski oraz zasugerowano kierunki dalszych badań w tym obszarze.

%~ Fundamentals
\clearpage
\section{Podstawy teoretyczne}
\subsection{Przewidywanie szeregów czasowych na rynkach finansowych}
Dane finansowe, takie jak np. ceny akcji, zawierają obserwacje tworzące szeregi czasowe.
Innymi słowy, są to dane, które reprezentują zmiany wartości w określonych odstępach czasu.
Formalnie szeregiem czasowym określa się zbiór uporządkowanych obserwacji w czasie, gdzie każda obserwacja jest powiązana z określoną chwilą czasową \cite{shah2024timeseries}:
\begin{equation}
    X = \{x_1, x_2, x_3, \ldots, x_n\}
\end{equation}
gdzie \( x_i \) reprezentuje wartość obserwacji w czasie \( t_i \), a \( n \) to liczba obserwacji w szeregu czasowym.

Abstrahując od rynków finansowych, przedstawiono kilka przykładów szeregów czasowych z innych dziedzin, celem lepszego zobrazowania tej koncepcji:
\begin{itemize}
    \item \textbf{Energetyka:} Godzinowe zużycie energii elektrycznej
    \item \textbf{Meteorologia:} Codzienny pomiar temperatury
    \item \textbf{Sport:} Wyniki meczów drużyny na przestrzeni sezonu
\end{itemize}

Najczęściej spotykanym formatem danych finansowych są tzw. dane OHLC.
Przedstawione w takiej postaci informacje tworzą szereg czasowy, w którym każda obserwacja składa się z czterech części \cite{tepelyan2025enhancingohlcdatatiming}:
\begin{itemize}
    \item \textbf{Open (O):} Cena otwarcia - cena, po której dany instrument finansowy rozpoczął notowania w danym okresie.
    \item \textbf{High (H):} Cena najwyższa - najwyższa cena osiągnięta przez instrument finansowy w danym okresie.
    \item \textbf{Low (L):} Cena najniższa - najniższa cena osiągnięta przez instrument finansowy w danym okresie.
    \item \textbf{Close (C):} Cena zamknięcia - cena, po której instrument finansowy zakończył notowania w danym okresie.
\end{itemize}
Na potrzeby tej pracy, wykorzystano składnik \textit{Close}, ze względu na jego powszechne wykorzystanie w analizie i prognozie cen akcji.

Rysunek \ref{fig:amzn_stock_prices} przedstawia przykładowy wykres cenowy względem składnika \textit{Close} spółki Amazon.com Inc (AMZN) na przestrzeni lat 2022-2025 w odstępach dziennych. 
Dane przedstawione na wykresie są nieregularne i zawierają liczne fluktuacje, co jest charakterystyczne dla danych finansowych.
Ta wysoka zmienność stanowi główne wyzwanie dla modeli predykcyjnych, co motywuje do poszukiwania skutecznych metod filtrujących \cite{cheeneebash2007improving}.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/amzn_stock.png}
    \caption{Wykres cenowy względem składnika \textit{Close} Amazon.com Inc (AMZN) w latach 2022-2025. Źródło danych: Yahoo Finance \cite{yfinance_data}.}
    \label{fig:amzn_stock_prices}
\end{figure}

Tradycyjnie analiza danych rynkowych opierała się o wskaźniki techniczne. 
Można je określić mianem narzędzi statystycznych reprezentujących różne aspekty zachowań cen \cite{MOSTAFAVI2025100631}.
W niniejszej pracy wykorzystano trzy wskaźniki techniczne, które opisano w następnych podsekcjach.

\subsubsection{Wskaźnik siły względnej (Relative Strength Index, RSI)}
Wskaźnik siły względnej (RSI) to popularny wskaźnik techniczny używany do oceny siły i prędkości zmian cen aktywów finansowych \cite{MOSTAFAVI2025100631}.
Wyraża się go wzorem:
\begin{equation}
    RSI = 100 - \frac{100}{1 + RS}
\end{equation}
gdzie \( RS \) (Relative Strength) to stosunek średnich wzrostów do średnich spadków cen w określonym czasie. Według badań, optymalny okres do obliczania RSI wynosi 14 dni \cite{agudelo2025artificial}.

Produktem końcowym RSI jest liczba z zakresu od 0 do 100, która interpretowana jest następująco:
\begin{itemize}
    \item Wartości powyżej 70 sugerują, że akcja jest wykupiona i może nastąpić spadek cen.
    \item Wartości poniżej 30 sugerują, że akcja jest wyprzedana i może nastąpić wzrost cen.
    \item Wartości pomiędzy 30 a 70 wskazują na neutralny stan rynku.
\end{itemize}

\subsubsection{Wstęgi Bollingera (Bollinger Bands)}
Wstęgi Bollingera to narzędzie analizy technicznej, dostarczające informacji o zmienności rynku \cite{MOSTAFAVI2025100631}. 
Składaja się z trzech linii na wykresie cenowym:
\begin{itemize}
    \item \textbf{Środkowa linia:} Prosta średnia krocząca (SMA) obliczona na podstawie cen zamknięcia w określonym czasie. Najczęsciej używanym okresem jest 20 dni.
    \item \textbf{Górna wstęga:} Obliczana jako suma wartości środkowej linii i dwukrotności odchylenia standardowego cen w tym okresie.
    \item \textbf{Dolna wstęga:} Obliczana jako różnica wartości środkowej linii i dwukrotności odchylenia standardowego cen w tym okresie.
\end{itemize}
Na podstawie ww. składowych można zinterpretować dwie nowe miary, które zostały wykorzystane w niniejszej pracy:
\begin{itemize}
    \item \textbf{Bollinger Bandwidth (BBW):} Miara szerokości wstęg Bollingera, obliczana jako stosunek różnicy między górną a dolną wstęgą do środkowej linii \cite{vaidya2021nepse}:
    \begin{equation}
        BBW = \frac{Upper Band - Lower Band}{Middle Line}
    \end{equation}
    \item \textbf{Bollinger \%B (BB\%):} Miara położenia ceny względem wstęg Bollingera, obliczana jako stosunek różnicy między ceną zamknięcia a dolną wstęgą do różnicy między górną a dolną wstęgą \cite{vaidya2021nepse}:
    \begin{equation}
        BB\% = \frac{Close - Lower Band}{Upper Band - Lower Band}
    \end{equation}
\end{itemize}

Opisane powyżej wskaźniki techniczne - RSI, BBW oraz BB\% - dostarczają cennych informacji o dynamice rynku. 
W tradycyjnej analizie mogą posłużyć do subiektywnej interpretacji przez analityków.
W nowoczesnych podejściach, opartych na modelach uczenia maszynowego, 
można je wykorzystać do wzbogacenia danych o dodatkowe cechy, co potencjalnie może poprawić jakość prognoz \cite{MOSTAFAVI2025100631}.

\subsection{Sieci neuronowe w prognozowaniu rynków finansowych}

Wraz z rozwojem mocy obliczeniowej i technik uczenia maszynowego, pojawiły się bardziej zaawansowane metody analizy i prognozowania w dziedzinie finansów.
Do najpopularniejszych podejść należą sieci rekurencyjne (RNN), w tym ich zaawansowane warianty, takie jak \textit{LSTM} (Long Short-Term Memory).
Sieci te są zdolne do uchwycenia złożonych wzorców i zależności w szeregach czasowych \cite{sen2021stock}.

W niniejszej sekcji zostały omówione podstawy działania sieci neuronowych. 
Przedstawiona została budowa pojedynczego neuronu wchodzącego w skład sieci, kluczowe algorytmy uczenia oraz architektura LSTM.

\subsubsection{Podstawy działania sztucznego neuronu}
Ważnym kamieniem milowym w dziedzinie uczenia maszynowego było wprowadzenie matematycznego modelu neuronu przez McCullocha i Pitts'a w 1943 roku \cite{piccinini2004first}.
Współcześnie można mówić o różnych architekturach takiego neuronu, jednak ich podstawowa zasada działania pozostaje podobna.

Neuron otrzymuje na wejściu sygnały \( x_1, x_2, \ldots, x_n \), które są ważone przez odpowiednie wagi \( w_1, w_2, \ldots, w_n \).
Następnie, sumuje te ważone sygnały i dodaje do nich wartość obciążenia (bias) \( b \) \cite{goodfellow-et-al-2016}:
\begin{equation}
    z = \sum_{i=1}^{n} w_i x_i + b
\end{equation}

Otrzymana wartość \( z \), zwana logitem (surowym wyjściem) neuronu, jest następnie przekształcana przez funkcję aktywacji \( f(z) \) \cite{goodfellow-et-al-2016}:
\begin{equation}
    \hat{y} = f(z) = f(\sum_{i=1}^{n} w_i x_i + b)
\end{equation}

Funkcja aktywacji modyfikuje logit \( z \), produkując finalne wyjście neuronu \( \hat{y} \) -- stopień aktywacji.
W zależności od zastosowanej funkcji aktywacji, wyjście może przyjmować różne formy \cite{szandala2020review}.
Tą różnicę najprościej zilustrować na przykładzie dwóch popularnych funkcji aktywacji:
\begin{itemize}
    \item \textbf{Funkcja skokowa:}
    \begin{equation}
        f(z) = 
        \begin{cases}
            1 & \text{jeśli } z \geq 0 \\
            0 & \text{jeśli } z < 0
        \end{cases}
    \end{equation}
    W tym przypadku, wyjście neuronu jest binarne. 
    Innymi słowy, neuron zostanie albo aktywowany (1), albo nieaktywowany (0), w zależności od tego, czy logit \( z \) przekracza pewien próg (w tym przypadku 0) \cite{szandala2020review}.
    \item \textbf{Funkcja sigmoidalna:}
    \begin{equation}
        f(z) = \frac{1}{1 + e^{-z}}
    \end{equation}
    W tym przypadku, wyjście neuronu jest ciągłe i mieści się w zakresie od 0 do 1.
    Oznacza to, że neuron może przyjmować różne poziomy aktywacji, co pozwala na wyrażenie stopnia pewności co do wyniku \cite{szandala2020review}.
\end{itemize}
Rysunek \ref{fig:step_sigmoid_comparison} przedstawia porównanie ww. funkcji aktywacji.
Po lewej stronie znajduje się wykres funkcji skokowej, gdzie wyjście nagle zmienia się z 0 na 1 w punkcie \( z=0 \).
Po prawej stronie znajduje się wykres funkcji sigmoidalnej, gdzie wyjście zmienia się stopniowo od 0 do 1 wraz ze wzrostem wartości \( z \).
\begin{figure}[H]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{assets/step_figure.png}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{assets/sigmoid_figure.png}
    \end{minipage}
    \caption{Porównanie funkcji aktywacji: (po lewej) funkcja skokowa, (po prawej) funkcja sigmoidalna.}
    \label{fig:step_sigmoid_comparison}
\end{figure}
Istnieje wiele innych funkcji aktywacji (np. ReLU, tanh, softmax), a każda z nich ma swoje unikalne właściwości i zastosowania.
W przypadku funkcji skokowej, neuron podejmuje twardą decyzję, aktywując się w pełni lub wcale.
Przez brak elastyczności, funkcja ta nie pozwala na wyrażenie przekonania co do wyniku.
W przeciwieństwie do niej, funkcja sigmoidalna umożliwia płynną aktywację, pozwalając uwzględnić stopień pewności \cite{szandala2020review}.

Znając rolę funkcji aktywacji, można lepiej wyjaśnić działanie parametrów uczonych neuronu, czyli wag \( w_i \) oraz obciążenia \( b \).

Wagi określają, jak duży wpływ ma każdy sygnał wejściowy \( x_i \) na logit \( z \).
Poprzez modelowanie wag, w trakcie procesu uczenia, neuron może nauczyć się, które cechy wejściowe są bardziej istotne dla danego zadania \cite{goodfellow-et-al-2016}.

Rysunek \ref{fig:sigmoid_weights_combined} przedstawia wpływ różnych wartości wagi \( w \) na funkcję sigmoidalną w neuronie z jednym wejściem i bez obciążenia.
Po lewej stronie znajduje się wykres dla małej wagi \( w=0.1 \), gdzie funkcja zmienia się powoli i ma łagodne nachylenie.
Po prawej stronie znajduje się wykres dla dużej wagi \( w=2.0 \), gdzie funkcja zmienia się gwałtownie i ma strome nachylenie.
Można zaobserwować, że wraz ze wzrostem wartości wagi, funkcja sigmoidalna zaczyna przypominać funkcję skokową.
Oznacza to, że neuron staje się pewniejszy swoich decyzji, aktywując się niemal natychmiast po przekroczeniu progu.

\begin{figure}[H]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{assets/sigmoid_w_min_figure.png}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{assets/sigmoid_w_max_figure.png}
    \end{minipage}
    \caption{Wpływ wartości wagi (w) na kształt funkcji sigmoidalnej: (po lewej) \(w=0.1\), (po prawej) \(w=2.0\).}
    \label{fig:sigmoid_weights_combined}
\end{figure}

Drugim kluczowym parametrem jest obciążenie, czyli bias \( b \), który przesuwa próg funkcji aktywacji wzdłuż osi poziomej.
W istocie umożliwia to opóźnienie lub przyspieszenie momentu, w którym neuron zostaje aktywowany \cite{goodfellow-et-al-2016}.

Rysunek \ref{fig:sigmoid_bias_combined} przedstawia wpływ różnych wartości biasu \( b \) na kształt funkcji sigmoidalnej w neuronie z jednym wejściem i wagą \( w=0.1 \).
\begin{figure}[H]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{assets/sigmoid_b_min_figure.png}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{assets/sigmoid_b_max_figure.png}
    \end{minipage}
    \caption{Wpływ wartości bias (b) na kształt funkcji sigmoidalnej: (po lewej) \(b=-2.82\), (po prawej) \(b=4.21\).}
    \label{fig:sigmoid_bias_combined}
\end{figure}

Opisane powyżej parametry -- wagi \( w_i \), obciążenie \( b \) oraz funkcja aktywacji \( f(z) \) - stanowią podstawę działania sztucznego neuronu \cite{goodfellow-et-al-2016}.

Rysunek \ref{fig:neuron_architecture} podsumowuje budowę sztucznego neuronu, ilustrując jak sygnały wejściowe są przetwarzane przez wagę, sumowane z obciążeniem i przekształcane przez funkcję aktywacji.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/neuron.png}
    \caption[Schemat budowy sztucznego neuronu]{Schemat budowy sztucznego neuronu. Źródło: \cite{wikimedia_neuron_mcculloch_pitts}}
    \label{fig:neuron_architecture}
\end{figure}

Niestety pojedyczny neuron jest ograniczony w swoich możliwościach -- może nauczyć się jedynie prostych zależności liniowo-separowalnych.
Inaczej mówiąc, jest w stanie rozróżnić tylko te wzorce, które można oddzielić prostą linią w przestrzeni cech.
Aby radzić sobie z bardziej złożonymi problemami, konieczne jest łączenie wielu neuronów w wielowarstwowe struktury \cite{goodfellow-et-al-2016}.

\subsubsection{Architektura sieci neuronowej}

W celu modelowania bardziej złożonych zależności, łączy się wiele neuronów w struktury zwane sieciami neuronowymi.
Składają się one z warstw, gdzie każda warstwa zawiera wiele neuronów.
Typowa sieć neuronowa składa się z trzech głównych typów warstw \cite{goodfellow-et-al-2016}:
\begin{enumerate}
    \item \textbf{Warstwa wejściowa:} Odpowiada za przyjmowanie danych wejściowych.
    \item \textbf{Warstwy ukryte:} Przetwarzają dane poprzez zestaw neuronów, ucząc się złożonych wzorców.
    \item \textbf{Warstwa wyjściowa:} Generuje ostateczne prognozy lub klasyfikacje na podstawie przetworzonych danych.
\end{enumerate}
Warstwy można łączyć na różne sposoby. Najbardziej podstawowym jest pełne łączenie (ang. \textit{fully-connected} lub \textit{dense}), gdzie każdy neuron z jednej warstwy jest połączony z każdym neuronem w warstwie następnej. 
Inne, bardziej zaawansowane metody to m.in. konwolucje czy rekurencje \cite{goodfellow-et-al-2016}.
Przepływ sygnału w takiej sieci odbywa się na zasadzie propagacji w przód (ang. forward propagation) -- od warstwy wejściowej, przez warstwy ukryte, aż do warstwy wyjściowej.

Formalnie ten proces można opisać krokami obliczeniowymi dla każdej warstwy \cite{goodfellow-et-al-2016}:
\begin{enumerate}
    \item \textbf{Warstwa wejściowa:}
    \begin{equation}
        \mathbf{a}^{(0)} = \mathbf{x}
    \end{equation}
    \item \textbf{Warstwy ukryte:}
    \begin{equation}
        \mathbf{a}^{(l)} = f(\mathbf{W}^{(l)} \mathbf{a}^{(l-1)} + \mathbf{b}^{(l)}) \quad \text{dla } l = 1, 2, \ldots, L-1
    \end{equation}
    \item \textbf{Warstwa wyjściowa:}
    \begin{equation}
        \mathbf{\hat{y}} = g(\mathbf{W}^{(L)} \mathbf{a}^{(L-1)} + \mathbf{b}^{(L)})
    \end{equation}
    gdzie:
    \begin{itemize}
        \item \( \mathbf{x} \) to wektor danych wejściowych,
        \item \( \mathbf{\hat{y}} \) to wektor danych wyjściowych (prognoz),
        \item \( \mathbf{a}^{(l)} \) to aktywacje (wyjścia) warstwy \( l \),
        \item \( \mathbf{W}^{(l)} \) to macierz wag warstwy \( l \),
        \item \( \mathbf{b}^{(l)} \) to wektor obciążeń warstwy \( l \),
        \item \( f \) to funkcja aktywacji dla warstw ukrytych,
        \item \( g \) to funkcja aktywacji dla warstwy wyjściowej,
        \item \( L \) to liczba warstw w sieci.
    \end{itemize}
\end{enumerate}

Rysunek \ref{fig:nn_architecture} przedstawia schematyczną budowę prostej sieci neuronowej z jedną warstwą wejściową, dwiema warstwami ukrytymi i jedną warstwą wyjściową.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/nn.png}
    \caption{Budowa prostej sieci neuronowej z jedną warstwą wejściową, dwiema warstwami ukrytymi i jedną warstwą wyjściową. Opracowanie własne na podstawie \cite{geeksforgeeks_nn_architecture}.}
    \label{fig:nn_architecture}
\end{figure}

Przedstawiona architektura oraz proces propagacji w przód definiują przepływ informacji w sieci neuronowej w celu generowania prognoz \cite{goodfellow-et-al-2016}.
Jednakże aby prognoza była trafna, parametry sieci -- wartości wag \( \mathbf{W}^{(l)} \) oraz obciążeń \( \mathbf{b}^{(l)} \) -- muszą zostać odpowiednio dobrane \cite{goodfellow-et-al-2016}.
Ten proces nazywany jest uczeniem sieci i zostanie omówiony w następnej podsekcji.

\subsubsection{Uczenie sieci neuronowej}
Uczenie sieci neuronowej polega na algorytmicznym dostosowywaniu jej parametrów (wag i obciążeń) w celu minimalizacji błędu prognoz.
Działa ono w oparciu o zestaw danych zawierających zarówno dane wejściowe \( \mathbf{x} \), jak i odpowiadające im rzeczywiste wartości wyjściowe \( \mathbf{y} \).
Innymi słowy, sieć uczy się na podstawie przykładów, aby poprawić swoje prognozy \cite{goodfellow-et-al-2016}.

Aby proces uczenia zwracał rzetelne wyniki, zestaw danych dzieli się na trzy niezależne podzbiory \cite{goodfellow-et-al-2016}:
\begin{itemize}
    \item \textbf{Zbiór treningowy:} Służy do uczenia sieci poprzez dostosowywanie jej parametrów \cite{goodfellow-et-al-2016}.
    \item \textbf{Zbiór walidacyjny:} Używany do monitorowania wydajności sieci podczas treningu i dostrajania hiperparametrów \cite{goodfellow-et-al-2016}.
    \item \textbf{Zbiór testowy:} Służy do oceny ostatecznej wydajności sieci na niewidzianych wcześniej danych \cite{goodfellow-et-al-2016}.
\end{itemize}

Sam proces dostosowywania parametrów sieci przeprowadzany jest na zbiorze treningowym i można go opisać w kilku kluczowych krokach \cite{goodfellow-et-al-2016}:

\begin{enumerate}

    \item \textbf{Inicjalizacja:} Na początku, wagi \( \mathbf{W}^{(l)} \) oraz obciążenia \( \mathbf{b}^{(l)} \) są inicjalizowane małymi, losowymi wartościami.

    \item \textbf{Propagacja w przód:} Dane wejściowe \( \mathbf{x} \) są przekazywane przez sieć, generując prognozy \( \mathbf{\hat{y}} \).

    \item \textbf{Obliczanie błędu:} Prognoza modelu \( \mathbf{\hat{y}} \) jest porównywana z rzeczywistą wartością \( \mathbf{y} \) za pomocą funkcji kosztu (np. MSE), co pozwala na zmierzenie błędu prognozy:
    \begin{equation}
        L = \frac{1}{n} \sum_{i=1}^{n} (\hat{y}_i - y_i)^2
    \end{equation}
    gdzie \( L \) to wartość funkcji kosztu MSE, a \( n \) to liczba próbek w zbiorze treningowym.

    \item \textbf{Propagacja wsteczna błędu:} Obliczony błąd jest propagowany wstecz sieci, od warstwy wyjściowej do wejściowej. 
    Celem tego kroku jest obliczenie gradientów funkcji kosztu w każdym neuronie sieci.
    Gradienty te wskazują kierunek i wielkość zmian, które należy wprowadzić w parametrach sieci, aby skutecznie minimalizować błąd prognozy.
    Formalnie gradient jest pochodną funkcji kosztu względem wag lub obciążeń \cite{rumelhart1986learning}:
    \begin{equation}
        \frac{\partial L}{\partial \mathbf{W}^{(l)}}, \quad \frac{\partial L}{\partial \mathbf{b}^{(l)}}
    \end{equation}

    \item \textbf{Aktualizacja parametrów:} Wagi i obciążenia są aktualizowane za pomocą algorytmu optymalizacji (np. Stochastic Gradient Descent, Adam), wykorzystując obliczone gradienty:
    \begin{equation}
        \mathbf{W}^{(l)} \leftarrow \mathbf{W}^{(l)} - \eta \frac{\partial L}{\partial \mathbf{W}^{(l)}}, \quad
        \mathbf{b}^{(l)} \leftarrow \mathbf{b}^{(l)} - \eta \frac{\partial L}{\partial \mathbf{b}^{(l)}}
    \end{equation}
    gdzie \( \eta \) to współczynnik nauki (learning rate), określający wielkość kroków aktualizacji.

\end{enumerate}

Proces ten jest powtarzany przez wiele iteracji (epok) na całym zbiorze treningowym, aż do osiągnięcia zadowalającej dokładności prognoz lub spełnienia kryteriów zatrzymania (np. minimalny błąd na zbiorze walidacyjnym).
Wynikowo sieć neuronowa uczy się optymalnych wartości wag i obciążeń, co pozwala jej na generowanie trafnych prognoz na niewidzianych wcześniej danych \cite{goodfellow-et-al-2016}.

\subsubsection{Sieci rekurencyjne}
Tradycyjna architekura sieci neuronowej, opisana w poprzednich podsekcjach, zakłada, że dane wejściowe są niezależne od siebie.
W przypadku danych finansowych (szeregi czasowe) takie założenie jest błędne, ponieważ obserwacje są ze sobą powiązane w czasie.
Można sobie to wyobrazić na przykładzie cen akcji, gdzie ceny z kilku poprzednich dni wpływają na cenę w dniu dzisiejszym.
Wówczas pojawia się potrzeba "pamiętania" wcześniejszych informacji podczas przetwarzania bieżących danych.
Sieci rekurencyjne (RNN) zostały zaprojektowane właśnie w tym celu \cite{goodfellow-et-al-2016}.

Podstawowym budulcem sieci RNN jest komórka rekurencyjna, która posiada zdolność do przechowywania stanu ukrytego \( \mathbf{h}_t \).
Stan ukryty \( \mathbf{h}_t \) jest nośnikiem informacji z poprzednich kroków czasowych.
Aby skutecznie taką informację utrwalić, sieci RNN wykorzystują mechanizm rekurencji, gdzie wyjście z poprzedniego kroku czasowego jest wykorzystywane jako dodatkowe wejście do bieżącego kroku \cite{goodfellow-et-al-2016}.

Formalnie, stan ukryty \( \mathbf{h}_t \) w czasie \( t \) jest wektorem obliczanym na podstawie bieżącego wejścia \( \mathbf{x}_t \) oraz poprzedniego stanu ukrytego \( \mathbf{h}_{t-1} \) \cite{goodfellow-et-al-2016}:
\begin{equation}
    \mathbf{h}_t = f(\mathbf{W}_h \mathbf{h}_{t-1} + \mathbf{W}_x \mathbf{x}_t + \mathbf{b})
\end{equation}
gdzie \( \mathbf{W}_h \) to macierz wag dla stanu ukrytego, \( \mathbf{W}_x \) to macierz wag dla wejścia, \( \mathbf{b} \) to wektor obciążeń, a \( f \) to funkcja aktywacji.

Gdy obliczony zostanie ostatni stan ukryty \( \mathbf{h}_t \), sieć może wygenerować prognozę \( \mathbf{\hat{y}}_t \) na podstawie tego stanu \cite{goodfellow-et-al-2016}:
\begin{equation}
    \mathbf{\hat{y}}_t = g(\mathbf{W}_y \mathbf{h}_t + \mathbf{b}_y)
\end{equation}
gdzie \( \mathbf{W}_y \) to macierz wag dla wyjścia, \( \mathbf{b}_y \) to wektor obciążeń wyjścia, a \( g \) to funkcja aktywacji wyjścia.

Rysunek \ref{fig:rnn_cell} przedstawia schematyczną budowę komórki rekurencyjnej w sieci RNN.
Aby lepiej zobrazować działanie komórki RNN, na rysunku pokazano jej rozwinięcie w czasie.
Stan ukryty \( \mathbf{h}_t \) jest przekazywany z jednego kroku czasowego do następnego.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{assets/rnn_cell.png}
    \caption{Budowa komórki rekurencyjnej w sieci RNN. Opracowanie własne na podstawie \cite{wikimedia_rnn_unfold}.}
    \label{fig:rnn_cell}
\end{figure}

Taka architektura stanowi solidny fundament do modelowania szeregów czasowyc, jednak ma ona pewne ograniczenia.
Są nimi m.in. problem zanikającego i eksplodującego gradientu podczas procesu uczenia, co utrudnia naukę długoterminowych zależności w danych \cite{goodfellow-et-al-2016}.

Aby wyjaśnić na czym polegają te problemy, należy wrócić do procesu opartego na wstecznej propagacji błędu.
W przypadku sieci RNN, odpowiednikiem algorytmu wstecznej propagacji jest algorytm zwany propagacją wsteczną w czasie (ang. *Backpropagation Through Time, BPTT*).
Tak jak w przypadku klasycznej propagacji wstecznej, BPTT polega na obliczaniu gradientów funkcji kosztu względem wag i obciążeń sieci.
Ze względu na współdzielenie wag w czasie, gradienty są sumowane przez wszystkie kroki czasowe, co daje ostateczny gradient dla każdej wagi \cite{goodfellow-et-al-2016}:
\begin{equation}
    \frac{\partial L}{\partial \mathbf{W}_h} = \sum_{t=1}^{T} \frac{\partial L}{\partial \mathbf{h}_t} \frac{\partial \mathbf{h}_t}{\partial \mathbf{W}_h}
\end{equation}
W praktyce, propagacja błędu w czasie wiąże się z wielokrotnym mnożeniem macierzy wag \( \mathbf{W}_h \) odpowiadających za stan ukryty \cite{goodfellow-et-al-2016}:
\begin{equation}
    \frac{\partial L}{\partial \mathbf{h}_t} = \frac{\partial L}{\partial \mathbf{h}_T} \prod_{k=t+1}^{T} \frac{\partial \mathbf{h}_k}{\partial \mathbf{h}_{k-1}}
\end{equation}
To właśnie ten mechanizm prowadzi do dwóch problemów:
\begin{itemize}
    \item \textbf{Problem zanikającego gradientu:} Jeśli wartości w macierzy wag \( \mathbf{W}_h \) są małe (norma macierzy mniejsza od 1), to przy wielokrotnym mnożeniu sygnał błędu (gradient) staje się wykładniczo coraz mniejszy.
    W konsekwencji sieć nie jest w stanie nauczyć się zależności między danymi, które są od siebie odległe w czasie \cite{goodfellow-et-al-2016}.

    \item \textbf{Problem eksplodującego gradientu:} Jest to sytuacja odwrotna. Jeśli wartości w macierzy wag \( \mathbf{W}_h \) są duże (norma macierzy większa od 1), sygnał błędu przy wielokrotnym mnożeniu rośnie wykładniczo, stając się ogromną liczbą.
    Na skutek tego aktualizacje wag stają się tak duże, że proces uczenia staje się niestabilny \cite{goodfellow-et-al-2016}.
\end{itemize}

Aby skutecznie radzić sobie z tymi problemami, opracowano zaawansowane architektury sieci rekurencyjnych.
Jedną z najpopularniejszych jest Long Short-Term Memory (LSTM), która zostanie omówiona w następnej podsekcji.

\subsubsection{Sieci Long Short-Term Memory}
Sieci Long Short-Term Memory (LSTM) zostały zaprojektowane, aby niwelować problemy zanikającego i eksplodującego gradientu występujące w tradycyjnych sieciach RNN \cite{hochreiter1997long}.
Cechę tę osiągnięto poprzez wprowadzenie mechanizmów zwanych bramkami (ang. *gates*) oraz dodatkowego stanu komórki \( \mathbf{C}_t \) \cite{hochreiter1997long}.

Stan komórki \( \mathbf{C}_t \), w odróżnieniu od stanu ukrytego \( \mathbf{h}_t \), jest nośnikiem długoterminowych informacji.
Dzięki temu LSTM mogą efektywnie przechowywać i wykorzystywać informacje z odległych kroków czasowych \cite{goodfellow-et-al-2016}.
Komórka LSTM składa sie z trzech głównych bramek \cite{goodfellow-et-al-2016}:
\begin{enumerate}
    \item \textbf{Bramka zapominania (Forget Gate):} Decyduje, które informacje z poprzedniego stanu komórki \( \mathbf{C}_{t-1} \) należy zachować, a które odrzucić.
    \item \textbf{Bramka wejścia (Input Gate):} Określa, które nowe informacje z bieżącego wejścia \( \mathbf{x}_t \) powinny zostać dodane do stanu komórki \( \mathbf{C}_t \).
    \item \textbf{Bramka wyjścia (Output Gate):} Kontroluje, które informacje ze stanu komórki \( \mathbf{C}_t \) zostaną wykorzystane do wygenerowania bieżącego stanu ukrytego \( \mathbf{h}_t \).
\end{enumerate}

Rysunek \ref{fig:lstm_cell} przedstawia schematyczną budowę komórki LSTM wraz z jej trzema bramkami.
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{assets/lstm_cell.png}
    \caption{Budowa komórki LSTM z trzema bramkami: bramką zapominania, bramką wejścia i bramką wyjścia. Opracowanie własne na podstawie \cite{lstm_cell_drawing}.}
    \label{fig:lstm_cell}
\end{figure}

Każda z bramek w komórce LSTM działa na podobnej zasadzie jak tradycyjny neuron, wykorzystując funkcję aktywacji sigmoidalnej do generowania wartości między 0 a 1 \cite{goodfellow-et-al-2016}.
Służy to określeniu stopnia przepuszczania informacji przez daną bramkę.
Przepływ informacji w komórce LSTM można opisać następującymi krokami \cite{goodfellow-et-al-2016}:
\begin{enumerate}
    \item \textbf{Bramka zapominania:} Oblicza się wartość bramki zapominania \( \mathbf{f}_t \) na podstawie bieżącego wejścia \( \mathbf{x}_t \) oraz poprzedniego stanu ukrytego \( \mathbf{h}_{t-1} \). 
    Otrzymana wartość decyduje, które informacje z poprzedniego stanu komórki \( \mathbf{C}_{t-1} \) należy zachować:
    \begin{equation}
        \mathbf{f}_t = \sigma(\mathbf{W}_f [\mathbf{h}_{t-1}, \mathbf{x}_t] + \mathbf{b}_f)
    \end{equation}
    \begin{equation}
        \mathbf{C}_t = \mathbf{f}_t * \mathbf{C}_{t-1}
    \end{equation}

    \item \textbf{Bramka wejścia:} Oblicza się wartość bramki wejścia \( \mathbf{i}_t \) oraz tworzy się kandydat na nowe informacje \( \tilde{\mathbf{C}}_t \) na podstawie bieżącego wejścia \( \mathbf{x}_t \) oraz poprzedniego stanu ukrytego \( \mathbf{h}_{t-1} \).
    Następnie, przy pomocy nowych informacji aktualizuje się stan komórki \( \mathbf{C}_t \):
    \begin{equation}
        \mathbf{i}_t = \sigma(\mathbf{W}_i [\mathbf{h}_{t-1}, \mathbf{x}_t] + \mathbf{b}_i)
    \end{equation}
    \begin{equation}
        \tilde{\mathbf{C}}_t = \tanh(\mathbf{W}_C [\mathbf{h}_{t-1}, \mathbf{x}_t] + \mathbf{b}_C)
    \end{equation}
    \begin{equation}
        \mathbf{C}_t = \mathbf{C}_t + \mathbf{i}_t * \tilde{\mathbf{C}}_t
    \end{equation}

    \item \textbf{Bramka wyjścia:} Oblicza się wartość bramki wyjścia \( \mathbf{o}_t \) na podstawie bieżącego wejścia \( \mathbf{x}_t \) oraz poprzedniego stanu ukrytego \( \mathbf{h}_{t-1} \).
    Następnie, generuje się bieżący stan ukryty \( \mathbf{h}_t \) na podstawie zaktualizowanego stanu komórki \( \mathbf{C}_t \):
    \begin{equation}
        \mathbf{o}_t = \sigma(\mathbf{W}_o [\mathbf{h}_{t-1}, \mathbf{x}_t] + \mathbf{b}_o)
    \end{equation}
    \begin{equation}
        \mathbf{h}_t = \mathbf{o}_t * \tanh(\mathbf{C}_t)
    \end{equation}
    gdzie:
    \begin{itemize}
        \item \( \sigma \) to funkcja aktywacji sigmoidalnej,
        \item \( \tanh \) to funkcja aktywacji tangens hiperboliczny,
        \item \( \mathbf{W}_f, \mathbf{W}_i, \mathbf{W}_C, \mathbf{W}_o \) to macierze wag dla poszczególnych bramek,
        \item \( \mathbf{b}_f, \mathbf{b}_i, \mathbf{b}_C, \mathbf{b}_o \) to wektory obciążeń dla poszczególnych bramek.
    \end{itemize}
\end{enumerate}

Kluczem do skutecznej minimalizacji problemu zanikającego gradientu w LSTM jest mechanizm bramek, który umożliwia selektywne przepuszczanie informacji przez stan komórki \( \mathbf{C}_t \).
Zamiast wielokrotnego mnożenia wag, jak ma to miejsce w tradycyjnych RNN, LSTM wykorzystują operacje dodawania do aktualizacji stanu komórki oraz mnożenia do określenia stopnia zachowania informacji.
Dzięki takiej architekturze, gradienty mogą przepływać przez sieć w sposób bardziej kontrolowany, co znacząco ogranicza ryzyko ich zanikania lub eksplodowania i poprawia stabilność procesu uczenia \cite{goodfellow-et-al-2016}.

\clearpage
\section{Filtr Kalmana}
Sieci neuronowe (w tym LSTM) są potężnymi narzędziami do modelowania danych.
Jednakże w praktyce, dane często zawierają szumy i fluktuacje, które wprowadzają niepożądane błędy w prognozach.
W przypadku cen akcji, takie zakłócenia mogą wynikać z nagłych wydarzeń rynkowo-politycznych, np.: niespodziewanych decyzji regulacyjnych czy kryzysów gospodarczych \cite{brogaard2022what}.

Aby skutecznie zaradzić temu problemowi, stosuje się różne techniki filtracji danych, których celem jest oddzielenie użytecznego sygnału od niepożądanego szumu \cite{welch1995introduction}.
Jedną z zaawansowanych metod filtracji jest filtr Kalmana.
Został on zaproponowany w 1960 roku przez Rudolfa E. Kalmana w pracy "A New Approach to Linear Filtering and Prediction Problems" \cite{kalman1960new}.
Jego pierwszym praktycznym zastosowaniem okazało się śledzenie trajektorii rakiet w programie kosmicznym Apollo.
Od tamtej pory znalazł szerokie zastosowanie w różnych dziedzinach, takich jak robotyka, nawigacja czy ekonomia \cite{welch1995introduction}.

Filtr Kalmana to algorytm rekurencyjny służący do estymacji stanu dynamicznego systemu.
Wykorzystuje on podejście probabilistyczne -- na podstawie modelu matematycznego systemu oraz dostępnych pomiarów, filtr Kalmana optymalnie łączy te dwie informacje, aby uzyskać jak najlepszą estymację stanu systemu.
Działa on w oparciu o cykl dwóch naprzemiennych króków: predykcji i aktualizacji.
W kroku predykcji, na podstawie modelu matematycznego systemu, filtr Kalmana przewiduje stan systemu w następnym kroku czasowym wraz z niepewnością tej predykcji.
W kroku aktualizacji, gdy dostępny jest nowy pomiar, filtr Kalmana koryguje swoją predykcję, uwzględniając zarówno przewidywany stan, jak i nowy pomiar.
Dodatkowo filtr Kalmana oblicza zysk Kalmana, który określa, jak bardzo należy zaufać pomiarowi w porównaniu do predykcji w danym kroku czasowym \cite{welch1995introduction,labbe2015kalman}.

W niniejszym rozdziale przedstawiono matematyczne podstawy filtru Kalmana, opisując jego kluczowe elementy oraz proces działania.

\subsection{Model matematyczny filtru Kalmana}
Proces działania filtru Kalmana można podzielić na trzy główne kroki \cite{welch1995introduction, labbe2015kalman}:
\begin{enumerate}
    \item \textbf{Inicjalizacja stanu:} Na początku (\(k=0\)) definiuje się początkową estymatę stanu systemu \(\mathbf{x}_0\) oraz macierz kowariancji błędu tej estymacji \(\mathbf{P}_0\) \cite{labbe2015kalman}. Jeśli stan początkowy jest nieznany, macierz \(\mathbf{P}_0\) ustawia się na dużą wartość, co odzwierciedla wysoką niepewność.
    
    Kluczowe jest również zdefiniowanie macierzy opisujących model systemu:
    \begin{itemize}
        \item \( \mathbf{F} \) -- \textbf{macierz przejścia stanu}, która opisuje, jak stan systemu zmienia się między krokiem \(k-1\) a \(k\).
        \item \( \mathbf{H} \) -- \textbf{macierz obserwacji}, która mapuje prawdziwy stan systemu \( \mathbf{x}_k \) na przestrzeń pomiarową \( \mathbf{z}_k \).
        \item \( \mathbf{Q} \) -- \textbf{macierz kowariancji szumu procesu}, która reprezentuje niepewność związaną z modelem predykcyjnym.
        \item \( \mathbf{R} \) -- \textbf{macierz kowariancji szumu pomiarowego}, która reprezentuje niepewność związaną z samymi pomiarami.
        \item \( \mathbf{B} \) -- \textbf{macierz sterowania} (opcjonalna), która opisuje wpływ zewnętrznego sterowania \( \mathbf{u}_{k-1} \) na stan systemu.
    \end{itemize}

    \item \textbf{Predykcja:} Na podstawie stanu z poprzedniego kroku \(\mathbf{x}_{k-1}\), wyznacza się przewidywany (a priori) stan systemu \(\mathbf{\hat{x}}_{k}^{-}\) oraz przewidywaną kowariancję błędu \(\mathbf{\hat{P}}_{k}^{-}\) na bieżący krok \(k\) \cite{labbe2015kalman}:
    \begin{equation}
        \mathbf{\hat{x}}_{k}^{-} = \mathbf{F} \mathbf{x}_{k-1} + \mathbf{B} \mathbf{u}_{k-1}
    \end{equation}
    \begin{equation}
        \mathbf{\hat{P}}_{k}^{-} = \mathbf{F} \mathbf{P}_{k-1} \mathbf{F}^T + \mathbf{Q}
    \end{equation}

    \item \textbf{Aktualizacja:} Gdy dostępny jest nowy pomiar \(\mathbf{z}_k\), następuje korekta predykcji. Najpierw oblicza się zysk Kalmana \(\mathbf{K}_k\) \cite{labbe2015kalman}:
    \begin{equation}
        \mathbf{K}_k = \mathbf{\hat{P}}_{k}^{-} \mathbf{H}^T (\mathbf{H} \mathbf{\hat{P}}_{k}^{-} \mathbf{H}^T + \mathbf{R})^{-1}
    \end{equation}
    Następnie, na podstawie zysku Kalmana i różnicy między pomiarem a predykcją, aktualizuje się estymowany (a posteriori) stan \(\mathbf{x}_k\) oraz kowariancję błędu \(\mathbf{P}_k\):
    \begin{equation}
        \mathbf{x}_k = \mathbf{\hat{x}}_{k}^{-} + \mathbf{K}_k (\mathbf{z}_k - \mathbf{H} \mathbf{\hat{x}}_{k}^{-})
    \end{equation}
    \begin{equation}
        \mathbf{P}_k = (\mathbf{I} - \mathbf{K}_k \mathbf{H}) \mathbf{\hat{P}}_{k}^{-}
    \end{equation}
    Zaktualizowane wartości \(\mathbf{x}_k\) oraz \(\mathbf{P}_k\) stają się wartościami wejściowymi (\(\mathbf{x}_{k-1}\), \(\mathbf{P}_{k-1}\)) dla następnego cyklu w kroku \(k+1\).
\end{enumerate}

Rysunek \ref{fig:kalman_filter_cycle} przedstawia schematyczny cykl działania filtru Kalmana, ilustrując kroki predykcji i aktualizacji.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/kalman_filter_cycle.png}
    \caption{Cykl działania filtru Kalmana, ilustrując kroki predykcji i aktualizacji. Opracowanie własne na podstawie \cite{kalman_filter_cycle_drawing}.}
    \label{fig:kalman_filter_cycle}
\end{figure}

W kontekście prognozowania cen akcji, filtr Kalmana może być użyty do filtracji danych w fazie ich wstępnego przetwarzania.
Dzięki temu sieć LSTM otrzymuje czystsze dane wejściowe, co może prowadzić do bardziej trafnych prognoz.
Integracja filtru Kalmana z siecią LSTM pozwala na skuteczne łączenie zalet obu metod: zdolności LSTM do modelowania złożonych zależności czasowych oraz umiejętności filtru Kalmana do redukcji szumów w danych \cite{cheeneebash2007improving}.

%~ Research approach
\clearpage
\section{Metodyka badań}
Celem przeprowadzonych badań było porównanie skuteczności predykcji cen akcji przy użyciu tradycyjnej sieci LSTM oraz sieci LSTM wspomaganej filtrem Kalmana.
Z tego powodu zaprojektowano i zaimplementowano trzy odrębne modele, z których każdy służył weryfikacji innej hipotezy badawczej:
\begin{itemize}
    \item \textbf{Model bazowy (Base Model):} Stanowił punkt odniesienia (ang. \textit{baseline}). Jego zadaniem było prognozowanie cen wyłącznie na podstawie ich historycznych wartości, przy użyciu prostej architektury LSTM.
    \item \textbf{Model wzbogacony (Enriched Model):} Miał na celu weryfikację, czy dostarczenie modelowi dodatkowego kontekstu rynkowego w postaci wskaźników analizy technicznej poprawi jakość predykcji.
    \item \textbf{Model z filtrem Kalmana (Kalman Model):} Służył do zbadania głównej hipotezy pracy -- czy wstępna filtracja danych wejściowych przy użyciu filtru Kalmana pozytywnie wpływa na skuteczność prognoz sieci LSTM.
\end{itemize}
W niniejszym rozdziale przedstawiono szczegółowy opis metodologii badawczej zastosowanej w pracy, obejmujący proces przygotowania danych, implementację modeli, procedurę uczenia, metryki oceny wydajności i sposób ewaluacji.
Cały proces badawczy, od przygotowania danych, przez trening, aż po ewaluację, został zaimplementowany jako zestaw modularnych i powtarzalnych pipeline'ów w ramach frameworku Kedro.

\subsection{Środowisko badawcze}
Do przeprowadzenia eksperymentów wykorzystano język programowania Python 3.12 oraz następujące biblioteki i narzędzia:
\begin{itemize}
    \item \textbf{Pandas:} Biblioteka służąca do manipulacji i analizy danych, w szczególności do pracy z danymi tabelarycznymi i szeregami czasowymi. Została wykorzystana do wczytywania, czyszczenia oraz transformacji danych giełdowych.
    \item \textbf{NumPy:} Podstawowy pakiet do obliczeń naukowych w Pythonie, zapewniający wsparcie dla wielowymiarowych tablic i macierzy oraz szerokiej gamy funkcji matematycznych.
    \item \textbf{PyTorch:} Jedna z wiodących platform do uczenia głębokiego, wykorzystana do zdefiniowania architektury sieci LSTM, implementacji pętli treningowej oraz przeprowadzenia procesu uczenia modeli.
    \item \textbf{Optuna:} Biblioteka do automatycznej optymalizacji hiperparametrów modeli uczenia maszynowego, która została użyta do znalezienia optymalnych wartości takich parametrów jak liczba warstw LSTM, liczba neuronów w warstwach, współczynnik nauki oraz wielkość partii treningowej (batch size).
    \item \textbf{Scikit-learn:} Kompleksowa biblioteka do uczenia maszynowego, z której wykorzystano m.in. narzędzia do skalowania danych (MinMaxScaler) oraz obliczania metryk oceny modeli (MSE, RMSE).
    \item \textbf{FilterPy:} Specjalistyczna biblioteka dostarczająca implementacje różnych algorytmów filtrujących, w tym filtru Kalmana, który został użyty do filtracji danych wejściowych.
    \item \textbf{Technical Analysis (ta):} Biblioteka umożliwiająca obliczanie wskaźników analizy technicznej, które zostały wykorzystane do wzbogacenia zestawu cech wejściowych modeli.
    \item \textbf{Matplotlib \& Seaborn:} Biblioteki do wizualizacji danych, które posłużyły do generowania wszystkich wykresów przedstawionych w pracy, m.in. wykresów cen, krzywych uczenia i porównań predykcji z wartościami rzeczywistymi.
    \item \textbf{yfinance:} Biblioteka umożliwiająca pobieranie historycznych danych rynkowych z serwisu Yahoo! Finance.
    \item \textbf{Kedro:} Framework do tworzenia modularnych i skalowalnych projektów uczenia maszynowego, który został użyty do zarządzania przepływem danych, konfiguracją eksperymentów oraz organizacją kodu źródłowego.
\end{itemize}

\subsection{Przygotowanie danych}
Proces przygotowania danych stanowił pierwszy etap badań.
Jego celem było uzyskanie oczyszczonego i odpowiednio sformatowanego zestawu danych giełdowych spółki Amazon (AMZN), który mógł zostać użyty do trenowania i testowania modeli LSTM.
Proces ten obejmował następujące kroki: pobrania danych, przetwarzania wstępnego, inżynierii cech oraz podziału na zbiory treningowy, walidacyjny i testowy \cite{goodfellow-et-al-2016}.

\subsubsection{Pobranie danych}
Dane historyczne dotyczące cen akcji spółki Amazon zostały pobrane z serwisu Yahoo! Finance przy użyciu biblioteki yfinance.
Zbiór danych objemował dzienne notowania z okresu od 3 stycznia 2022 roku do 11 września 2025 roku.
Każdy rekord w surowym zbiorze danych zawierał informacje OHLC (Open, High, Low, Close), wolumen obrotu oraz datę notowania \cite{yfinance_data}.
Tabela \ref{tab:raw_data_sample} przedstawia przykładowe rekordy z pobranego zbioru danych.
\begin{table}[H]
    \centering
    \caption{Przykładowe rekordy z surowego zbioru danych dla spółki AMZN. Źródło: \cite{yfinance_data}}
    \label{tab:raw_data_sample}
    \begin{tabular}{lrrrrr}
        \hline
        \textbf{Date} & \textbf{Open} & \textbf{High} & \textbf{Low} & \textbf{Close} & \textbf{Volume} \\
        \hline
        2022-01-03 & 170.40 & 170.70 & 166.16 & 167.55 & 63520000 \\
        2022-01-04 & 167.52 & 171.40 & 166.35 & 170.44 & 70726000 \\
        2022-01-05 & 164.36 & 167.13 & 164.36 & 166.88 & 64302000 \\
        2022-01-06 & 163.25 & 164.80 & 161.94 & 163.45 & 51958000 \\
        2022-01-07 & 162.55 & 165.24 & 162.03 & 163.84 & 46606000 \\
        ... & ... & ... & ... \\
        \hline
    \end{tabular}
\end{table}

\subsubsection{Przetwarzanie wstępne i inżynieria cech}
Surowe dane w formie szeregu czasowego nie są bezpośrednio kompatybilne z architekturą sieci LSTM, która oczekuje danych w formacie nadzorowanym, tj. par (sekwencja wejściowa, wartość docelowa). 
W związku z tym, pierwszym krokiem było przekształcenie danych do odpowiedniego formatu, który zawierałby sekwencje historycznych cen jako wejścia oraz odpowiadające im przyszłe ceny jako wartości docelowe \cite{goodfellow-et-al-2016}.
Na potrzeby przeprowadzenia eksperymentów podjęto decyzję uwzględnieniu cen zamknięcia (Close) z trzech poprzednich dni jako cech wejściowych do przewidywania ceny zamknięcia w dniu następnym.
Tabela \ref{tab:formatted_data_sample} przedstawia przykładowe rekordy z przetworzonego zbioru danych.
\begin{table}[H]
    \centering
    \caption{Przykładowa struktura danych po przekształceniu do formatu nadzorowanego.}
    \label{tab:formatted_data_sample}
    \begin{tabular}{cccc}
        \hline
        \textbf{Close} & \textbf{Close (t-1)} & \textbf{Close (t-2)} & \textbf{Close (t-3)} \\
        \hline
        163.25 & 164.36 & 167.52 & 170.40 \\
        162.55 & 163.25 & 164.36 & 167.52 \\
        161.49 & 162.55 & 163.25 & 164.36 \\
        165.36 & 161.49 & 162.55 & 163.25 \\
        165.21 & 165.36 & 161.49 & 162.55 \\
        ... & ... & ... & ... \\
        \hline
    \end{tabular}
\end{table}

Po tym fundamentalnym etapie, który był wspólny dla wszystkich eksperymentów, dalsze kroki przetwarzania i inżynierii cech zostały zróżnicowane. 
Powodem tego była potrzeba przygotowania trzech odrębnych wariantów zbioru danych, z których każdy był dedykowany jednemu z porównywanych modeli.

\begin{enumerate}
    \item \textbf{Zbiór dla modelu bazowego (Base Model):} W tym wariancie nie stosowano zaawansowanej inżynierii cech. Jedyną cechą wejściową była historyczna cena zamknięcia (Close).

    \item \textbf{Zbiór dla modelu wzbogaconego (Enriched Model):} Ten zbiór został rozszerzony o dodatkowe cechy uzyskane w procesie inżynierii cech. Do ceny zamknięcia dołączono trzy wskaźniki analizy technicznej: wskaźnik siły względnej (RSI), szerokość wstęg Bollingera (BBW) oraz procentowe położenie ceny względem wstęg (\%B).

    \item \textbf{Zbiór dla modelu z filtrem Kalmana (Kalman Model):} W tym podejściu cena zamknięcia została poddana procesowi filtracji przy użyciu filtru Kalmana. 
    W ramach implementacji zdefiniowano dwuwymiarowy wektor stanu \(x\), który śledzi zarówno cenę, jak i jej chwilową prędkość (trend):
    \[ x = \begin{bmatrix} \text{cena} \\ \text{prędkość} \end{bmatrix} \]
    Pozostałe parametry filtru przedstawiono poniżej:
    \begin{itemize}
        \item \textbf{Macierz przejścia stanu (F):} Zakładający stałą prędkość zmiany ceny.
        \[ F = \begin{bmatrix} 1 & 1 \\ 0 & 1 \end{bmatrix} \]

        \item \textbf{Macierz pomiaru (H):} Mapująca rzeczywisty stan do przestrzeni pomiarowej.
        \[ H = \begin{bmatrix} 1 & 0 \end{bmatrix} \]

        \item \textbf{Kowariancja błędu estymacji (P):} Ustawiona na wysoką wartość początkową dla prędkości, aby odzwierciedlić niepewność co do trendu cenowego.
        \[ P = \begin{bmatrix} 1 & 0 \\ 0 & 1000 \end{bmatrix} \]

        \item \textbf{Kowariancja szumu pomiarowego (R):} Zdefiniowana jako stała wartość, reprezentująca niepewność pomiaru ceny.
        \[ R = 1.0 \]

        \item \textbf{Kowariancja szumu procesu (Q): } Ustawiona empirycznie na niską wartość.
        \[ Q = \begin{bmatrix} 0.001 & 0 \\ 0 & 0.001 \end{bmatrix} \]
    \end{itemize}
\end{enumerate}

Po zdefiniowaniu cech dla każdego z trzech wariantów, wszystkie zbiory zostały poddane tym samym, końcowym etapom przetwarzania, aby zapewnić spójność i rzetelność porównania.

\subsubsection{Podział danych}
Po zakończeniu wszystkich etapów przetwarzania i inżynierii cech, zbiory danych zostały podzielone na trzy odrębne części:
\begin{itemize}
    \item \textbf{Zbiór treningowy (Training Set):} Obejmuje 72\% danych i służy do trenowania modeli LSTM.
    \item \textbf{Zbiór walidacyjny (Validation Set):} Obejmuje 18\% danych i jest wykorzystywany do monitorowania wydajności modeli podczas treningu oraz do strojenia hiperparametrów.
    \item \textbf{Zbiór testowy (Test Set):} Obejmuje pozostałe 10\% danych i służy do ostatecznej oceny wydajności wytrenowanych modeli.
\end{itemize}
Podział danych został przeprowadzony w sposób chronologiczny, aby zachować naturalną kolejność czasową szeregów danych giełdowych \cite{goodfellow-et-al-2016}.

\subsubsection{Skalowanie danych}
Skalowanie cech wejściowych jest kluczowym krokiem w przygotowaniu danych do trenowania sieci neuronowych -- przyspiesza oraz stabilizuje proces uczenia sieci neuronowej \cite{goodfellow-et-al-2016}.
W ramach ninejszej pracy wykrzystano skalowanie min-max, które przekształca wartości cech do zdefiniowanego zakresu, zazwyczaj od 0 do 1 \cite{goodfellow-et-al-2016}.
Proces skalowania został przeprowadzony przy użyciu klasy `MinMaxScaler` z biblioteki Scikit-learn.

Ważnym aspektem metodologicznym było dopasowanie skalera wyłącznie na danych treningowych. 
Następnie ten sam, dopasowany skaler został użyty do transformacji zarówno zbioru walidacyjnego, jak i testowego. 
Takie podejście zapobiega "przeciekowi danych" (ang. data leakage) z przyszłości do modelu, co jest niezbędne dla uzyskania wiarygodnych i rzetelnych wyników \cite{goodfellow-et-al-2016}.

\subsection{Architektura modeli}
W niniejszej pracy porównano trzy różne modele LSTM, z których każdy charakteryzował się odmiennym podejściem do przetwarzania danych wejściowych.
Wszystkie modele zostały zaimplementowane przy użyciu biblioteki PyTorch, co zapewniło elastyczność i wydajność niezbędną do przeprowadzenia eksperymentów.

Chociaż ogólny schemat tworzenia modeli był wspólny, to jednak poszczególne modele różniły się kluczowymi hiperparametrami architektury, takimi jak wymiar danych wejściowych, liczba warstw LSTM oraz liczba neuronów w warstwach ukrytych. 
Różnice te wynikały z różnicy w charakterystyce danych wejściowych, których dany model miał używać do predykcji cen akcji.
Poniżej przedstawiono szczegółowy opis każdego z trzech modeli.


\subsubsection{Model bazowy (Base Model)}
Model bazowy stanowił najprostszą implementację, zaprojektowaną w celu ustanowienia punktu odniesienia (ang. \textit{baseline}). 
Architektura modelu bazowego składała się z jednej warstwy LSTM z 39 neuronami w warstwie ukrytej, co zapewniało wystarczającą zdolność modelowania prostych zależności czasowych w danych wejściowych.

\subsubsection{Model wzbogacony (Enriched Model)}
Model wzbogacony rozszerzał architekturę modelu bazowego poprzez dodanie trzech wskaźników analizy technicznej (RSI, BBW, \%B) jako dodatkowych cech wejściowych.
Z tego względu zastosowano bardziej złożoną architekturę, obejmującą dwie warstwy LSTM oraz większą liczbę neuronów (96) w warstwach ukrytych.

\subsubsection{Model z filtrem Kalmana (Kalman Model)}
Model ten operował na takich samych danych jak model bazowy, jednak przed podaniem ich na wejście sieci LSTM, dane te były poddawane procesowi filtracji przy użyciu filtru Kalmana.
W wyniku procesu optymalizacji hiperparametrów, jego finalna architektura okazała się nieco bardziej złożona niż w przypadku modelu bazowego, składając się z dwóch warstw LSTM i 41 neuronów w warstwach ukrytych. 
Mimo tych różnic, głównym czynnikiem odróżniającym oba modele pozostał sposób przygotowania danych wejściowych.

\vspace{0.5cm}
Tabela \ref{tab:model_architecture_params} przedstawia zestawienie kluczowych hiperparametrów architektury każdego z modeli, które uzyskano w wyniku procesu optymalizacji.
\begin{table}[H]
    \centering
    \caption{Zestawienie kluczowych hiperparametrów architektury modeli.}
    \label{tab:model_architecture_params}
    \begin{tabular}{lccc}
        \hline
        \textbf{Hiperparametr} & \textbf{Base Model} & \textbf{Enriched Model} & \textbf{Kalman Model} \\
        \hline
        Wymiar wejścia & 1 & 4 & 1 \\
        Liczba warstw LSTM & 1 & 2 & 2 \\
        Liczba neuronów ukrytych & 39 & 96 & 41 \\
        Wymiar wyjścia & 1 & 1 & 1 \\
        \hline
    \end{tabular}
\end{table}

Podsumowując, architektury trzech modeli zostały świadomie zróżnicowane w procesie automatycznego strojenia, aby jak najlepiej dopasować ich złożoność do charakteru danych wejściowych.
Mimo to, porównanie modelu bazowego i modelu z filtrem Kalmana wciąż pozwala na wyciągnięcie wniosków na temat wpływu filtracji, analizując, jak modele o różnej, optymalnej dla siebie złożoności radzą sobie z danymi o różnej charakterystyce.
W kolejnej sekcji opisano proces uczenia i ewaluacji tych modeli.

\subsection{Metryki oceny}
Do monitorowania wydajności modeli w trakcie procesu uczenia oraz do finalnej oceny ich skuteczności na zbiorze testowym, wybrano trzy powszechnie stosowane metryki regresji:
\begin{itemize}
    \item \textbf{Mean Squared Error (MSE):} Miara średniego kwadratu różnic między wartościami przewidywanymi a rzeczywistymi.
    \begin{equation}
        \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
    \end{equation}
    gdzie \( y_i \) to rzeczywista wartość, \( \hat{y}_i \) to wartość przewidywana przez model, a \( n \) to liczba próbek.
    \item \textbf{Root Mean Squared Error (RMSE):} Pierwiastek kwadratowy z MSE, który daje wynik w tych samych jednostkach co dane wejściowe.
    \begin{equation}
        \text{RMSE} = \sqrt{\text{MSE}} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}
    \end{equation}
    gdzie \( y_i \) to rzeczywista wartość, \( \hat{y}_i \) to wartość przewidywana przez model, a \( n \) to liczba próbek.
    \item \textbf{R-squared \(R^2\):} Miara dopasowania modelu, wskazująca, jaka część wariancji danych jest wyjaśniona przez model.
    \begin{equation}
        R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}
    \end{equation}
    gdzie \( y_i \) to rzeczywista wartość, \( \hat{y}_i \) to wartość przewidywana przez model, \( \bar{y} \) to średnia, a \( n \) to liczba próbek.
\end{itemize}

\subsection{Proces uczenia}
Proces uczenia objemował strojenie hiperparametrów, wybór funkcji straty oraz algorytmu optymalizacji, własciwy trening na danych treningowych oraz monitorowanie wydajności na zbiorze walidacyjnym.
Każdy z trzech modeli był trenowany niezależnie, z zastosowaniem tych samych procedur, aby zapewnić odpowiednią porównywalność wyników.

\subsubsection{Strojenie hiperparametrów}
W celu znalezienia optymalnych wartości hiperparametrów dla każdego z modeli, zastosowano bibliotekę Optuna do automatyzacji tego procesu \cite{akiba2019optuna}.
Przeszukiwana przestrzeń hiperparametrów była wspólna dla wszystkich modeli i obejmowała:

Dla modelu bazowego oraz modelu z filtrem Kalmana, które operowały na jednowymiarowych danych wejściowych (tylko cena zamknięcia), przeszukiwana przestrzeń hiperparametrów obejmowała:
\begin{itemize}
    \item \textbf{Liczba warstw LSTM:} wartości całkowite z zakresu [1, 3].
    \item \textbf{Liczba neuronów w warstwach ukrytych:} wartości całkowite z zakresu [20, 50].
    \item \textbf{Współczynnik nauki (learning rate):} wartości z rozkładu logarytmicznego w zakresie [1e-4, 1e-2].
    \item \textbf{Wielkość partii treningowej (batch size):} wybór spośród wartości [8, 16, 32].
    \item \textbf{Liczba epok treningowych:} wartości całkowite z zakresu [10, 50].
\end{itemize}

Z kolei dla modelu wzbogaconego, który przetwarzał czterowymiarowe dane wejściowe (cena zamknięcia oraz trzy wskaźniki techniczne), zdefiniowano szerszą przestrzeń poszukiwań dla kluczowych parametrów architektury, aby umożliwić modelowi dopasowanie się do większej złożoności danych:
\begin{itemize}
    \item \textbf{Liczba warstw LSTM:} wartości całkowite z zakresu [1, 3].
    \item \textbf{Liczba neuronów w warstwach ukrytych:} wartości całkowite z zakresu [50, 100].
    \item \textbf{Współczynnik nauki (learning rate):} wartości z rozkładu logarytmicznego w zakresie [1e-4, 1e-2].
    \item \textbf{Wielkość partii treningowej (batch size):} wybór spośród wartości [8, 16, 32].
    \item \textbf{Liczba epok treningowych:} wartości całkowite z zakresu [20, 80].
\end{itemize}
Dla każdego modelu przeprowadzono 150 prób optymalizacji (ang. \textit{trials}). Najlepsze znalezione zestawy hiperparametrów, które zostały następnie wykorzystane w finalnym treningu modeli, przedstawiono w tabeli \ref{tab:optimal_hyperparams}.
\begin{table}[H]
    \centering
    \caption{Optymalne hiperparametry uzyskane w procesie strojenia dla każdego z modeli.}
    \label{tab:optimal_hyperparams}
    \begin{tabular}{lccc}
        \hline
        \textbf{Hiperparametr} & \textbf{Base Model} & \textbf{Enriched Model} & \textbf{Kalman Model} \\
        \hline
        Liczba warstw LSTM & 1 & 2 & 2 \\
        Liczba neuronów ukrytych & 39 & 96 & 41 \\
        Współczynnik nauki & 0.00107 & 0.00034 & 0.00029 \\
        Wielkość partii treningowej & 32 & 32 & 8 \\
        Liczba epok treningowych & 47 & 78 & 15 \\
        \hline
    \end{tabular}
\end{table}

\subsubsection{Przebieg procesu uczenia}
Proces uczenia modeli przeprowadzono na zbiorze treningowym, stanowiącym 72\% wszystkich danych, wykorzystując zoptymalizowane hiperparametry. 
Jako funkcję kosztu, której wartość była minimalizowana w trakcie uczenia, wybrano błąd średniokwadratowy (MSE). 
Do aktualizacji wag modelu posłużył optymalizator Adam, będący standardem w zadaniach uczenia głębokiego ze względu na jego efektywność i adaptacyjny dobór współczynnika uczenia \cite{kingma2014adam}.

Liczba epok, przez które trenowano każdy model, została również ustalona jako jeden z hiperparametrów w procesie automatycznego strojenia. 
Wydajność modelu w trakcie uczenia była na bieżąco monitorowana na zbiorze walidacyjnym z wykorzystaniem zdefiniowanych wcześniej metryk (MSE, RMSE, \(R^2\)).
Pozwoliło to na generowanie krzywych uczenia i weryfikację, czy model nie wykazuje oznak znacznego przeuczenia (ang. \textit{overfitting}).

Po zakończeniu treningu, wytrenowane modele zostały poddane ewaluacji na zbiorze testowym.

\subsection{Proces ewaluacji}
Finalna ocena modeli została przeprowadzona na zbiorze testowym, który stanowił 10\% wszystkich danych i nie był wykorzystywany podczas treningu ani walidacji.
Celem ewaluacji było uzyskanie porównywalnych wyników wydajności modeli, które odzwierciedlałyby ich zdolność do generalizacji na nieznanych danych.
Do oceny wydajności modeli na zbiorze testowym zastosowano zdefiniowane wcześniej metryki (MSE, RMSE oraz \(R^2\)).
Produktami końcowymi ewaluacji były:
\begin{itemize}
    \item Zestawienie wyników metryk wydajności dla każdego z modeli.
    \item Wykresy porównujące przewidywane ceny akcji z rzeczywistymi wartościami na zbiorze testowym.
    \item Analiza błędów predykcji w postaci histogramów ich rozkładu.
    \item Krzywe uczenia ilustrujące przebieg procesu treningu dla każdego z modeli.
\end{itemize}
Tak przygotowane i zestawione wyniki posłużyły jako podstawa do przeprowadzenia szczegółowej analizy porównawczej, interpretacji rezultatów oraz sformułowania wniosków dotyczących skuteczności poszczególnych podejść.

\vspace{0.5cm}
W tym rozdziale przedstawiono kompleksową metodykę badań, obejmującą proces przygotowania danych, implementację i trenowanie trzech odrębnych modeli LSTM oraz procedurę ich ewaluacji.
Taka struktura przeprowadzenia badania miała na celu zapewnienie rzetelności, powtarzalności i porównywalności wyników.
Rysunek \ref{fig:training_pipeline} stanowi podsumowanie całego procesu uczenia modeli w formie schematu pipeline'u.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{assets/workflow_visualized.png}
    \caption{Schemat zwizualizowanego procesu uczenia modelu. Opracowanie własne.}
    \label{fig:training_pipeline}
\end{figure}

\clearpage
\section{Wyniki badań}
Ninejszy rozdział zawiera zestawienie oraz analizę wyników uzyskanych w ramach przeprowadzanego badania.
Analizę rozpoczyna podsekcja zestawiająca wyniki modelu bazowego stanowiącego punkt odniesienia dla całego eksperymentu.
Następnie, w kontraście do modelu bazowego przedstawione są wyniki modelu wzbogaconego oraz modelu z filtrem Kalmana, które są kluczowe dla weryfikacji postawionych hipotez badawczych.
Całość zamyka podsekcja zestawiająca wyniki wszystkich modeli wraz z wizualizacją wykresów porównujących przewidywane ceny z rzeczywistymi oraz rozkładów błędów predykcji.
Analiza wyników obejmuje również interpretację uzyskanych rezultatów w kontekście postawionych hipotez badawczych.

\subsection{Wyniki modelu bazowego}
Model bazowy, wykorzystujący jedynie historyczne ceny zamknięcia, niesie fundamentalną wartość porównawczą dla całości badania.
Jego celem było ustalenie punktu odniesienia, jakie wyniki jest w stanie osiągnąć stosunkowo prosta architektura LSTM w kontekście przewidywania cen giełdowych.
Tabela \ref{tab:base_model_metrics} przedstawia osiągnięte przez model bazowy metryki.

\begin{table}[H]
    \centering
    \caption{Metryki wydajności modelu bazowego na zbiorze testowym.}
    \label{tab:base_model_metrics}
    \begin{tabular}{lc}
        \hline
        \textbf{Metryka} & \textbf{Wartość} \\
        \hline
        MSE & 26.1835 \\
        RMSE & 5.1169 \\
        \(R^2\) & 0.8403 \\
        \hline
    \end{tabular}
\end{table}

Wyniki modelu bazowego pozwalają na wstępne określenie, że stosunkowo prosta architektura LSTM jest w stanie dobrze poradzić sobie z zadaniem prognozowania cen akcji.

\subsection{Wyniki modelu wzbogaconego}
Model wzbogacony wykorzystywał dodatkowe wskaźniki analizy technicznej (RSI, BBW, \%B) jako cechy wejściowe.
Stanowi on również istotny punkt odniesienia, pozwalający ocenić wpływ dodatkowych cech na zachowanie modelu.
Osiągnięte wartości metryk przez model wzbogacony przedstawia tabela \ref{tab:enhanced_model_metrics}

\begin{table}[H]
    \centering
    \caption{Metryki wydajności modelu wzbogaconego na zbiorze testowym.}
    \label{tab:enhanced_model_metrics}
    \begin{tabular}{lc}
        \hline
        \textbf{Metryka} & \textbf{Wartość} \\
        \hline
        MSE & 31.0509 \\
        RMSE & 5.5723 \\
        \(R^2\) & 0.7892 \\
        \hline
    \end{tabular}
\end{table}

W porównaniu do modelu bazowego, model wzbogacony uzyskał gorsze wyniki we wszystkich analizowanych metrykach.
Błąd RMSE na poziomie 5.5723 sugeruje, że średnie odchylenie prognoz od rzeczywistych cen zamknięcia wynosi około 5.6 jednostek (dolarów).
Wskaźnik \(R^2\) na poziomie 0.7892 oznacza, że model wyjaśnia około 79\% wariancji w danych testowych. 

Uzyskane wyniki sugerują, że dostarczenie modelowi dodatkowych informacji w postaci wskaźników analizy technicznej nie poprawiło, a wręcz pogorszyło jakość predykcji i zdolność generalizacji.
Prawdopodobną przyczyną jest wprowadzenie dodatkowego szumu informacyjnego przez wskaźniki techniczne. 
Wskaźniki te, choć niosą pewien sygnał, same w sobie również podlegają fluktuacjom, co mogło utrudnić sieci neuronowej wyodrębnienie kluczowych wzorców. 

\subsection{Wyniki modelu z filtrem Kalmana}
Trzeci model, stanowiący sedno niniejszej pracy, został wytrenowany na danych wejściowych poddanych wstępnej filtracji za pomocą filtru Kalmana. 
Jego celem była weryfikacja głównej hipotezy badawczej, mówiącej o pozytywnym wpływie filtracji danych na jakość predykcji.
Aby w pełni ocenić skuteczność tego podejścia, przeprowadzono dwuetapową ewaluację. 
Najpierw oceniono, jak dobrze model radzi sobie z przewidywaniem na danych testowych już poddanych filtracji.
Następnie sprawdzono jego wydajność w realistycznym scenariuszu, czyli podczas predykcji na oryginalnych, niefiltrowanych danych testowych. 
Wyniki obu testów przedstawiono w tabeli \ref{tab:kalman_model_metrics}.

\begin{table}[H]
    \centering
    \caption{Metryki wydajności modelu z filtrem Kalmana w zależności od rodzaju zbioru testowego.}
    \label{tab:kalman_model_metrics}
    \begin{tabular}{lccc}
        \hline
        \textbf{Rodzaj testu} & \textbf{MSE} & \textbf{RMSE} & \textbf{\(R^2\)} \\
        \hline
        Test na danych filtrowanych & 7.4117 & 2.7224 & 0.9543 \\
        Test na danych oryginalnych & 30.02485 & 5.4794 & 0.8169 \\
        \hline
    \end{tabular}
\end{table}

W teście na danych filtrowanych model osiągnął rewelacyjną skuteczność -- błąd RMSE wyniósł 2.7224 oraz współczynnik \(R^2\) wynoszący 0.9543. 
Oznacza to, że model był w stanie wyjaśnić ponad 95\% wariancji na danych poddanych filtracji. 
Potwierdza to, że usunięcie szumu za pomocą filtru Kalmana pozwoliło sieci LSTM na nauczenie się bazowego trendu z bardzo wysoką precyzją.

Z kolei w teście na danych oryginalnych, ten sam model wykazał znaczny spadek wydajności -- błąd RMSE wzrósł do 5.4794, a \(R^2\) spadł do 0.8169.
Względem modelu bazowego, wyniki te są bardzo zbliżone, co sugeruje, że model wytrenowany na filtrowanych danych, gdy staje przed zadaniem predykcji w oparciu o oryginalne dane, zachowuje się podobnie do modelu, który od początku uczył się na danych oryginalnych.

Wyniki te potwierdzają hipotezę, że wstępna filtracja danych za pomocą filtru Kalmana znacząco poprawia jakość prognozy, gdy model jest uczony i testowany na przefiltrowanych danych.
Jednakże, w rzeczywistości rynkowej, model ten nie wykazuje przewagi nad modelem bazowym.
Sugeruje to, że choć filtracja może nie być korzystna w przypadku predykcji dokładnych cen akcji, to jednak w przypadku przewidywania następnych ruchów cenowych lub trendów, gdzie szum może mieć mniejsze znaczenie, takie podejście mogłoby przynieść korzyści.


\subsection{Porównanie i analiza wyników}
Przeprowadzone eksperymenty pozwoliły na uzyskanie kompleksowych danych dotyczących wydajności trzech różnych modeli LSTM w kontekście przewidywania cen akcji.
Celem ninejszej podsekcji jest zestawienie i porównanie wyników uzyskanych przez każdy z modeli oraz przeprowadzenie analizy, która pozwoli na wyciągnięcie wniosków dotyczących skuteczności poszczególnych podejść.

\subsubsection{Zestawienie metryk wydajności}
Pierwszym krokiem w analizie jest porównanie kluczowych metryk wydajności (MSE, RMSE, \(R^2\)) uzyskanych przez każdy z modeli na zbiorze testowym.
Tabela \ref{tab:comparison_metrics} przedstawia zestawienie tych metryk dla wszystkich trzech modeli.
Należy podkreślić, że dla modelu z filtrem Kalmana przedstawiono dwa zestawy wyników.
Pierwszy (dane oryginalne) odzwierciedla realistyczny scenariusz, w którym model uczony na danych filtrowanych jest testowany na oryginalnych, niefiltrowanych danych testowych. 
Drugi zestaw (dane filtrowane) pokazuje wydajność tego samego modelu w warunkach laboratoryjnych, czyli podczas testu na danych również poddanych filtracji.

\begin{table}[H]
    \centering
    \caption{Zestawienie metryk wydajności modeli na zbiorze testowym.}
    \label{tab:comparison_metrics}
    \begin{tabular}{lccc}
        \hline
        \textbf{Model} & \textbf{MSE} & \textbf{RMSE} & \textbf{\(R^2\)} \\
        \hline
        Model bazowy & 26.1835 & 5.1169 & 0.8403 \\
        Model wzbogacony & 31.0509 & 5.5723 & 0.7892 \\
        Model z filtrem Kalmana (dane oryginalne) & 30.0248 & 5.4794 & 0.8169 \\
        \hline
        Model z filtrem Kalmana (dane filtrowane) & 7.4117 & 2.7224 & 0.9543 \\
        \hline
    \end{tabular}
\end{table}

Analiza powyższych wyników prowadzi do kilku kluczowych obserwacji:
\begin{enumerate}
    \item Przy testach na danych filtrowanych, model z filtrem Kalmana zdecydowanie przewyższa pozostałe modele pod względem wszystkich metryk.
    \item Model bazowy osiąga najlepsze wyniki spośród modeli testowanych na oryginalnych danych.
    \item Model wzbogacony, mimo dodatkowych cech wejściowych, wykazuje najgorszą wydajność, co sugeruje, że wprowadzenie wskaźników analizy technicznej mogło wprowadzić więcej szumu niż użytecznej informacji.
    \item Model z filtrem Kalmana, gdy jest testowany na oryginalnych danych, osiąga wyniki zbliżone do modelu bazowego, co wskazuje na ograniczoną zdolność do generalizacji na dane niefiltrowane.
\end{enumerate}

\subsubsection{Wizualne porównanie predykcji}
Wizualne zestawienie prognoz (rys. \ref{fig:all_models_comparison}, \ref{fig:kalman_filtered_actual_vs_predicted}) oraz rozkładów błędów predykcji (rys. \ref{fig:all_errors_distribution}) potwierdzają wnioski płynące z analizy metryk.
Wszystkie modele poprawnie podążają za ogólnym trendem cen akcji, jednak różnią się w sposobie odwzorowania krótkoterminowych wahań.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/combined_predictions.png}
    \caption{Porównanie predykcji cen rzeczywistych z prognozami modeli: bazowego, wzbogaconego oraz z filtrem Kalmana.}
    \label{fig:all_models_comparison}
\end{figure}

Na powyższym wykresie widać, że wszystkie modele poprawnie podążają za ogólnym trendem cen akcji. 
Model z filtrem Kalmana wykazuje podobne wyniki do pozostałych modeli, co świadczy, że filtracja nie przyniosła znaczącej przewagi w kontekście predykcji na danych niefiltrowanych.
Z kolei Model wzbogacony, pomimo najgorszych wyników metrycznych, najlepiej poradził sobie z anomalią cenową w okolicach 60 dnia testowego, co sugeruje, że dodatkowe cechy mogły pomóc w uchwyceniu tego nietypowego zachowania.


Aby w pełni zrozumieć potencjał filtracji, na rysunku \ref{fig:kalman_filtered_actual_vs_predicted} przedstawiono wyniki modelu z filtrem Kalmana w laboratoryjnym teście na danych filtrowanych.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/kalman_actual_vs_predicted_filtered.png}
    \caption{Porównanie predykcji cen rzeczywistych z prognozami modelu z filtrem Kalmana na danych filtrowanych.}
    \label{fig:kalman_filtered_actual_vs_predicted}
\end{figure}

Wykres ten doskonale ilustruje, dlaczego model osiągnął tak wysoki współczynnik \(R^2\) (0.9543) w tym scenariuszu. 
Linia predykcji niemal idealnie pokrywa się z przefiltrowanym sygnałem, co dowodzi, że w określonych warunkach, sieć LSTM była w stanie niemal perfekcyjnie nauczyć się bazowego trendu.
Kontrast między rysunkiem \ref{fig:all_models_comparison} a \ref{fig:kalman_filtered_actual_vs_predicted} stanowi wizualny dowód na skuteczność samej filtracji, nawet jeśli nie przełożyło się to na ostateczną przewagę w predykcji na danych oryginalnych.

Dodatkowo, analiza rozkładów błędów (rys. \ref{fig:all_errors_distribution}) dostarcza dalszych informacji.
\begin{figure}[H]
    \centering
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=\linewidth]{assets/base_error_distribution.png}
    \end{minipage}\hfill
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=\linewidth]{assets/enhanced_error_distribution.png}
    \end{minipage}
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=\linewidth]{assets/kalman_error_distribution_filtered.png}
    \end{minipage}\hfill
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=\linewidth]{assets/kalman_error_distribution_original.png}
    \end{minipage}
    \caption{Wizualizacja porównawcza rozkładów błędów predykcji: (góra-lewo) model bazowy, (góra-prawo) model wzbogacony, (dół-lewo) model z filtrem Kalmana na danych filtrowanych, (dół-prawo) model z filtrem Kalmana na danych oryginalnych.}
    \label{fig:all_errors_distribution}
\end{figure}
Histogramy potwierdzają, że model wzbogacony ma najszerszy rozkład błędów, co świadczy o największej niepewności. 
Z kolei najwęższy rozkład błędów prezentuje model Kalmana na danych filtrowanych (dół-lewo), co zgadza z jego doskonałymi wynikami metrycznymi w tym teście.
Kluczowe jest jednak zwrócenie uwagi na rozkład błędów modelu Kalmana na danych oryginalnych (dół-prawo), który jest zbliżony do rozkładu modelu bazowego (góra-lewo) oraz modelu wzbogaconego (góra-prawo), co ponownie podkreśla ograniczoną zdolność do generalizacji na niefiltrowane dane.

\clearpage
\subsection{Dyskusja i wnioski końcowe}
Analiza porównawcza jednoznacznie wskazuje, że w przeprowadzonym badaniu najskuteczniejszym podejściem okazał się model bazowy. 
Jego prosta architektura, operująca wyłącznie na historycznych cenach zamknięcia, była w stanie najwierniej odwzorować dynamikę cen akcji spółki Amazon.com Inc w badanym okresie.

Wynik modelu wzbogaconego sugeruje, że wskaźniki analizy technicznej dodały modelowi pewnej wiedzy o dynamice rynku, co pozwoliło mu lepiej reagować na nietypowe zdarzenia cenowe. 
Jednakże, dodatkowe cechy mogły również wprowadzić pewną dozę szumu informacyjnego, co poskutkowało pogorszeniem wydajności modelu względem pozostałych podejść.
Sieć neuronowa, zamiast skupić się na głównym sygnale cenowym, modelowała również wahania wskaźników, co doprowadziło do pogorszenia wyników.

Najciekawsze wnioski płyną z analizy modelu z filtrem Kalmana. Mimo że nie pokonał on modelu bazowego w realistycznym teście, jego rewelacyjne wyniki na danych filtrowanych (RMSE 2.7224, \(R^2\) 0.9543) dowodzą, że filtracja skutecznie usuwa szum i pozwala sieci LSTM na niemal perfekcyjne nauczenie się bazowego trendu. 
Fakt, że model ten nie przełożył tej wiedzy na lepsze prognozy danych niefiltrowanych, otwiera pole do dalszych badań -- być może zamiast prognozować dokładną cenę, model wytrenowany na filtrowanym sygnale mógłby być znacznie skuteczniejszy w zadaniach takich jak prognozowanie kierunku zmiany ceny lub identyfikacja punktów zwrotnych na rynku.

Tym samym główna hipoteza pracy została potwierdzona częściowo -- filtracja Kalmana drastycznie poprawia zdolność modelu do nauki trendu, jednak w bezpośredniej predykcji oryginalnych cen nie gwarantuje przewagi nad prostszym wariantem modelu.


%~ Summary
\clearpage
\section{Podsumowanie}

Celem ninejszej pracy dyplomowej było zbadanie wpływu zastosowania filtracji Kalmana na skuteczność sieci LSTM w zadaniu prognozowania cen akcji.
W ramach przeprowadzonych eksperymentów porównano trzy modele o różnej architekturze i charakterystyce danych wejściowych, aby zweryfikować postawione hipotezy badawcze.
Pierwszym z nich był model bazowy, operujący wyłącznie na historycznych cenach zamknięcia (Close).
Drugim modelem był model wzbogacony, który rozszerzał architekturę o dodatkowe cechy (RSI, BBW, \%B).
Ostatnim modelem był model z filtrem Kalmana, który uczył się na takich samych danych jak model bazowy, z tą różnicą, że dane te były wcześniej poddane procesowi filtracji.

Analiza wyników dostarczyła kluczowych informacji na temat skuteczności poszczególnych podejść i pozwoliła na wyciągnięcie istotnych wniosków w kontekście postawionej hipotezy badawczej.
W realistycznym scenariuszu testowym, model bazowy okazał się najskuteczniejszy, osiągając najlepsze wyniki we wszystkich analizowanych metrykach (MSE, RMSE, \(R^2\)).
Model wzbogacony, pomimo dostępu do dodatkowych informacji o dynamice rynku, wykazał się najgorszą wydajnością, co sugeruje, że wprowadzenie wskaźników analizy technicznej mogło wprowadzić więcej szumu niż użytecznej informacji.
Jednak ten sam model lepiej poradził sobie z nietypowymi zdarzeniami cenowymi, co wskazuje na potencjalne korzyści z wykorzystania dodatkowych cech w specyficznych sytuacjach.

Najważniejszych wyników dostarczył model z filtrem Kalmana.
W teście na danych filtrowanych osiągnął on rewelacyjną skuteczność, niemal perfekcyjnie odwzorowując bazowy trend cen akcji.
Jednakże, w teście na oryginalnych, niefiltrowanych danych, jego wydajność była zbliżona do modelu bazowego, co wskazywało na ograniczoną zdolność do generalizacji na niefiltrowane dane.
Fakt, że model ten nie przełożył tej wiedzy na lepsze prognozy danych niefiltrowanych, stanowi sedno odkryć tej pracy i jednocześnie otwiera pole do dalszych badań.

Należy zaznaczyć, że przeprowadzone badania ograniczały się do analizy danych jednej spółki (Amazon.com Inc) w konkretnym okresie.
Otrzymanych wyników nie można w pełni generalizować na inne instrumenty finansowe czy odmienne warunki rynkowe.
Mimo to, ciekawe rezultaty modelu z zastosowaniem filtracji Kalmana wskazują na obiecujące kierunki dla przyszłych badań.
Zamiast prognozować dokładną wartość ceny, model wytrenowany na filtrowanym sygnale mógłby okazać się znacznie skuteczniejszy w zadaniach klasyfikacyjnych, takich jak przewidywanie rynkowego kierunku zmiany ceny.
W takich zastosowaniach zdolność do ignorowania krótkoterminowego szumu i koncentracji na głównym trendzie mogłaby okazać się decydującą przewagą.

Ostatecznie, praca ta częściowo potwierdza postawioną hipotezę badawczą.
Zastosowanie filtracji Kalmana na etapie przetwarzania danych wejściowych znacząco poprawia zdolność modelu do nauki bazowego trendu cen akcji,
jednak w bezpośredniej predykcji oryginalnych cen nie gwarantuje przewagi nad prostszym wariantem modelu.


\clearpage
\begin{spacing}{1.0}
    \listoffigures
    \listoftables
\end{spacing}

% %~ Bibliography
\clearpage
\bibliographystyle{unsrt}
\bibliography{references}

\section*{Dodatki}
\subsection*{Kod źródłowy}
Cały kod źródłowy projektu, obejmujący implementację modeli, proces przygotowania danych, uczenia oraz ewaluacji, jest dostępny publicznie w repozytorium GitHub pod adresem:
\begin{center}
    \url{https://github.com/EmD4blju/kalman_stock_prediction}
\end{center}


\end{document}
