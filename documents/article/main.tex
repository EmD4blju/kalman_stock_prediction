\documentclass[12pt]{article}

%~ Packages
\usepackage{amsmath}   % For math
\usepackage{graphicx}  % For images
\usepackage{float}     % For stronger figure placement
\usepackage{hyperref}  % For links
\usepackage[T1]{fontenc}
\usepackage{geometry} % For margins
\usepackage[utf8]{inputenc} % Polish characters
\usepackage[polish]{babel} % Polish language support
\usepackage{times} % Use Times font
\usepackage{indentfirst} % Indent first paragraph after section
\usepackage{titlesec} % Customize section titles
\usepackage{float}     % For stronger figure placement
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

%~ Document settings
\geometry{a4paper, margin=2.5cm}
% \renewcommand{\familydefault}{\sfdefault} % Switched to Times

% Adjust justification to prevent overfull boxes without hyphenation
\tolerance=1000
\emergencystretch=\maxdimen
\hyphenpenalty=10000
\hbadness=10000

%~ Section formatting
\titleformat{\section}{\Large\bfseries}{\thesection.}{1em}{}
\titleformat{\subsection}{\large\bfseries}{\thesubsection.}{1em}{}


%~ Document
\begin{document}

%~ Main Page
\begin{titlepage}
    \centering
    
    \includegraphics[width=0.4\textwidth]{assets/PJATK_PL_sygnet.png}

    {\Large Polsko-Japońska Akademia Technik Komputerowych}
    
    \vspace{0.5cm}
    
    {\large Wydział Informatyki}
    
    \vspace{2cm}
    
    {\huge\bfseries Zastosowanie filtrów Kalmana do poprawy predykcji cen giełdowych przy użyciu sieci LSTM}
    
    \vspace{2cm}
    
    {\Large Praca Dyplomowa}
    
    \vspace{2cm}
    
    \begin{flushleft}
    \begin{tabular}{ll}
        \textbf{Autor:} & Mikołaj Warda (s28034) \\
        \textbf{Kierunek studiów:} & Informatyka \\
        \textbf{Specjalizacja:} & Data Science \\
        \textbf{Promotor:} & dr Sinh Hoa Nguyen Thi \\
    \end{tabular}
    \end{flushleft}
    
    \vfill
    
    {\large \today}
    
\end{titlepage}

%~ Table of Contents
\tableofcontents
\clearpage

%~ Abstract
\begin{abstract}
    
\end{abstract}
\clearpage

%~ Introduction
\section{Wstęp}

Prognozowanie cen akcji odgrywa kluczową rolę w finansach, wspierając inwestorów w podejmowaniu świadomych decyzji zarządzania swoim portfolio.
Chaotyczny charakter rynków sprawia jednak, że trafne przewidywanie notowań pozostaje trudnym zadaniem.
Tradycyjna analiza techniczna bywa niewystarczająca - jest wrażliwa na szum, a wnioski często zawierają element subiektywności \cite{TODO_general_finanse_predicting}.

W ostatnich latach dynamiczny rozwój uczenia maszynowego, zwłaszcza sieci neuronowych, 
znacząco zmienił podejście do modelowania danych czasowych (w tym giełdowych).
Architektury takie jak LSTM (Long Short-Term Memory) potrafią uchwycić złożone zależności i długookresowe relacje w danych, 
co czyni je obiecującymi narzędziami do prognozowania cen \cite{TODO_LSTM_paper}.
Niemniej jednak ich skuteczność nadal zależy od jakości danych wejściowych.
Głównym problemem, jest wysoka wrażliwość na losowe wahania, które są nieodłącznym elementem danych finansowych. 
Te zniekształcenia wynikają z nieprzewidywalnych zdarzeń rynkowych.
Model, zamiast uczyć się rzeczywistych trendów, modeluje wspomniane zakłócenia, 
obniżając swoją zdolność do generalizacji na nowych danych. 
W rezultacie, predykcje mogą być obarczone znacznym błędem, 
co podważa ich użyteczność w podejmowaniu decyzji inwestycyjnych \cite{TODO_LSTM_problem}.

Można temu zapobiegać stosując techniki filtracji na danych wejściowych.
Jednym z klasycznych narzędzi tego typu jest filtr Kalmana,
który może pełnić rolę modułu wygładzania i korekty obserwacji, podnosząc stabilność i dokładność predykcji.
Trenowanie sieci neuronowej na przefiltrowanych danych przy użyciu filtra Kalmana może zredukować wpływ szumu, 
pozwalając na lepsze uchwycenie istotnych wzorców i trendów w danych \cite{TODO_KalmanFilter_paper, TODO_FilteringInfluenceOnLearning}.

W ramach niniejszej pracy dyplomowej, podjęto się zbadania skuteczności zastosowania filtru Kalmana jako etapu przetwarzania danych dla modeli LSTM w kontekście prognozowania cen akcji spółki Amazon.com Inc (AMZN) .
Wybór tematu pracy wyniknął z chęci zdobycia wiedzy na temat działania architektury LSTM oraz zbadania wpływu filtracji danych na jakość prognoz.
Dodatkową motywacją była możliwość wszechstronnego rozwoju ze względu na złożony charakter problemu, łączącego zagadnienia z dziedziny uczenia maszynowego, analizy szeregów czasowych oraz teorii filtrów.

W dalszej części pracy, w sekcji \textit{"Podstawy teoretyczne"}, przedstawiono wszelkie niezbędne pojęcia związane z tematem pracy i przebiegiem badań ze szczególnym naciskiem na architekturę sieci LSTM oraz filtr Kalmana.
Następnie, w sekcji \textit{"Metodyka badań"}, opisano podejście badawcze, w tym przygotowanie danych, implementację modelu, metryki oceny oraz wykorzystane narzędzia.
Kolejna sekcja \textit{"Wyniki i dyskusja"} prezentuje uzyskane wyniki eksperymentów wraz z ich analizą i interpretacją.
Na zakończenie, w sekcji \textit{"Podsumowanie i wnioski"}, podsumowano przeprowadzone badania, przedstawiono kluczowe wnioski oraz zasugerowano kierunki dalszych badań w tym obszarze.

%~ Fundamentals
\clearpage
\section{Podstawy teoretyczne}
\subsection{Przewidywanie szeregów czasowych na rynkach finansowych}
Dane finansowe, takie jak np. ceny akcji, zawierają obserwacje tworzące szeregi czasowe.
Innymi słowy, są to dane, które reprezentują zmiany wartości w określonych odstępach czasu.
Formalnie szeregiem czasowym określa się zbiór uporządkowanych obserwacji w czasie, gdzie każda obserwacja jest powiązana z określoną chwilą czasową \cite{TODO_time_series_definition}:
\begin{equation}
    X = \{x_1, x_2, x_3, \ldots, x_n\}
\end{equation}
gdzie \( x_i \) reprezentuje wartość obserwacji w czasie \( t_i \), a \( n \) to liczba obserwacji w szeregu czasowym.

Abstrahując od rynków finansowych, przedstawiono kilka przykładów szeregów czasowych z innych dziedzin, celem lepszego zobrazowania tej koncepcji:
\begin{itemize}
    \item \textbf{Energetyka:} Godzinowe zużycie energii elektrycznej
    \item \textbf{Meteorologia:} Codzienny pomiar temperatury
    \item \textbf{Sport:} Wyniki meczów drużyny na przestrzeni sezonu
\end{itemize}

Najczęściej spotykanym formatem danych finansowych są tzw. dane OHLC.
Przedstawione w takiej postaci informacje tworzą szereg czasowy, w którym każda obserwacja składa się z czterech części \cite{TODO_OHLC_definition}:
\begin{itemize}
    \item \textbf{Open (O):} Cena otwarcia - cena, po której dany instrument finansowy rozpoczął notowania w danym okresie.
    \item \textbf{High (H):} Cena najwyższa - najwyższa cena osiągnięta przez instrument finansowy w danym okresie.
    \item \textbf{Low (L):} Cena najniższa - najniższa cena osiągnięta przez instrument finansowy w danym okresie.
    \item \textbf{Close (C):} Cena zamknięcia - cena, po której instrument finansowy zakończył notowania w danym okresie.
\end{itemize}
Na potrzeby tej pracy, wykorzystano składnik \textit{Close}, ze względu na jego powszechne wykorzystanie w analizie i prognozie cen akcji \cite{TODO_Close_price_usage}.

Rysunek \ref{fig:amzn_stock_prices} przedstawia przykładowy wykres cenowy względem składnika \textit{Close} spółki Amazon.com Inc (AMZN) na przestrzeni kilku lat w odstępach dziennych. 
Dane przedstawione na wykresie są nieregularne i zawierają liczne fluktuacje, co jest charakterystyczne dla danych finansowych.
Ta wysoka zmienność stanowi główne wyzwanie dla modeli predykcyjnych, co motywuje do poszukiwania skutecznych metod filtrujących \cite{TODO_LSTM_problem}.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/amzn_stock.png}
    \caption{Wykres cenowy względem składnika \textit{Close} Amazon.com Inc (AMZN) w latach 2022-2025. Źródło danych: Yahoo Finance \cite{TODO_YahooFinance}.}
    \label{fig:amzn_stock_prices}
\end{figure}

Tradycyjnie analiza danych rynkowych opierała się o wskaźniki techniczne. 
Można je określić mianem narzędzi statystycznych reprezentujących różne aspekty zachowań cen \cite{TODO_technical_indicators_paper}.
W niniejszej pracy wykorzystano trzy wskaźniki techniczne, które opisano w następnych podsekcjach.

\subsubsection{Wskaźnik siły względnej (Relative Strength Index, RSI)}
Wskaźnik siły względnej (RSI) to popularny wskaźnik techniczny używany do oceny siły i prędkości zmian cen aktywów finansowych \cite{TODO_RSI_paper}.
Wyraża się go wzorem:
\begin{equation}
    RSI = 100 - \frac{100}{1 + RS}
\end{equation}
gdzie \( RS \) (Relative Strength) to stosunek średnich wzrostów do średnich spadków cen w określonym czasie. Według badań, optymalny okres do obliczania RSI wynosi 14 dni \cite{TODO_RSI_paper}.

Produktem końcowym RSI jest liczba z zakresu od 0 do 100, która interpretowana jest następująco:
\begin{itemize}
    \item Wartości powyżej 70 sugerują, że akcja jest wykupiona i może nastąpić spadek cen.
    \item Wartości poniżej 30 sugerują, że akcja jest wyprzedana i może nastąpić wzrost cen.
    \item Wartości pomiędzy 30 a 70 wskazują na neutralny stan rynku.
\end{itemize}

\subsubsection{Wstęgi Bollingera (Bollinger Bands)}
Wstęgi Bollingera to narzędzie analizy technicznej, dostarczające informacji o zmienności rynku \cite{TODO_bollinger_bands_paper}. 
Składaja się z trzech linii na wykresie cenowym:
\begin{itemize}
    \item \textbf{Środkowa linia:} Prosta średnia krocząca (SMA) obliczona na podstawie cen zamknięcia w określonym czasie. Najczęsciej używanym okresem jest 20 dni.
    \item \textbf{Górna wstęga:} Obliczana jako suma wartości środkowej linii i dwukrotności odchylenia standardowego cen w tym okresie.
    \item \textbf{Dolna wstęga:} Obliczana jako różnica wartości środkowej linii i dwukrotności odchylenia standardowego cen w tym okresie.
\end{itemize}
Na podstawie ww. składowych można zinterpretować dwie nowe miary, które zostały wykorzystane w niniejszej pracy:
\begin{itemize}
    \item \textbf{Bollinger Bandwidth (BBW):} Miara szerokości wstęg Bollingera, obliczana jako stosunek różnicy między górną a dolną wstęgą do środkowej linii \cite{TODO_bollinger_bands_paper}:
    \begin{equation}
        BBW = \frac{Upper Band - Lower Band}{Middle Line}
    \end{equation}
    \item \textbf{Bollinger \%B (BB\%):} Miara położenia ceny względem wstęg Bollingera, obliczana jako stosunek różnicy między ceną zamknięcia a dolną wstęgą do różnicy między górną a dolną wstęgą \cite{TODO_bollinger_bands_paper}:
    \begin{equation}
        BB\% = \frac{Close - Lower Band}{Upper Band - Lower Band}
    \end{equation}
\end{itemize}

Opisane powyżej wskaźniki techniczne - RSI, BBW oraz BB\% - dostarczają cennych informacji o dynamice rynku. 
W tradycyjnej analizie mogą posłużyć do subiektywnej interpretacji przez analityków.
W nowoczesnych podejściach, opartych na modelach uczenia maszynowego, 
można je wykorzystać do wzbogacenia danych o dodatkowe cechy, co potencjalnie może poprawić jakość prognoz \cite{TODO_dataset_enrichment_indicators}.

\subsection{Sieci neuronowe w prognozowaniu rynków finansowych}

Wraz z rozwojem mocy obliczeniowej i technik uczenia maszynowego, pojawiły się bardziej zaawansowane metody analizy i prognozowania w dziedzinie finansów \cite{TODO_better_methods_on_market_predictions}.
Do najpopularniejszych podejść należą sieci rekurencyjne (RNN), w tym ich zaawansowane warianty, takie jak \textit{LSTM} (Long Short-Term Memory).
Sieci te są zdolne do uchwycenia złożonych wzorców i zależności w szeregach czasowych \cite{TODO_RNN_paper, TODO_LSTM_paper}.

W niniejszej sekcji zostały omówione podstawy działania sieci neuronowych. 
Przedstawiona została budowa pojedynczego neuronu wchodzącego w skład sieci, kluczowe algorytmy uczenia oraz architektura LSTM.

\subsubsection{Podstawy działania sztucznego neuronu}
Ważnym kamieniem milowym w dziedzinie uczenia maszynowego było wprowadzenie matematycznego modelu neuronu przez McCullocha i Pitts'a w 1943 roku \cite{TODO_neuron_McCulloch_Pitts}.
Współcześnie można mówić o różnych architekturach takiego neuronu, jednak ich podstawowa zasada działania pozostaje podobna.

Neuron otrzymuje na wejściu sygnały \( x_1, x_2, \ldots, x_n \), które są ważone przez odpowiednie wagi \( w_1, w_2, \ldots, w_n \).
Następnie, sumuje te ważone sygnały i dodaje do nich wartość obciążenia (bias) \( b \) \cite{TODO_how_neurons_process_signals}:
\begin{equation}
    z = \sum_{i=1}^{n} w_i x_i + b
\end{equation}

Otrzymana wartość \( z \), zwana logitem (surowym wyjściem) neuronu, jest następnie przekształcana przez funkcję aktywacji \( f(z) \) \cite{TODO_how_neurons_process_signals}:
\begin{equation}
    \hat{y} = f(z) = f(\sum_{i=1}^{n} w_i x_i + b)
\end{equation}

Funkcja aktywacji modyfikuje logit \( z \), produkując finalne wyjście neuronu \( \hat{y} \) -- stopień aktywacji.
W zależności od zastosowanej funkcji aktywacji, wyjście może przyjmować różne formy \cite{TODO_activation_function_overview}.
Tą różnicę najprościej zilustrować na przykładzie dwóch popularnych funkcji aktywacji:
\begin{itemize}
    \item \textbf{Funkcja skokowa:}
    \begin{equation}
        f(z) = 
        \begin{cases}
            1 & \text{jeśli } z \geq 0 \\
            0 & \text{jeśli } z < 0
        \end{cases}
    \end{equation}
    W tym przypadku, wyjście neuronu jest binarne. 
    Innymi słowy, neuron zostanie albo aktywowany (1), albo nieaktywowany (0), w zależności od tego, czy logit \( z \) przekracza pewien próg (w tym przypadku 0) \cite{TODO_step_function_overview}.
    \item \textbf{Funkcja sigmoidalna:}
    \begin{equation}
        f(z) = \frac{1}{1 + e^{-z}}
    \end{equation}
    W tym przypadku, wyjście neuronu jest ciągłe i mieści się w zakresie od 0 do 1.
    Oznacza to, że neuron może przyjmować różne poziomy aktywacji, co pozwala na wyrażenie stopnia pewności co do wyniku \cite{TODO_sigmoid_function_overview}.
\end{itemize}
Rysunek \ref{fig:step_sigmoid_comparison} przedstawia porównanie ww. funkcji aktywacji.
Po lewej stronie znajduje się wykres funkcji skokowej, gdzie wyjście nagle zmienia się z 0 na 1 w punkcie \( z=0 \).
Po prawej stronie znajduje się wykres funkcji sigmoidalnej, gdzie wyjście zmienia się stopniowo od 0 do 1 wraz ze wzrostem wartości \( z \).
\begin{figure}[H]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{assets/step_figure.png}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{assets/sigmoid_figure.png}
    \end{minipage}
    \caption{Porównanie funkcji aktywacji: (po lewej) funkcja skokowa, (po prawej) funkcja sigmoidalna. Opracownanie własne przy użyciu Matplotlib.}
    \label{fig:step_sigmoid_comparison}
\end{figure}
Istnieje wiele innych funkcji aktywacji (np. ReLU, tanh, softmax), a każda z nich ma swoje unikalne właściwości i zastosowania \cite{TODO_activation_function_overview}.
W przypadku funkcji skokowej, neuron podejmuje twardą decyzję, aktywując się w pełni lub wcale.
Przez brak elastyczności, funkcja ta nie pozwala na wyrażenie przekonania co do wyniku \cite{TODO_step_function_overview}.
W przeciwieństwie do niej, funkcja sigmoidalna umożliwia płynną aktywację, pozwalając uwzględnić stopień pewności \cite{TODO_sigmoid_function_overview}.

Znając rolę funkcji aktywacji, można lepiej wyjaśnić działanie parametrów uczonych neuronu, czyli wag \( w_i \) oraz obciążenia \( b \).

Wagi określają, jak duży wpływ ma każdy sygnał wejściowy \( x_i \) na logit \( z \).
Poprzez modelowanie wag, w trakcie procesu uczenia, neuron może nauczyć się, które cechy wejściowe są bardziej istotne dla danego zadania \cite{TODO_weights}.

Rysunek \ref{fig:sigmoid_weights_combined} przedstawia wpływ różnych wartości wagi \( w \) na funkcję sigmoidalną w neuronie z jednym wejściem i bez obciążenia.
Po lewej stronie znajduje się wykres dla małej wagi \( w=0.1 \), gdzie funkcja zmienia się powoli i ma łagodne nachylenie.
Po prawej stronie znajduje się wykres dla dużej wagi \( w=2.0 \), gdzie funkcja zmienia się gwałtownie i ma strome nachylenie.
Można zaobserwować, że wraz ze wzrostem wartości wagi, funkcja sigmoidalna zaczyna przypominać funkcję skokową.
Oznacza to, że neuron staje się pewniejszy swoich decyzji, aktywując się niemal natychmiast po przekroczeniu progu.

\begin{figure}[H]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{assets/sigmoid_w_min_figure.png}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{assets/sigmoid_w_max_figure.png}
    \end{minipage}
    \caption{Wpływ wartości wagi (w) na kształt funkcji sigmoidalnej: (po lewej) \(w=0.1\), (po prawej) \(w=2.0\). Opracowanie własne przy użyciu Matplotlib.}
    \label{fig:sigmoid_weights_combined}
\end{figure}

Drugim kluczowym parametrem jest obciążenie, czyli bias \( b \), który przesuwa próg funkcji aktywacji wzdłuż osi poziomej.
W istocie umożliwia to opóźnienie lub przyspieszenie momentu, w którym neuron zostaje aktywowany \cite{TODO_bias}.

Rysunek \ref{fig:sigmoid_bias_combined} przedstawia wpływ różnych wartości biasu \( b \) na kształt funkcji sigmoidalnej w neuronie z jednym wejściem i wagą \( w=0.1 \).
\begin{figure}[H]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{assets/sigmoid_b_min_figure.png}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{assets/sigmoid_b_max_figure.png}
    \end{minipage}
    \caption{Wpływ wartości bias (b) na kształt funkcji sigmoidalnej: (po lewej) \(b=-2.82\), (po prawej) \(b=4.21\).}
    \label{fig:sigmoid_bias_combined}
\end{figure}

Opisane powyżej parametry -- wagi \( w_i \), obciążenie \( b \) oraz funkcja aktywacji \( f(z) \) - stanowią podstawę działania sztucznego neuronu \cite{TODO_weights_bias_importance}.

Rysunek \ref{fig:neuron_architecture} podsumowuje budowę sztucznego neuronu, ilustrując jak sygnały wejściowe są przetwarzane przez wagę, sumowane z obciążeniem i przekształcane przez funkcję aktywacji.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/neuron.png}
    % Andrut, Krzysztof Zajączkowski, \href{https://commons.wikimedia.org/wiki/File:Neuron_McCullocha-Pittsa.svg}{Wikimedia Commons}, licencja \href{https://creativecommons.org/licenses/by-sa/2.5/deed.pl}{CC BY-SA 2.5}.
    \caption[Schemat budowy sztucznego neuronu]{Schemat budowy sztucznego neuronu. Źródło: \cite{wikimedia_neuron_mcculloch_pitts}}
    \label{fig:neuron_architecture}
\end{figure}

Niestety pojedyczny neuron jest ograniczony w swoich możliwościach -- może nauczyć się jedynie prostych zależności liniowo-separowalnych.
Inaczej mówiąc, jest w stanie rozróżnić tylko te wzorce, które można oddzielić prostą linią w przestrzeni cech.
Aby radzić sobie z bardziej złożonymi problemami, konieczne jest łączenie wielu neuronów w wielowarstwowe struktury \cite{TODO_single_neuron_limitations}.

\subsubsection{Architektura sieci neuronowej}

W celu modelowania bardziej złożonych zależności, łączy się wiele neuronów w struktury zwane sieciami neuronowymi.
Składają się one z warstw, gdzie każda warstwa zawiera wiele neuronów.
Typowa sieć neuronowa składa się z trzech głównych typów warstw \cite{TODO_nn}:
\begin{enumerate}
    \item \textbf{Warstwa wejściowa:} Odpowiada za przyjmowanie danych wejściowych.
    \item \textbf{Warstwy ukryte:} Przetwarzają dane poprzez zestaw neuronów, ucząc się złożonych wzorców.
    \item \textbf{Warstwa wyjściowa:} Generuje ostateczne prognozy lub klasyfikacje na podstawie przetworzonych danych.
\end{enumerate}
Warstwy można łączyć na różne sposoby, np. poprzez pełne łączenie, konwolucje czy rekurencje \cite{TODO_alternative_ways_connecting_layers}.
W przypadku pełnego łączenia tworzy się połączenia każdego neuronu z jednej warstwy do każdego neuronu w następnej warstwie \cite{TODO_dense_layer}.
Przepływ sygnału w takiej sieci odbywa się na zasadzie propagacji w przód (ang. forward propagation) -- od warstwy wejściowej, przez warstwy ukryte, aż do warstwy wyjściowej.
\clearpage
Formalnie ten proces można opisać krokami obliczeniowymi dla każdej warstwy \cite{TODO_forward_propagation}:
\begin{enumerate}
    \item \textbf{Warstwa wejściowa:}
    \begin{equation}
        \mathbf{a}^{(0)} = \mathbf{x}
    \end{equation}
    \item \textbf{Warstwy ukryte:}
    \begin{equation}
        \mathbf{a}^{(l)} = f(\mathbf{W}^{(l)} \mathbf{a}^{(l-1)} + \mathbf{b}^{(l)}) \quad \text{dla } l = 1, 2, \ldots, L-1
    \end{equation}
    \item \textbf{Warstwa wyjściowa:}
    \begin{equation}
        \mathbf{\hat{y}} = g(\mathbf{W}^{(L)} \mathbf{a}^{(L-1)} + \mathbf{b}^{(L)})
    \end{equation}
    gdzie:
    \begin{itemize}
        \item \( \mathbf{x} \) to wektor danych wejściowych,
        \item \( \mathbf{\hat{y}} \) to wektor danych wyjściowych (prognoz),
        \item \( \mathbf{a}^{(l)} \) to aktywacje (wyjścia) warstwy \( l \),
        \item \( \mathbf{W}^{(l)} \) to macierz wag warstwy \( l \),
        \item \( \mathbf{b}^{(l)} \) to wektor obciążeń warstwy \( l \),
        \item \( f \) to funkcja aktywacji dla warstw ukrytych,
        \item \( g \) to funkcja aktywacji dla warstwy wyjściowej,
        \item \( L \) to liczba warstw w sieci.
    \end{itemize}
\end{enumerate}

Rysunek \ref{fig:nn_architecture} przedstawia schematyczną budowę prostej sieci neuronowej z jedną warstwą wejściową, dwiema warstwami ukrytymi i jedną warstwą wyjściową.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/nn.png}
    \caption{Budowa prostej sieci neuronowej z jedną warstwą wejściową, dwiema warstwami ukrytymi i jedną warstwą wyjściową. Opracowanie własne na podstawie \href{https://media.geeksforgeeks.org/wp-content/uploads/20250923121847731542/Neural-Networks-Architecture.webp}{GeeksforGeeks}.}
    \label{fig:nn_architecture}
\end{figure}

Przedstawiona architektura oraz proces propagacji w przód definiują przepływ informacji w sieci neuronowej w celu generowania prognoz \cite{TODO_nn, TODO_forward_propagation}.
Jednakże aby prognoza była trafna, parametry sieci -- wartości wag \( \mathbf{W}^{(l)} \) oraz obciążeń \( \mathbf{b}^{(l)} \) -- muszą zostać odpowiednio dobrane \cite{TODO_weights_bias_importance}.
Ten proces nazywany jest uczeniem sieci i zostanie omówiony w następnej podsekcji.

\subsubsection{Uczenie sieci neuronowej}
Uczenie sieci neuronowej polega na algorytmicznym dostosowywaniu jej parametrów (wag i obciążeń) w celu minimalizacji błędu prognoz.
Działa ono w oparciu o zestaw danych zawierających zarówno dane wejściowe \( \mathbf{x} \), jak i odpowiadające im rzeczywiste wartości wyjściowe \( \mathbf{y} \).
Innymi słowy, sieć uczy się na podstawie przykładów, aby poprawić swoje prognozy \cite{TODO_nn_modelling}.

Aby proces uczenia zwracał rzetelne wyniki, zestaw danych dzieli się na trzy niezależne podzbiory \cite{TODO_dataset_split}:
\begin{itemize}
    \item \textbf{Zbiór treningowy:} Służy do uczenia sieci poprzez dostosowywanie jej parametrów \cite{TODO_train_dataset}.
    \item \textbf{Zbiór walidacyjny:} Używany do monitorowania wydajności sieci podczas treningu i dostrajania hiperparametrów \cite{TODO_valid_dataset}.
    \item \textbf{Zbiór testowy:} Służy do oceny ostatecznej wydajności sieci na niewidzianych wcześniej danych \cite{TODO_test_dataset}.
\end{itemize}

Sam proces dostosowywania parametrów sieci przeprowadzany jest na zbiorze treningowym i można go opisać w kilku kluczowych krokach \cite{TODO_nn_modelling}:

\begin{enumerate}

    \item \textbf{Inicjalizacja:} Na początku, wagi \( \mathbf{W}^{(l)} \) oraz obciążenia \( \mathbf{b}^{(l)} \) są inicjalizowane małymi, losowymi wartościami \cite{TODO_weights_bias_init}.

    \item \textbf{Propagacja w przód:} Dane wejściowe \( \mathbf{x} \) są przekazywane przez sieć, generując prognozy \( \mathbf{\hat{y}} \) \cite{TODO_forward_propagation}.

    \item \textbf{Obliczanie błędu:} Prognoza modelu \( \mathbf{\hat{y}} \) jest porównywana z rzeczywistą wartością \( \mathbf{y} \) za pomocą funkcji kosztu (np. MSE), co pozwala na zmierzenie błędu prognozy \cite{TODO_measuring_loss}:
    \begin{equation}
        L = \frac{1}{n} \sum_{i=1}^{n} (\hat{y}_i - y_i)^2
    \end{equation}
    gdzie \( L \) to wartość funkcji kosztu MSE, a \( n \) to liczba próbek w zbiorze treningowym.

    \item \textbf{Propagacja wsteczna błędu:} Obliczony błąd jest propagowany wstecz sieci, od warstwy wyjściowej do wejściowej. 
    Celem tego kroku jest obliczenie gradientów funkcji kosztu w każdym neuronie sieci.
    Gradienty te wskazują kierunek i wielkość zmian, które należy wprowadzić w parametrach sieci, aby skutecznie minimalizować błąd prognozy.
    Formalnie gradient jest pochodną funkcji kosztu względem wag lub obciążeń \cite{TODO_backward_propagation}:
    \begin{equation}
        \frac{\partial L}{\partial \mathbf{W}^{(l)}}, \quad \frac{\partial L}{\partial \mathbf{b}^{(l)}}
    \end{equation}

    \item \textbf{Aktualizacja parametrów:} Wagi i obciążenia są aktualizowane za pomocą algorytmu optymalizacji (np. Stochastic Gradient Descent, Adam), wykorzystując obliczone gradienty \cite{TODO_weights_bias_update}:
    \begin{equation}
        \mathbf{W}^{(l)} \leftarrow \mathbf{W}^{(l)} - \eta \frac{\partial L}{\partial \mathbf{W}^{(l)}}, \quad
        \mathbf{b}^{(l)} \leftarrow \mathbf{b}^{(l)} - \eta \frac{\partial L}{\partial \mathbf{b}^{(l)}}
    \end{equation}
    gdzie \( \eta \) to współczynnik nauki (learning rate), określający wielkość kroków aktualizacji.

\end{enumerate}

Proces ten jest powtarzany przez wiele iteracji (epok) na całym zbiorze treningowym, aż do osiągnięcia zadowalającej dokładności prognoz lub spełnienia kryteriów zatrzymania (np. minimalny błąd na zbiorze walidacyjnym).
Wynikowo sieć neuronowa uczy się optymalnych wartości wag i obciążeń, co pozwala jej na generowanie trafnych prognoz na niewidzianych wcześniej danych \cite{TODO_nn_modelling}.

\subsubsection{Sieci rekurencyjne}
Tradycyjna architekura sieci neuronowej, opisana w poprzednich podsekcjach, zakłada, że dane wejściowe są niezależne od siebie \cite{TODO_nn_independent_inputs}.
W przypadku danych finansowych (szeregi czasowe) takie założenie jest błędne, ponieważ obserwacje są ze sobą powiązane w czasie.
Można sobie to wyobrazić na przykładzie cen akcji, gdzie ceny z kilku poprzednich dni wpływają na cenę w dniu dzisiejszym.
Wówczas pojawia się potrzeba "pamiętania" wcześniejszych informacji podczas przetwarzania bieżących danych.
Sieci rekurencyjne (RNN) zostały zaprojektowane właśnie w tym celu \cite{TODO_time_series_data}.

Podstawowym budulcem sieci RNN jest komórka rekurencyjna, która posiada zdolność do przechowywania stanu ukrytego \( \mathbf{h}_t \) \cite{TODO_RNN_cells}.
Stan ukryty \( \mathbf{h}_t \) jest nośnikiem informacji z poprzednich kroków czasowych \cite{TODO_hidden_state}.
Aby skutecznie taką informację utrwalić, sieci RNN wykorzystują mechanizm rekurencji, gdzie wyjście z poprzedniego kroku czasowego jest wykorzystywane jako dodatkowe wejście do bieżącego kroku \cite{TODO_RNN_recurrence}.

Formalnie, stan ukryty \( \mathbf{h}_t \) w czasie \( t \) jest wektorem obliczanym na podstawie bieżącego wejścia \( \mathbf{x}_t \) oraz poprzedniego stanu ukrytego \( \mathbf{h}_{t-1} \) \cite{TODO_RNN_cells}:
\begin{equation}
    \mathbf{h}_t = f(\mathbf{W}_h \mathbf{h}_{t-1} + \mathbf{W}_x \mathbf{x}_t + \mathbf{b})
\end{equation}
gdzie \( \mathbf{W}_h \) to macierz wag dla stanu ukrytego, \( \mathbf{W}_x \) to macierz wag dla wejścia, \( \mathbf{b} \) to wektor obciążeń, a \( f \) to funkcja aktywacji.

Gdy obliczony zostanie ostatni stan ukryty \( \mathbf{h}_t \), sieć może wygenerować prognozę \( \mathbf{\hat{y}}_t \) na podstawie tego stanu \cite{TODO_RNN_output}:
\begin{equation}
    \mathbf{\hat{y}}_t = g(\mathbf{W}_y \mathbf{h}_t + \mathbf{b}_y)
\end{equation}
gdzie \( \mathbf{W}_y \) to macierz wag dla wyjścia, \( \mathbf{b}_y \) to wektor obciążeń wyjścia, a \( g \) to funkcja aktywacji wyjścia.

Rysunek \ref{fig:rnn_cell} przedstawia schematyczną budowę komórki rekurencyjnej w sieci RNN.
Aby lepiej zobrazować działanie komórki RNN, na rysunku pokazano jej rozwinięcie w czasie.
Stan ukryty \( \mathbf{h}_t \) jest przekazywany z jednego kroku czasowego do następnego.
% Wagi \( \mathbf{W}_h \), \( \mathbf{W}_x \), \( \mathbf{W}_y \) oraz obciążenie \( \mathbf{b} \) są współdzielone przez wszystkie kroki czasowe.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{assets/rnn_cell.png}
    % \href{https://commons.wikimedia.org/wiki/File:Recurrent_neural_network_unfold.svg}{Wikimedia Commons}
    \caption{Budowa komórki rekurencyjnej w sieci RNN. Opracowanie własne na podstawie \cite{wikimedia_rnn_unfold}.}
    \label{fig:rnn_cell}
\end{figure}

Taka architektura stanowi solidny fundament do modelowania szeregów czasowych \cite{TODO_RNN_for_time_series_modelling}.
Niemniej jednak, tradycyjne sieci RNN mają pewne ograniczenia.
Są nimi m.in. problem zanikającego i eksplodującego gradientu podczas procesu uczenia, co utrudnia naukę długoterminowych zależności w danych \cite{TODO_vanishing_gradient, TODO_exploding_gradient}.
Aby wyjaśnić na czym polegają te problemy, należy wrócić do procesu opartego na wstecznej propagacji błędu.

W przypadku sieci RNN, odpowiednikiem algorytmu wstecznej propagacji jest algorytm zwany propagacją wsteczną w czasie (ang. *Backpropagation Through Time, BPTT*).
Tak jak w przypadku klasycznej propagacji wstecznej, BPTT polega na obliczaniu gradientów funkcji kosztu względem wag i obciążeń sieci.
Ze względu na współdzielenie wag w czasie, gradienty są sumowane przez wszystkie kroki czasowe, co daje ostateczny gradient dla każdej wagi \cite{TODO_BPTT}:
\begin{equation}
    \frac{\partial L}{\partial \mathbf{W}_h} = \sum_{t=1}^{T} \frac{\partial L}{\partial \mathbf{h}_t} \frac{\partial \mathbf{h}_t}{\partial \mathbf{W}_h}
\end{equation}
W praktyce, propagacja błędu w czasie wiąże się z wielokrotnym mnożeniem macierzy wag \( \mathbf{W}_h \) odpowiadających za stan ukryty \cite{TODO_repetetive_multiplication_of_weights}:
\begin{equation}
    \frac{\partial L}{\partial \mathbf{h}_t} = \frac{\partial L}{\partial \mathbf{h}_T} \prod_{k=t+1}^{T} \frac{\partial \mathbf{h}_k}{\partial \mathbf{h}_{k-1}}
\end{equation}
To właśnie ten mechanizm prowadzi do dwóch problemów:
\begin{itemize}
    \item \textbf{Problem zanikającego gradientu:} Jeśli wartości w macierzy wag \( \mathbf{W}_h \) są małe (norma macierzy mniejsza od 1), to przy wielokrotnym mnożeniu sygnał błędu (gradient) staje się wykładniczo coraz mniejszy.
    W konsekwencji sieć nie jest w stanie nauczyć się zależności między danymi, które są od siebie odległe w czasie \cite{TODO_vanishing_gradient}.

    \item \textbf{Problem eksplodującego gradientu:} Jest to sytuacja odwrotna. Jeśli wartości w macierzy wag \( \mathbf{W}_h \) są duże (norma macierzy większa od 1), sygnał błędu przy wielokrotnym mnożeniu rośnie wykładniczo, stając się ogromną liczbą.
    Na skutek tego aktualizacje wag stają się tak duże, że proces uczenia staje się niestabilny \cite{TODO_exploding_gradient}.
\end{itemize}

Aby skutecznie radzić sobie z tymi problemami, opracowano zaawansowane architektury sieci rekurencyjnych.
Jedną z najpopularniejszych jest Long Short-Term Memory (LSTM), która zostanie omówiona w następnej podsekcji \cite{TODO_LSTM}.

\subsubsection{Sieci Long Short-Term Memory}
Sieci Long Short-Term Memory (LSTM) zostały zaprojektowane, aby niwelować problemy zanikającego i eksplodującego gradientu występujące w tradycyjnych sieciach RNN \cite{TODO_LSTM}.
Cechę tę osiągnięto poprzez wprowadzenie mechanizmów zwanych bramkami (ang. *gates*) oraz dodatkowego stanu komórki \( \mathbf{C}_t \) \cite{TODO_LSTM_cells}.
Stan komórki \( \mathbf{C}_t \), w odróżnieniu od stanu ukrytego \( \mathbf{h}_t \), jest nośnikiem długoterminowych informacji.
Dzięki temu LSTM mogą efektywnie przechowywać i wykorzystywać informacje z odległych kroków czasowych \cite{TODO_LSTM_long_term_memory}.
Komórka LSTM składa sie z trzech głównych bramek \cite{TODO_LSTM_gates}:
\begin{enumerate}
    \item \textbf{Bramka zapominania (Forget Gate):} Decyduje, które informacje z poprzedniego stanu komórki \( \mathbf{C}_{t-1} \) należy zachować, a które odrzucić.
    \item \textbf{Bramka wejścia (Input Gate):} Określa, które nowe informacje z bieżącego wejścia \( \mathbf{x}_t \) powinny zostać dodane do stanu komórki \( \mathbf{C}_t \).
    \item \textbf{Bramka wyjścia (Output Gate):} Kontroluje, które informacje ze stanu komórki \( \mathbf{C}_t \) zostaną wykorzystane do wygenerowania bieżącego stanu ukrytego \( \mathbf{h}_t \).
\end{enumerate}

Rysunek \ref{fig:lstm_cell} przedstawia schematyczną budowę komórki LSTM wraz z jej trzema bramkami.
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{assets/lstm_cell.png}
    \caption{Budowa komórki LSTM z trzema bramkami: bramką zapominania, bramką wejścia i bramką wyjścia. Opracowanie własne na podstawie \cite{lstm_cell_drawing}.}
    \label{fig:lstm_cell}
\end{figure}

Każda z bramek w komórce LSTM działa na podobnej zasadzie jak tradycyjny neuron, wykorzystując funkcję aktywacji sigmoidalnej do generowania wartości między 0 a 1 \cite{TODO_LSTM_gates}.
Służy to określeniu stopnia przepuszczania informacji przez daną bramkę.
Przepływ informacji w komórce LSTM można opisać następującymi krokami \cite{TODO_LSTM_operations}:
\begin{enumerate}
    \item \textbf{Bramka zapominania:} Oblicza się wartość bramki zapominania \( \mathbf{f}_t \) na podstawie bieżącego wejścia \( \mathbf{x}_t \) oraz poprzedniego stanu ukrytego \( \mathbf{h}_{t-1} \). 
    Otrzymana wartość decyduje, które informacje z poprzedniego stanu komórki \( \mathbf{C}_{t-1} \) należy zachować \cite{TODO_LSTM_forgetting}:
    \begin{equation}
        \mathbf{f}_t = \sigma(\mathbf{W}_f [\mathbf{h}_{t-1}, \mathbf{x}_t] + \mathbf{b}_f)
    \end{equation}
    \begin{equation}
        \mathbf{C}_t = \mathbf{f}_t * \mathbf{C}_{t-1}
    \end{equation}

    \item \textbf{Bramka wejścia:} Oblicza się wartość bramki wejścia \( \mathbf{i}_t \) oraz tworzy się kandydat na nowe informacje \( \tilde{\mathbf{C}}_t \) na podstawie bieżącego wejścia \( \mathbf{x}_t \) oraz poprzedniego stanu ukrytego \( \mathbf{h}_{t-1} \).
    Następnie, przy pomocy nowych informacji aktualizuje się stan komórki \( \mathbf{C}_t \) \cite{TODO_LSTM_input}:
    \begin{equation}
        \mathbf{i}_t = \sigma(\mathbf{W}_i [\mathbf{h}_{t-1}, \mathbf{x}_t] + \mathbf{b}_i)
    \end{equation}
    \begin{equation}
        \tilde{\mathbf{C}}_t = \tanh(\mathbf{W}_C [\mathbf{h}_{t-1}, \mathbf{x}_t] + \mathbf{b}_C)
    \end{equation}
    \begin{equation}
        \mathbf{C}_t = \mathbf{C}_t + \mathbf{i}_t * \tilde{\mathbf{C}}_t
    \end{equation}

    \item \textbf{Bramka wyjścia:} Oblicza się wartość bramki wyjścia \( \mathbf{o}_t \) na podstawie bieżącego wejścia \( \mathbf{x}_t \) oraz poprzedniego stanu ukrytego \( \mathbf{h}_{t-1} \).
    Następnie, generuje się bieżący stan ukryty \( \mathbf{h}_t \) na podstawie zaktualizowanego stanu komórki \( \mathbf{C}_t \) \cite{TODO_LSTM_output}:
    \begin{equation}
        \mathbf{o}_t = \sigma(\mathbf{W}_o [\mathbf{h}_{t-1}, \mathbf{x}_t] + \mathbf{b}_o)
    \end{equation}
    \begin{equation}
        \mathbf{h}_t = \mathbf{o}_t * \tanh(\mathbf{C}_t)
    \end{equation}
    gdzie:
    \begin{itemize}
        \item \( \sigma \) to funkcja aktywacji sigmoidalnej,
        \item \( \tanh \) to funkcja aktywacji tangens hiperboliczny,
        \item \( \mathbf{W}_f, \mathbf{W}_i, \mathbf{W}_C, \mathbf{W}_o \) to macierze wag dla poszczególnych bramek,
        \item \( \mathbf{b}_f, \mathbf{b}_i, \mathbf{b}_C, \mathbf{b}_o \) to wektory obciążeń dla poszczególnych bramek.
    \end{itemize}
\end{enumerate}

Kluczem do skutecznej minimalizacji problemu zanikającego gradientu w LSTM jest mechanizm bramek, który umożliwia selektywne przepuszczanie informacji przez stan komórki \( \mathbf{C}_t \) \cite{TODO_LSTM_vanishing_gradient_solution}.
Zamiast wielokrotnego mnożenia wag, jak ma to miejsce w tradycyjnych RNN, LSTM wykorzystują operacje dodawania do aktualizacji stanu komórki oraz mnożenia do określenia stopnia zachowania informacji.
Dzięki takiej architekturze, gradienty mogą przepływać przez sieć w sposób bardziej kontrolowany, co znacząco ogranicza ryzyko ich zanikania lub eksplodowania i poprawia stabilność procesu uczenia \cite{TODO_LSTM_gradient_flow}.

\clearpage
\subsubsection{Filtr Kalmana}
Sieci neuronowe (w tym LSTM) są potężnymi narzędziami do modelowania danych.
Jednakże w praktyce, dane często zawierają szumy i fluktuacje, które wprowadzają niepożądane błędy w prognozach \cite{TODO_data_noise}.
W przypadku cen akcji, takie zakłócenia mogą wynikać z nagłych wydarzeń rynkowo-politycznych, np.: niespodziewanych decyzji regulacyjnych czy kryzysów gospodarczych \cite{TODO_stock_price_fluctuations}.
Aby skutecznie minimalizować wpływ takich szumów, stosuje się różne techniki filtracji danych.

Ogólne pojęcie filtracji odnosi się do procesu usuwania niepożądanych części sygnału, w celu uzyskania czystszego sygnału \cite{TODO_signal_filtering}.
Jedną z zaawansowanych metod filtracji jest filtr Kalmana.
Filtr Kalmana to algorytm rekurencyjny służący do estymacji stanu dynamicznego systemu (np. poruszającego się pojazdu, cen akcji) \cite{TODO_kalman_filter}.
Działa on poprzez łączenie dwóch źródeł informacji:
\begin{itemize}
    \item \textbf{Modelu predykcyjnego:} Opisuje, jak stan systemu zmienia się w czasie.
    \item \textbf{Pomiarów obserwacyjnych:} Dostarcza informacji o aktualnym stanie systemu.
\end{itemize}
Obydwie z ww. informacji są obarczone niepewnością -- model predykcyjny może nie uwzględniać wszystkich czynników wpływających na system, a pomiary mogą być zanieczyszczone szumem \cite{TODO_kalman_filter_uncertainty}.
Z tego powodu filtr Kalmana wykorzystuje podejście probabilistyczne, aby w sposób optymalny łączyć te dwie informacje i uzyskać jak najlepszą estymację stanu systemu \cite{TODO_kalman_filter_probabilistic_approach}.
Proces działania filtru Kalmana można podzielić na trzy główne kroki \cite{TODO_kalman_filter_steps}:
\begin{enumerate}
    \item \textbf{Inicjalizacja stanu:} Na początku definiuje się początkowy stan systemu \(\mathbf{x}\) oraz macierz kowariancji błędu estymacji \(\mathbf{P}\) \cite{TODO_kalman_filter_initialization}.
    Na początku można założyć, że stan jest nieznany, więc macierz \(\mathbf{P}\) jest ustawiona na dużą wartość, co odzwierciedla wysoką niepewność.
    
    Kluczowe jest również zdefiniowanie macierzy opisujących model systemu:
    \begin{itemize}
        \item \( \mathbf{F} \) -- \textbf{macierz przejścia stanu}, która opisuje, zmianę stanu systemu w czasie.
        \item \( \mathbf{H} \) -- \textbf{macierz obserwacji}, która mapuje prawdziwy stan systemu \( \mathbf{x} \) na przestrzeń pomiarową \( \mathbf{z} \).
        \item \( \mathbf{Q} \) -- \textbf{macierz kowariancji szumu procesu}, która reprezentuje niepewność związaną z modelem predykcyjnym (np. czynniki nieujęte w modelu).
        \item \( \mathbf{R} \) -- \textbf{macierz kowariancji szumu pomiarowego}, która reprezentuje niepewność związaną z samymi pomiarami (np. niedokładność czujnika).
        \item \( \mathbf{B} \) -- \textbf{macierz sterowania} (opcjonalna), która opisuje wpływ zewnętrznego sterowania \( \mathbf{u} \) na stan systemu.
    \end{itemize}

    \item \textbf{Predykcja:} Wyznacza się przewidywany stan systemu \(\mathbf{\hat{x}}\) oraz przewidywaną macierz kowariancji błędu estymacji \(\mathbf{\hat{P}}\) \cite{TODO_kalman_filter_prediction}:
    \begin{equation}
        \mathbf{\hat{x}} = \mathbf{F} \mathbf{x} + \mathbf{B} \mathbf{u}
    \end{equation}
    \begin{equation}
        \mathbf{\hat{P}} = \mathbf{F} \mathbf{P} \mathbf{F}^T + \mathbf{Q}
    \end{equation}

    \item \textbf{Aktualizacja:} Gdy dostępny jest nowy pomiar \(\mathbf{z}\), wyznacza się resztę pomiarową (ang. residual) \(\mathbf{y}\), oraz zysk Kalmana \(\mathbf{K}\) (ang. Kalman gain) \cite{TODO_kalman_filter_update}:
    \begin{equation}
        \mathbf{y} = \mathbf{z} - \mathbf{H} \mathbf{\hat{x}}
    \end{equation}
    \begin{equation}
        \mathbf{K} = \mathbf{\hat{P}} \mathbf{H}^T (\mathbf{H} \mathbf{\hat{P}} \mathbf{H}^T + \mathbf{R})^{-1}
    \end{equation}
    Następnie, aktualizuje się estymowany stan \(\mathbf{x}\) oraz macierz kowariancji błędu estymacji \(\mathbf{P}\):
    \begin{equation}
        \mathbf{x} = \mathbf{\hat{x}} + \mathbf{K} \mathbf{y}
    \end{equation}
    \begin{equation}
        \mathbf{P} = (\mathbf{I} - \mathbf{K} \mathbf{H}) \mathbf{\hat{P}}
    \end{equation}
    Zaktualizowane wartości stanu \(\mathbf{x}\) oraz macierzy \(\mathbf{P}\) są następnie wykorzystywane w kolejnym kroku predykcji.
\end{enumerate}

Rysunek \ref{fig:kalman_filter_cycle} przedstawia schematyczny cykl działania filtru Kalmana, ilustrując kroki predykcji i aktualizacji.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/kalman_filter_cycle.png}
    \caption{Cykl działania filtru Kalmana, ilustrujący kroki predykcji i aktualizacji. Opracowanie własne na podstawie \cite{kalman_filter_cycle_drawing}.}
    \label{fig:kalman_filter_cycle}
\end{figure}

W kontekście prognozowania cen akcji, filtr Kalmana może być użyty do odszumienia danych w fazie ich wstępnego przetwarzania \cite{TODO_kalman_filter_stock_prices}.
Dzięki temu sieć LSTM otrzymuje czystsze dane wejściowe, co może prowadzić do bardziej trafnych prognoz.
Integracja filtru Kalmana z siecią LSTM pozwala na skuteczne łączenie zalet obu metod: zdolności LSTM do modelowania złożonych zależności czasowych oraz umiejętności filtru Kalmana do redukcji szumów w danych \cite{TODO_kalman_lstm_integration}.

%~ Research approach
\clearpage
\section{Metodyka badań}
Celem przeprowadzonych badań było porównanie skuteczności predykcji cen akcji przy użyciu tradycyjnej sieci LSTM oraz sieci LSTM wspomaganej filtrem Kalmana.
Z tego powodu zaprojektowano i zaimplementowano trzy odrębne modele, z których każdy służył weryfikacji innej hipotezy badawczej:
\begin{itemize}
    \item \textbf{Model bazowy (Base Model):} Stanowił punkt odniesienia (ang. \textit{baseline}). Jego zadaniem było prognozowanie cen wyłącznie na podstawie ich historycznych wartości, przy użyciu prostej architektury LSTM.
    \item \textbf{Model wzbogacony (Enriched Model):} Miał na celu weryfikację, czy dostarczenie modelowi dodatkowego kontekstu rynkowego w postaci wskaźników analizy technicznej poprawi jakość predykcji.
    \item \textbf{Model z filtrem Kalmana (Kalman Model):} Służył do zbadania głównej hipotezy pracy -- czy wstępna filtracja i odszumienie danych wejściowych przy użyciu filtru Kalmana pozytywnie wpływa na skuteczność prognoz sieci LSTM.
\end{itemize}
W niniejszym rozdziale przedstawiono szczegółowy opis metodologii badawczej zastosowanej w pracy, obejmujący proces przygotowania danych, implementację modeli, procedurę uczenia, metryki oceny wydajności i sposób ewaluacji.

\subsection{Środowisko badawcze}
Do przeprowadzenia eksperymentów wykorzystano język programowania Python 3.12 oraz następujące biblioteki:
\begin{itemize}
    \item \textbf{Pandas:} Biblioteka służąca do manipulacji i analizy danych, w szczególności do pracy z danymi tabelarycznymi i szeregami czasowymi. Została wykorzystana do wczytywania, czyszczenia oraz transformacji danych giełdowych.
    \item \textbf{NumPy:} Podstawowy pakiet do obliczeń naukowych w Pythonie, zapewniający wsparcie dla wielowymiarowych tablic i macierzy oraz szerokiej gamy funkcji matematycznych.
    \item \textbf{PyTorch:} Jedna z wiodących platform do uczenia głębokiego, wykorzystana do zdefiniowania architektury sieci LSTM, implementacji pętli treningowej oraz przeprowadzenia procesu uczenia modeli.
    \item \textbf{Optuna:} Biblioteka do automatycznej optymalizacji hiperparametrów modeli uczenia maszynowego, która została użyta do znalezienia optymalnych wartości takich parametrów jak liczba warstw LSTM, liczba neuronów w warstwach, współczynnik nauki oraz wielkość partii treningowej (batch size).
    \item \textbf{Scikit-learn:} Kompleksowa biblioteka do uczenia maszynowego, z której wykorzystano m.in. narzędzia do skalowania danych (MinMaxScaler) oraz obliczania metryk oceny modeli (MSE, RMSE).
    \item \textbf{FilterPy:} Specjalistyczna biblioteka dostarczająca implementacje różnych algorytmów filtrujących, w tym filtru Kalmana, który został użyty do odszumiania danych wejściowych.
    \item \textbf{Technical Analysis (ta):} Biblioteka umożliwiająca obliczanie wskaźników analizy technicznej, które zostały wykorzystane do wzbogacenia zestawu cech wejściowych modeli.
    \item \textbf{Matplotlib \& Seaborn:} Biblioteki do wizualizacji danych, które posłużyły do generowania wszystkich wykresów przedstawionych w pracy, m.in. wykresów cen, krzywych uczenia i porównań predykcji z wartościami rzeczywistymi.
    \item \textbf{yfinance:} Biblioteka umożliwiająca pobieranie historycznych danych rynkowych z serwisu Yahoo! Finance.
\end{itemize}
Całość kodu została zorganizowana w ramach projektu Kedro, co zapewniło modularność, reużywalność oraz łatwość zarządzania eksperymentami.

\subsection{Przygotowanie danych}
Proces przygotowania danych stanowił pierwszy etap badań.
Jego celem było uzyskanie oczyszczonego i odpowiednio sformatowanego zestawu danych giełdowych spółki Amazon (AMZN), który mógł zostać użyty do trenowania i testowania modeli LSTM.
Proces ten obejmował następujące kroki: pobrania danych, przetwarzania wstępnego, inżynierii cech oraz podziału na zbiory treningowy, walidacyjny i testowy \cite{TODO_preprocessing_practices}.

\subsubsection{Pobranie danych}
Dane historyczne dotyczące cen akcji spółki Amazon zostały pobrane z serwisu Yahoo! Finance przy użyciu biblioteki yfinance.
Zbiór danych objemował dzienne notowania z okresu od 3 stycznia 2022 roku do 11 września 2025 roku.
Każdy rekord w surowym zbiorze danych zawierał informacje OHLC (Open, High, Low, Close), wolumen obrotu oraz datę notowania \cite{TODO_yfinance_data_retrieval}.
Tabela \ref{tab:raw_data_sample} przedstawia przykładowe rekordy z pobranego zbioru danych.
\begin{table}[H]
    \centering
    \caption{Przykładowe rekordy z surowego zbioru danych dla spółki AMZN. Źródło: \cite{TODO_yfinance}}
    \label{tab:raw_data_sample}
    \begin{tabular}{lrrrrr}
        \hline
        \textbf{Date} & \textbf{Open} & \textbf{High} & \textbf{Low} & \textbf{Close} & \textbf{Volume} \\
        \hline
        2022-01-03 & 170.40 & 170.70 & 166.16 & 167.55 & 63520000 \\
        2022-01-04 & 167.52 & 171.40 & 166.35 & 170.44 & 70726000 \\
        2022-01-05 & 164.36 & 167.13 & 164.36 & 166.88 & 64302000 \\
        2022-01-06 & 163.25 & 164.80 & 161.94 & 163.45 & 51958000 \\
        2022-01-07 & 162.55 & 165.24 & 162.03 & 163.84 & 46606000 \\
        ... & ... & ... & ... \\
        \hline
    \end{tabular}
\end{table}

\subsubsection{Przetwarzanie wstępne i inżynieria cech}
Surowe dane w formie szeregu czasowego nie są bezpośrednio kompatybilne z architekturą sieci LSTM, która oczekuje danych w formacie nadzorowanym, tj. par (sekwencja wejściowa, wartość docelowa). 
W związku z tym, pierwszym krokiem było przekształcenie danych do odpowiedniego formatu, który zawierałby sekwencje historycznych cen jako wejścia oraz odpowiadające im przyszłe ceny jako wartości docelowe \cite{TODO_time_series_formatting}.
Na potrzeby przeprowadzenia eksperymentów podjęto decyzję uwzględnieniu cen zamknięcia (Close) z trzech poprzednich dni jako cech wejściowych do przewidywania ceny zamknięcia w dniu następnym.
Tabela \ref{tab:formatted_data_sample} przedstawia przykładowe rekordy z przetworzonego zbioru danych.
\begin{table}[H]
    \centering
    \caption{Przykładowa struktura danych po przekształceniu do formatu nadzorowanego.}
    \label{tab:formatted_data_sample}
    \begin{tabular}{cccc}
        \hline
        \textbf{Close} & \textbf{Close (t-1)} & \textbf{Close (t-2)} & \textbf{Close (t-3)} \\
        \hline
        163.25 & 164.36 & 167.52 & 170.40 \\
        162.55 & 163.25 & 164.36 & 167.52 \\
        161.49 & 162.55 & 163.25 & 164.36 \\
        165.36 & 161.49 & 162.55 & 163.25 \\
        165.21 & 165.36 & 161.49 & 162.55 \\
        ... & ... & ... & ... \\
        \hline
    \end{tabular}
\end{table}

Po tym fundamentalnym etapie, który był wspólny dla wszystkich eksperymentów, dalsze kroki przetwarzania i inżynierii cech zostały zróżnicowane. 
Powodem tego była potrzeba przygotowania trzech odrębnych wariantów zbioru danych, z których każdy był dedykowany jednemu z porównywanych modeli.

\begin{enumerate}
    \item \textbf{Zbiór dla modelu bazowego (Base Model):} W tym wariancie nie stosowano zaawansowanej inżynierii cech. Jedyną cechą wejściową była historyczna cena zamknięcia (Close).

    \item \textbf{Zbiór dla modelu wzbogaconego (Enriched Model):} Ten zbiór został rozszerzony o dodatkowe cechy uzyskane w procesie inżynierii cech. Do ceny zamknięcia dołączono trzy wskaźniki analizy technicznej: wskaźnik siły względnej (RSI), szerokość wstęg Bollingera (BBW) oraz procentowe położenie ceny względem wstęg (\%B).

    \item \textbf{Zbiór dla modelu z filtrem Kalmana (Kalman Model):} W tym podejściu cena zamknięcia została poddana procesowi filtracji przy użyciu filtru Kalmana.
\end{enumerate}

Po zdefiniowaniu cech dla każdego z trzech wariantów, wszystkie zbiory zostały poddane tym samym, końcowym etapom przetwarzania, aby zapewnić spójność i rzetelność porównania.

\subsubsection{Skalowanie danych}
Skalowanie cech wejściowych jest kluczowym krokiem w przygotowaniu danych do trenowania sieci neuronowych -- przyspiesza oraz stabilizuje proces uczenia sieci neuronowej \cite{TODO_data_scaling_importance}.
W ramach ninejszej pracy zbadano i porównano dwie strategie skalowania danych:
\begin{itemize}
    \item \textbf{Normalizacja (Min-Max Scaling):} Przekształca wartości cech do z góry określonego zakresu, w tym przypadku [0, 1].
    \item \textbf{Standaryzacja (Z-score Standardization):} Przekształca dane tak, aby miały średnią równą 0 i odchylenie standardowe równe 1.
\end{itemize}
Ważnym aspektem metodologicznym było dopasowanie skalera wyłącznie na danych treningowych. 
Następnie ten sam, dopasowany skaler został użyty do transformacji zarówno zbioru walidacyjnego, jak i testowego. 
Takie podejście zapobiega "przeciekowi danych" (ang. data leakage) z przyszłości do modelu, co jest niezbędne dla uzyskania wiarygodnych i rzetelnych wyników \cite{TODO_data_leakage_prevention}.

\subsubsection{Podział danych}
Po zakończeniu wszystkich etapów przetwarzania i inżynierii cech, zbiory danych zostały podzielone na trzy odrębne części:
\begin{itemize}
    \item \textbf{Zbiór treningowy (Training Set):} Obejmuje 72\% danych i służy do trenowania modeli LSTM.
    \item \textbf{Zbiór walidacyjny (Validation Set):} Obejmuje 18\% danych i jest wykorzystywany do monitorowania wydajności modeli podczas treningu oraz do strojenia hiperparametrów.
    \item \textbf{Zbiór testowy (Test Set):} Obejmuje pozostałe 10\% danych i służy do ostatecznej oceny wydajności wytrenowanych modeli.
\end{itemize}
Podział danych został przeprowadzony w sposób chronologiczny, aby zachować naturalną kolejność czasową szeregów danych giełdowych i uniknąć potencjalnych problemów związanych z przeciekiem danych \cite{TODO_time_series_data_splitting}.

\subsection{Architektura modeli}
W niniejszej pracy porównano trzy różne modele LSTM, z których każdy charakteryzował się odmiennym podejściem do przetwarzania danych wejściowych.
Wszystkie modele zostały zaimplementowane przy użyciu biblioteki PyTorch, co zapewniło elastyczność i wydajność niezbędną do przeprowadzenia eksperymentów \cite{TODO_pytorch_usage}.

Chociaż ogólny schemat tworzenia modeli był wspólny, to jednak poszczególne modele różniły się kluczowymi hiperparametrami architektury, takimi jak wymiar danych wejściowych, liczba warstw LSTM oraz liczba neuronów w warstwach ukrytych. 
Różnice te wynikały z różnicy w charakterystyce danych wejściowych, których dany model miał używać do predykcji cen akcji.
Poniżej przedstawiono szczegółowy opis każdego z trzech modeli.


\subsubsection{Model bazowy (Base Model)}
Model bazowy stanowił najprostszą implementację, zaprojektowaną w celu ustanowienia punktu odniesienia (ang. \textit{baseline}). 
Architektura modelu bazowego składała się z jednej warstwy LSTM z 27 neuronami w warstwie ukrytej, co zapewniało wystarczającą zdolność modelowania prostych zależności czasowych w danych wejściowych.

\subsubsection{Model wzbogacony (Enriched Model)}
Model wzbogacony rozszerzał architekturę modelu bazowego poprzez dodanie trzech wskaźników analizy technicznej (RSI, BBW, \%B) jako dodatkowych cech wejściowych.
Z tego względu zastosowano bardziej złożoną architekturę, obejmującą dwie warstwy LSTM oraz większą liczbę neuronów w warstwach ukrytych.


\subsubsection{Model z filtrem Kalmana (Kalman Model)}
Model ten operował na takich samych danych jak model bazowy, jednak przed podaniem ich na wejście sieci LSTM, dane te były poddawane procesowi filtracji przy użyciu filtru Kalmana.
Jego architektura była tożsama z architekturą modelu bazowego, co pozwalało na bezpośrednie porównanie wpływu samej filtracji danych na wyniki predykcji.

\vspace{0.5cm}
Tabela \ref{tab:model_architecture_params} przedstawia zestawienie kluczowych hiperparametrów architektury każdego z modeli, które uzyskano w wyniku procesu optymalizacji.
\begin{table}[H]
    \centering
    \caption{Zestawienie kluczowych hiperparametrów architektury modeli.}
    \label{tab:model_architecture_params}
    \begin{tabular}{lccc}
        \hline
        \textbf{Hiperparametr} & \textbf{Base Model} & \textbf{Enriched Model} & \textbf{Kalman Model} \\
        \hline
        Wymiar wejścia & 1 & 4 & 1 \\
        Liczba warstw LSTM & 1 & 2 & 1 \\
        Liczba neuronów ukrytych & 27 & 64 & 27 \\
        Wymiar wyjścia & 1 & 1 & 1 \\
        \hline
    \end{tabular}
\end{table}

Podsumowując, architektury trzech modeli zostały świadomie zróżnicowane, aby umożliwić rzetelne zbadanie postawionych hipotez. 
Model bazowy i model z filtrem Kalmana posiadały identyczną, prostą architekturę, co pozwoliło na wyizolowanie i ocenę wpływu samej filtracji danych. 
Z kolei model wzbogacony, ze względu na wielowymiarowy charakter danych wejściowych, został wyposażony w bardziej złożoną strukturę, zdolną do przetwarzania bogatszego zestawu informacji. 
W kolejnej sekcji opisano proces uczenia i ewaluacji tych modeli.

\subsection{Metryki oceny}
Do monitorowania wydajności modeli w trakcie procesu uczenia oraz do finalnej oceny ich skuteczności na zbiorze testowym, wybrano trzy powszechnie stosowane metryki regresji:
\begin{itemize}
    \item \textbf{Mean Squared Error (MSE):} Miara średniego kwadratu różnic między wartościami przewidywanymi a rzeczywistymi.
    \begin{equation}
        \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
    \end{equation}
    gdzie \( y_i \) to rzeczywista wartość, \( \hat{y}_i \) to wartość przewidywana przez model, a \( n \) to liczba próbek.
    \item \textbf{Root Mean Squared Error (RMSE):} Pierwiastek kwadratowy z MSE, który daje wynik w tych samych jednostkach co dane wejściowe.
    \begin{equation}
        \text{RMSE} = \sqrt{\text{MSE}} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}
    \end{equation}
    gdzie \( y_i \) to rzeczywista wartość, \( \hat{y}_i \) to wartość przewidywana przez model, a \( n \) to liczba próbek.
    \item \textbf{R-squared \(R^2\):} Miara dopasowania modelu, wskazująca, jaka część wariancji danych jest wyjaśniona przez model.
    \begin{equation}
        R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}
    \end{equation}
    gdzie \( y_i \) to rzeczywista wartość, \( \hat{y}_i \) to wartość przewidywana przez model, \( \bar{y} \) to średnia, a \( n \) to liczba próbek.
\end{itemize}

\subsection{Proces uczenia}
Proces uczenia objemował strojenie hiperparametrów, wybór funkcji straty oraz algorytmu optymalizacji, własciwy trening na danych treningowych oraz monitorowanie wydajności na zbiorze walidacyjnym.
Każdy z trzech modeli był trenowany niezależnie, z zastosowaniem tych samych procedur, aby zapewnić odpowiednią porównywalność wyników.

\subsubsection{Strojenie hiperparametrów}
W celu znalezienia optymalnych wartości hiperparametrów dla każdego z modeli, zastosowano bibliotekę Optuna do automatyzacji tego procesu \cite{TODO_hyperparameter_optimization}.
Przeszukiwana przestrzeń hiperparametrów była wspólna dla wszystkich modeli i obejmowała:
\begin{itemize}
    \item \textbf{Liczba warstw LSTM:} wartości całkowite z zakresu [1, 3].
    \item \textbf{Liczba neuronów w warstwach ukrytych:} wartości całkowite z zakresu [16, 128].
    \item \textbf{Współczynnik nauki (learning rate):} wartości z rozkładu logarytmicznego w zakresie [1e-4, 1e-2].
    \item \textbf{Wielkość partii treningowej (batch size):} wybór spośród wartości [16, 32, 64, 128].
    \item \textbf{Liczba epok treningowych:} wartości całkowite z zakresu [10, 100].
\end{itemize}
Dla każdego modelu przeprowadzono 50 prób optymalizacji (ang. \textit{trials}), a najlepsze zestawy hiperparametrów zostały następnie wykorzystane w treningu modeli.

\subsubsection{Przebieg procesu uczenia}
Proces uczenia modeli przeprowadzono na zbiorze treningowym, stanowiącym 72\% wszystkich danych, wykorzystując zoptymalizowane hiperparametry. 
Jako funkcję kosztu, której wartość była minimalizowana w trakcie uczenia, wybrano błąd średniokwadratowy (MSE). 
Do aktualizacji wag modelu posłużył optymalizator Adam, będący standardem w zadaniach uczenia głębokiego ze względu na jego efektywność i adaptacyjny dobór współczynnika uczenia \cite{TODO_adam_optimizer}.

Liczba epok, przez które trenowano każdy model, została również ustalona jako jeden z hiperparametrów w procesie automatycznego strojenia. 
Wydajność modelu w trakcie uczenia była na bieżąco monitorowana na zbiorze walidacyjnym z wykorzystaniem zdefiniowanych wcześniej metryk (MSE, RMSE, \(R^2\)).
Pozwoliło to na generowanie krzywych uczenia i weryfikację, czy model nie wykazuje oznak znacznego przeuczenia (ang. \textit{overfitting}).

Cały proces uczenia został zaimplementowany jako pipeline w ramach projektu Kedro, co pozwoliło na ustrukturyzowanie i zautomatyzowanie wszystkich opisanych kroków. 
Parametry procesu, takie jak przeszukiwane zakresy hiperparametrów czy liczba prób optymalizacji, zostały umieszczone w plikach konfiguracyjnych. 
Takie podejście zapewniło nie tylko przejrzystość i łatwość zarządzania eksperymentami, ale przede wszystkim gwarantowało powtarzalność (ang. \textit{reproducibility}) procesu uczenia dla każdego z trzech modeli \cite{TODO_kedro_reproducibility}.
Po zakończeniu treningu, wytrenowane modele zostały poddane ewaluacji na zbiorze testowym.

\subsection{Proces ewaluacji}
Po zakończeniu procesu uczenia, każdy z trzech modeli został poddany ocenie na zbiorze testowym, który stanowił 10\% wszystkich danych i nie był wykorzystywany podczas treningu ani walidacji.
Celem ewaluacji było uzyskanie porównywalnych wyników wydajności modeli, które odzwierciedlałyby ich zdolność do generalizacji na nieznanych danych.
Do oceny wydajności modeli na zbiorze testowym zastosowano zdefiniowane wcześniej metryki (MSE, RMSE oraz \(R^2\)).
Produktami końcowymi ewaluacji były:
\begin{itemize}
    \item Zestawienie wyników metryk wydajności dla każdego z modeli.
    \item Wykresy porównujące przewidywane ceny akcji z rzeczywistymi wartościami na zbiorze testowym.
    \item Analiza błędów predykcji w postaci histogramów ich rozkładu.
\end{itemize}
Cały proces, od generowania metryk po wizualizacje, został zaimplementowany jako zautomatyzowany pipeline w ramach projektu Kedro, co zapewniło spójność i powtarzalność całego eksperymentu \cite{TODO_kedro_evaluation}. 
Tak przygotowane i zestawione wyniki posłużyły jako podstawa do przeprowadzenia szczegółowej analizy porównawczej, interpretacji rezultatów oraz sformułowania wniosków dotyczących skuteczności poszczególnych podejść.

\vspace{0.5cm}
Niniejszy rozdział przedstawił kompleksową metodykę badań, obejmującą proces przygotowania danych, implementację i trenowanie trzech odrębnych modeli LSTM oraz procedurę ich ewaluacji.
Taka struktura przeprowadzenia badania miała na celu zapewnienie rzetelności, powtarzalności i porównywalności wyników.
W następnym rozdziale zaprezentowane zostaną wyniki przeprowadzonych eksperymentów oraz ich szczegółowa analiza.

% \section{Wyniki i dyskusja}

% %~ Summary
% \section{Podsumowanie i wnioski}

% %~ Bibliography
% \section{Bibliografia}

% %~ List of figures and tables
% \section{Spis rysunków i tabel}

% %~ Attachments
% \section{Załączniki}


\end{document}
